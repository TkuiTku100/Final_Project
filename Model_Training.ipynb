{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\pc\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (0.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-29T10:42:15.141387100Z",
     "start_time": "2024-10-29T10:42:12.632169100Z"
    }
   },
   "id": "d7a141407b521b23",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-01T22:32:29.224725Z",
     "start_time": "2024-10-30T11:25:52.582485900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\PC\\PycharmProjects\\pythonProject1\\.venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\PC\\PycharmProjects\\pythonProject1\\.venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\PC\\PycharmProjects\\pythonProject1\\.venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\PC\\PycharmProjects\\pythonProject1\\.venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Python312\\Lib\\asyncio\\base_events.py\", line 639, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Python312\\Lib\\asyncio\\base_events.py\", line 1985, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\PC\\PycharmProjects\\pythonProject1\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\PC\\PycharmProjects\\pythonProject1\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\PC\\PycharmProjects\\pythonProject1\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\PC\\PycharmProjects\\pythonProject1\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\PC\\PycharmProjects\\pythonProject1\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\PC\\PycharmProjects\\pythonProject1\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\PC\\PycharmProjects\\pythonProject1\\.venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\PC\\PycharmProjects\\pythonProject1\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\PC\\PycharmProjects\\pythonProject1\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\PC\\PycharmProjects\\pythonProject1\\.venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\PC\\PycharmProjects\\pythonProject1\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\PC\\PycharmProjects\\pythonProject1\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\PC\\PycharmProjects\\pythonProject1\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_30668\\1296453242.py\", line 1, in <module>\n",
      "    import torch\n",
      "  File \"C:\\Users\\PC\\PycharmProjects\\pythonProject1\\.venv\\Lib\\site-packages\\torch\\__init__.py\", line 2120, in <module>\n",
      "    from torch._higher_order_ops import cond\n",
      "  File \"C:\\Users\\PC\\PycharmProjects\\pythonProject1\\.venv\\Lib\\site-packages\\torch\\_higher_order_ops\\__init__.py\", line 1, in <module>\n",
      "    from .cond import cond\n",
      "  File \"C:\\Users\\PC\\PycharmProjects\\pythonProject1\\.venv\\Lib\\site-packages\\torch\\_higher_order_ops\\cond.py\", line 5, in <module>\n",
      "    import torch._subclasses.functional_tensor\n",
      "  File \"C:\\Users\\PC\\PycharmProjects\\pythonProject1\\.venv\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py\", line 42, in <module>\n",
      "    class FunctionalTensor(torch.Tensor):\n",
      "  File \"C:\\Users\\PC\\PycharmProjects\\pythonProject1\\.venv\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py\", line 258, in FunctionalTensor\n",
      "    cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n",
      "C:\\Users\\PC\\PycharmProjects\\pythonProject1\\.venv\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:258: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Some weights of DebertaV2ForQuestionAnswering were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1/3\n",
      "Epoch [1/3], Batch [1/2500], Loss: 7.185484409332275\n",
      "Epoch [1/3], Batch [2/2500], Loss: 7.146399021148682\n",
      "Epoch [1/3], Batch [3/2500], Loss: 7.035147190093994\n",
      "Epoch [1/3], Batch [4/2500], Loss: 6.60031270980835\n",
      "Epoch [1/3], Batch [5/2500], Loss: 6.502469062805176\n",
      "Epoch [1/3], Batch [6/2500], Loss: 6.381110668182373\n",
      "Epoch [1/3], Batch [7/2500], Loss: 6.338171482086182\n",
      "Epoch [1/3], Batch [8/2500], Loss: 5.970200538635254\n",
      "Epoch [1/3], Batch [9/2500], Loss: 5.862594127655029\n",
      "Epoch [1/3], Batch [10/2500], Loss: 5.665922164916992\n",
      "Epoch [1/3], Batch [11/2500], Loss: 5.621922016143799\n",
      "Epoch [1/3], Batch [12/2500], Loss: 5.236872673034668\n",
      "Epoch [1/3], Batch [13/2500], Loss: 5.279245376586914\n",
      "Epoch [1/3], Batch [14/2500], Loss: 4.897632598876953\n",
      "Epoch [1/3], Batch [15/2500], Loss: 4.903325080871582\n",
      "Epoch [1/3], Batch [16/2500], Loss: 4.850433349609375\n",
      "Epoch [1/3], Batch [17/2500], Loss: 4.6417436599731445\n",
      "Epoch [1/3], Batch [18/2500], Loss: 4.565725326538086\n",
      "Epoch [1/3], Batch [19/2500], Loss: 4.514950275421143\n",
      "Epoch [1/3], Batch [20/2500], Loss: 4.232226848602295\n",
      "Epoch [1/3], Batch [21/2500], Loss: 4.1201558113098145\n",
      "Epoch [1/3], Batch [22/2500], Loss: 4.541397571563721\n",
      "Epoch [1/3], Batch [23/2500], Loss: 3.8463010787963867\n",
      "Epoch [1/3], Batch [24/2500], Loss: 3.886218547821045\n",
      "Epoch [1/3], Batch [25/2500], Loss: 3.840012550354004\n",
      "Epoch [1/3], Batch [26/2500], Loss: 3.770876884460449\n",
      "Epoch [1/3], Batch [27/2500], Loss: 3.4290690422058105\n",
      "Epoch [1/3], Batch [28/2500], Loss: 3.3467893600463867\n",
      "Epoch [1/3], Batch [29/2500], Loss: 3.0799472332000732\n",
      "Epoch [1/3], Batch [30/2500], Loss: 3.1494040489196777\n",
      "Epoch [1/3], Batch [31/2500], Loss: 2.74035382270813\n",
      "Epoch [1/3], Batch [32/2500], Loss: 2.9820868968963623\n",
      "Epoch [1/3], Batch [33/2500], Loss: 2.377131223678589\n",
      "Epoch [1/3], Batch [34/2500], Loss: 3.151538848876953\n",
      "Epoch [1/3], Batch [35/2500], Loss: 2.1979055404663086\n",
      "Epoch [1/3], Batch [36/2500], Loss: 2.126042604446411\n",
      "Epoch [1/3], Batch [37/2500], Loss: 1.8777977228164673\n",
      "Epoch [1/3], Batch [38/2500], Loss: 1.8884552717208862\n",
      "Epoch [1/3], Batch [39/2500], Loss: 2.4911305904388428\n",
      "Epoch [1/3], Batch [40/2500], Loss: 1.989190697669983\n",
      "Epoch [1/3], Batch [41/2500], Loss: 1.6920007467269897\n",
      "Epoch [1/3], Batch [42/2500], Loss: 1.4708795547485352\n",
      "Epoch [1/3], Batch [43/2500], Loss: 1.8168264627456665\n",
      "Epoch [1/3], Batch [44/2500], Loss: 1.395534873008728\n",
      "Epoch [1/3], Batch [45/2500], Loss: 1.1488280296325684\n",
      "Epoch [1/3], Batch [46/2500], Loss: 1.593252182006836\n",
      "Epoch [1/3], Batch [47/2500], Loss: 1.169374942779541\n",
      "Epoch [1/3], Batch [48/2500], Loss: 1.2780967950820923\n",
      "Epoch [1/3], Batch [49/2500], Loss: 0.8258799314498901\n",
      "Epoch [1/3], Batch [50/2500], Loss: 1.6276999711990356\n",
      "Epoch [1/3], Batch [51/2500], Loss: 1.343863844871521\n",
      "Epoch [1/3], Batch [52/2500], Loss: 1.8932292461395264\n",
      "Epoch [1/3], Batch [53/2500], Loss: 1.221483588218689\n",
      "Epoch [1/3], Batch [54/2500], Loss: 1.2270468473434448\n",
      "Epoch [1/3], Batch [55/2500], Loss: 1.3126804828643799\n",
      "Epoch [1/3], Batch [56/2500], Loss: 0.5061814785003662\n",
      "Epoch [1/3], Batch [57/2500], Loss: 0.5134695768356323\n",
      "Epoch [1/3], Batch [58/2500], Loss: 1.0708401203155518\n",
      "Epoch [1/3], Batch [59/2500], Loss: 0.4542509913444519\n",
      "Epoch [1/3], Batch [60/2500], Loss: 0.4835814833641052\n",
      "Epoch [1/3], Batch [61/2500], Loss: 1.74384605884552\n",
      "Epoch [1/3], Batch [62/2500], Loss: 1.4978057146072388\n",
      "Epoch [1/3], Batch [63/2500], Loss: 0.8859590888023376\n",
      "Epoch [1/3], Batch [64/2500], Loss: 0.502819299697876\n",
      "Epoch [1/3], Batch [65/2500], Loss: 0.33283206820487976\n",
      "Epoch [1/3], Batch [66/2500], Loss: 0.3105005621910095\n",
      "Epoch [1/3], Batch [67/2500], Loss: 0.3163803517818451\n",
      "Epoch [1/3], Batch [68/2500], Loss: 0.6698827743530273\n",
      "Epoch [1/3], Batch [69/2500], Loss: 1.4496196508407593\n",
      "Epoch [1/3], Batch [70/2500], Loss: 0.9420284032821655\n",
      "Epoch [1/3], Batch [71/2500], Loss: 0.5482603907585144\n",
      "Epoch [1/3], Batch [72/2500], Loss: 0.8524661660194397\n",
      "Epoch [1/3], Batch [73/2500], Loss: 0.6866298317909241\n",
      "Epoch [1/3], Batch [74/2500], Loss: 0.35174834728240967\n",
      "Epoch [1/3], Batch [75/2500], Loss: 0.3899856209754944\n",
      "Epoch [1/3], Batch [76/2500], Loss: 0.5652597546577454\n",
      "Epoch [1/3], Batch [77/2500], Loss: 0.4314396381378174\n",
      "Epoch [1/3], Batch [78/2500], Loss: 0.6568206548690796\n",
      "Epoch [1/3], Batch [79/2500], Loss: 0.3429252505302429\n",
      "Epoch [1/3], Batch [80/2500], Loss: 0.5193831920623779\n",
      "Epoch [1/3], Batch [81/2500], Loss: 0.8659690022468567\n",
      "Epoch [1/3], Batch [82/2500], Loss: 0.2646161615848541\n",
      "Epoch [1/3], Batch [83/2500], Loss: 0.8842054009437561\n",
      "Epoch [1/3], Batch [84/2500], Loss: 0.8773571848869324\n",
      "Epoch [1/3], Batch [85/2500], Loss: 0.5204835534095764\n",
      "Epoch [1/3], Batch [86/2500], Loss: 0.41386908292770386\n",
      "Epoch [1/3], Batch [87/2500], Loss: 0.307693213224411\n",
      "Epoch [1/3], Batch [88/2500], Loss: 0.32253387570381165\n",
      "Epoch [1/3], Batch [89/2500], Loss: 0.38031619787216187\n",
      "Epoch [1/3], Batch [90/2500], Loss: 0.22279226779937744\n",
      "Epoch [1/3], Batch [91/2500], Loss: 0.21414463222026825\n",
      "Epoch [1/3], Batch [92/2500], Loss: 0.18273715674877167\n",
      "Epoch [1/3], Batch [93/2500], Loss: 0.22478120028972626\n",
      "Epoch [1/3], Batch [94/2500], Loss: 0.6735917329788208\n",
      "Epoch [1/3], Batch [95/2500], Loss: 0.3617866635322571\n",
      "Epoch [1/3], Batch [96/2500], Loss: 0.20585498213768005\n",
      "Epoch [1/3], Batch [97/2500], Loss: 1.1611499786376953\n",
      "Epoch [1/3], Batch [98/2500], Loss: 0.8613059520721436\n",
      "Epoch [1/3], Batch [99/2500], Loss: 0.613136887550354\n",
      "Epoch [1/3], Batch [100/2500], Loss: 0.4604910612106323\n",
      "Epoch [1/3], Batch [101/2500], Loss: 0.27619388699531555\n",
      "Epoch [1/3], Batch [102/2500], Loss: 0.43150392174720764\n",
      "Epoch [1/3], Batch [103/2500], Loss: 0.5180233120918274\n",
      "Epoch [1/3], Batch [104/2500], Loss: 0.43302905559539795\n",
      "Epoch [1/3], Batch [105/2500], Loss: 0.6907510757446289\n",
      "Epoch [1/3], Batch [106/2500], Loss: 0.7138382196426392\n",
      "Epoch [1/3], Batch [107/2500], Loss: 0.4113800525665283\n",
      "Epoch [1/3], Batch [108/2500], Loss: 0.41560637950897217\n",
      "Epoch [1/3], Batch [109/2500], Loss: 0.9996623992919922\n",
      "Epoch [1/3], Batch [110/2500], Loss: 0.4619830250740051\n",
      "Epoch [1/3], Batch [111/2500], Loss: 0.44059741497039795\n",
      "Epoch [1/3], Batch [112/2500], Loss: 0.4430091381072998\n",
      "Epoch [1/3], Batch [113/2500], Loss: 0.37666669487953186\n",
      "Epoch [1/3], Batch [114/2500], Loss: 0.5073543787002563\n",
      "Epoch [1/3], Batch [115/2500], Loss: 0.3360876142978668\n",
      "Epoch [1/3], Batch [116/2500], Loss: 0.391839861869812\n",
      "Epoch [1/3], Batch [117/2500], Loss: 0.3163886070251465\n",
      "Epoch [1/3], Batch [118/2500], Loss: 0.306335985660553\n",
      "Epoch [1/3], Batch [119/2500], Loss: 0.32315120100975037\n",
      "Epoch [1/3], Batch [120/2500], Loss: 0.4509671926498413\n",
      "Epoch [1/3], Batch [121/2500], Loss: 0.7411277890205383\n",
      "Epoch [1/3], Batch [122/2500], Loss: 0.40591466426849365\n",
      "Epoch [1/3], Batch [123/2500], Loss: 0.30456358194351196\n",
      "Epoch [1/3], Batch [124/2500], Loss: 0.3088328242301941\n",
      "Epoch [1/3], Batch [125/2500], Loss: 0.6064932346343994\n",
      "Epoch [1/3], Batch [126/2500], Loss: 0.37701672315597534\n",
      "Epoch [1/3], Batch [127/2500], Loss: 0.3462805151939392\n",
      "Epoch [1/3], Batch [128/2500], Loss: 0.44603273272514343\n",
      "Epoch [1/3], Batch [129/2500], Loss: 0.5234506130218506\n",
      "Epoch [1/3], Batch [130/2500], Loss: 0.36062848567962646\n",
      "Epoch [1/3], Batch [131/2500], Loss: 1.2635746002197266\n",
      "Epoch [1/3], Batch [132/2500], Loss: 0.3788115084171295\n",
      "Epoch [1/3], Batch [133/2500], Loss: 0.4135558009147644\n",
      "Epoch [1/3], Batch [134/2500], Loss: 0.41091641783714294\n",
      "Epoch [1/3], Batch [135/2500], Loss: 0.25786736607551575\n",
      "Epoch [1/3], Batch [136/2500], Loss: 0.4225257635116577\n",
      "Epoch [1/3], Batch [137/2500], Loss: 0.36710837483406067\n",
      "Epoch [1/3], Batch [138/2500], Loss: 0.3327491581439972\n",
      "Epoch [1/3], Batch [139/2500], Loss: 0.3143826723098755\n",
      "Epoch [1/3], Batch [140/2500], Loss: 0.4964585304260254\n",
      "Epoch [1/3], Batch [141/2500], Loss: 0.40314173698425293\n",
      "Epoch [1/3], Batch [142/2500], Loss: 0.3052707314491272\n",
      "Epoch [1/3], Batch [143/2500], Loss: 0.5912303924560547\n",
      "Epoch [1/3], Batch [144/2500], Loss: 0.40133532881736755\n",
      "Epoch [1/3], Batch [145/2500], Loss: 0.42205849289894104\n",
      "Epoch [1/3], Batch [146/2500], Loss: 0.5350825786590576\n",
      "Epoch [1/3], Batch [147/2500], Loss: 0.5615813136100769\n",
      "Epoch [1/3], Batch [148/2500], Loss: 0.2409316748380661\n",
      "Epoch [1/3], Batch [149/2500], Loss: 0.2894212305545807\n",
      "Epoch [1/3], Batch [150/2500], Loss: 0.5876433253288269\n",
      "Epoch [1/3], Batch [151/2500], Loss: 0.27670997381210327\n",
      "Epoch [1/3], Batch [152/2500], Loss: 0.3116171061992645\n",
      "Epoch [1/3], Batch [153/2500], Loss: 0.24225452542304993\n",
      "Epoch [1/3], Batch [154/2500], Loss: 0.4220117926597595\n",
      "Epoch [1/3], Batch [155/2500], Loss: 0.39334172010421753\n",
      "Epoch [1/3], Batch [156/2500], Loss: 0.43623751401901245\n",
      "Epoch [1/3], Batch [157/2500], Loss: 0.32805219292640686\n",
      "Epoch [1/3], Batch [158/2500], Loss: 0.40916362404823303\n",
      "Epoch [1/3], Batch [159/2500], Loss: 0.3182690441608429\n",
      "Epoch [1/3], Batch [160/2500], Loss: 0.1882573366165161\n",
      "Epoch [1/3], Batch [161/2500], Loss: 0.5072333812713623\n",
      "Epoch [1/3], Batch [162/2500], Loss: 0.2099227011203766\n",
      "Epoch [1/3], Batch [163/2500], Loss: 0.3484182357788086\n",
      "Epoch [1/3], Batch [164/2500], Loss: 0.8605707883834839\n",
      "Epoch [1/3], Batch [165/2500], Loss: 0.2519044280052185\n",
      "Epoch [1/3], Batch [166/2500], Loss: 0.15633448958396912\n",
      "Epoch [1/3], Batch [167/2500], Loss: 0.26015880703926086\n",
      "Epoch [1/3], Batch [168/2500], Loss: 0.4923318922519684\n",
      "Epoch [1/3], Batch [169/2500], Loss: 0.7303555011749268\n",
      "Epoch [1/3], Batch [170/2500], Loss: 0.46581530570983887\n",
      "Epoch [1/3], Batch [171/2500], Loss: 0.22691452503204346\n",
      "Epoch [1/3], Batch [172/2500], Loss: 0.20982743799686432\n",
      "Epoch [1/3], Batch [173/2500], Loss: 0.3008091449737549\n",
      "Epoch [1/3], Batch [174/2500], Loss: 0.2603163421154022\n",
      "Epoch [1/3], Batch [175/2500], Loss: 0.4642915725708008\n",
      "Epoch [1/3], Batch [176/2500], Loss: 0.5800831317901611\n",
      "Epoch [1/3], Batch [177/2500], Loss: 0.2668176591396332\n",
      "Epoch [1/3], Batch [178/2500], Loss: 0.3548424243927002\n",
      "Epoch [1/3], Batch [179/2500], Loss: 0.3440159559249878\n",
      "Epoch [1/3], Batch [180/2500], Loss: 0.40769943594932556\n",
      "Epoch [1/3], Batch [181/2500], Loss: 0.48650282621383667\n",
      "Epoch [1/3], Batch [182/2500], Loss: 0.3825443387031555\n",
      "Epoch [1/3], Batch [183/2500], Loss: 0.43042799830436707\n",
      "Epoch [1/3], Batch [184/2500], Loss: 0.47706419229507446\n",
      "Epoch [1/3], Batch [185/2500], Loss: 0.25858765840530396\n",
      "Epoch [1/3], Batch [186/2500], Loss: 0.4095000624656677\n",
      "Epoch [1/3], Batch [187/2500], Loss: 0.4966161251068115\n",
      "Epoch [1/3], Batch [188/2500], Loss: 0.5158776640892029\n",
      "Epoch [1/3], Batch [189/2500], Loss: 0.4862702190876007\n",
      "Epoch [1/3], Batch [190/2500], Loss: 0.3742939531803131\n",
      "Epoch [1/3], Batch [191/2500], Loss: 0.4026607275009155\n",
      "Epoch [1/3], Batch [192/2500], Loss: 0.37285447120666504\n",
      "Epoch [1/3], Batch [193/2500], Loss: 0.44689470529556274\n",
      "Epoch [1/3], Batch [194/2500], Loss: 0.402976930141449\n",
      "Epoch [1/3], Batch [195/2500], Loss: 0.2866407334804535\n",
      "Epoch [1/3], Batch [196/2500], Loss: 0.40402573347091675\n",
      "Epoch [1/3], Batch [197/2500], Loss: 0.2835789918899536\n",
      "Epoch [1/3], Batch [198/2500], Loss: 0.3392874002456665\n",
      "Epoch [1/3], Batch [199/2500], Loss: 0.3874000012874603\n",
      "Epoch [1/3], Batch [200/2500], Loss: 0.3036017119884491\n",
      "Epoch [1/3], Batch [201/2500], Loss: 0.43085983395576477\n",
      "Epoch [1/3], Batch [202/2500], Loss: 0.4328419268131256\n",
      "Epoch [1/3], Batch [203/2500], Loss: 0.3551467955112457\n",
      "Epoch [1/3], Batch [204/2500], Loss: 0.302912175655365\n",
      "Epoch [1/3], Batch [205/2500], Loss: 0.3191940188407898\n",
      "Epoch [1/3], Batch [206/2500], Loss: 0.38389623165130615\n",
      "Epoch [1/3], Batch [207/2500], Loss: 0.3431106507778168\n",
      "Epoch [1/3], Batch [208/2500], Loss: 0.2476367950439453\n",
      "Epoch [1/3], Batch [209/2500], Loss: 0.33407700061798096\n",
      "Epoch [1/3], Batch [210/2500], Loss: 0.44636353850364685\n",
      "Epoch [1/3], Batch [211/2500], Loss: 0.3357354998588562\n",
      "Epoch [1/3], Batch [212/2500], Loss: 0.398732990026474\n",
      "Epoch [1/3], Batch [213/2500], Loss: 0.20302727818489075\n",
      "Epoch [1/3], Batch [214/2500], Loss: 0.1397857666015625\n",
      "Epoch [1/3], Batch [215/2500], Loss: 0.438161164522171\n",
      "Epoch [1/3], Batch [216/2500], Loss: 0.39168810844421387\n",
      "Epoch [1/3], Batch [217/2500], Loss: 0.373481810092926\n",
      "Epoch [1/3], Batch [218/2500], Loss: 0.3679201006889343\n",
      "Epoch [1/3], Batch [219/2500], Loss: 0.2851731777191162\n",
      "Epoch [1/3], Batch [220/2500], Loss: 0.1434018909931183\n",
      "Epoch [1/3], Batch [221/2500], Loss: 0.3527829647064209\n",
      "Epoch [1/3], Batch [222/2500], Loss: 0.5213235020637512\n",
      "Epoch [1/3], Batch [223/2500], Loss: 0.47196924686431885\n",
      "Epoch [1/3], Batch [224/2500], Loss: 0.12322060018777847\n",
      "Epoch [1/3], Batch [225/2500], Loss: 0.30675068497657776\n",
      "Epoch [1/3], Batch [226/2500], Loss: 0.5037696361541748\n",
      "Epoch [1/3], Batch [227/2500], Loss: 0.4269843101501465\n",
      "Epoch [1/3], Batch [228/2500], Loss: 0.3576914668083191\n",
      "Epoch [1/3], Batch [229/2500], Loss: 0.3012514114379883\n",
      "Epoch [1/3], Batch [230/2500], Loss: 0.14798900485038757\n",
      "Epoch [1/3], Batch [231/2500], Loss: 0.1912379264831543\n",
      "Epoch [1/3], Batch [232/2500], Loss: 0.19447769224643707\n",
      "Epoch [1/3], Batch [233/2500], Loss: 0.26070207357406616\n",
      "Epoch [1/3], Batch [234/2500], Loss: 0.5988620519638062\n",
      "Epoch [1/3], Batch [235/2500], Loss: 0.16266514360904694\n",
      "Epoch [1/3], Batch [236/2500], Loss: 0.3933275043964386\n",
      "Epoch [1/3], Batch [237/2500], Loss: 0.3395920693874359\n",
      "Epoch [1/3], Batch [238/2500], Loss: 0.27236318588256836\n",
      "Epoch [1/3], Batch [239/2500], Loss: 0.11119545251131058\n",
      "Epoch [1/3], Batch [240/2500], Loss: 0.41154739260673523\n",
      "Epoch [1/3], Batch [241/2500], Loss: 0.1545102894306183\n",
      "Epoch [1/3], Batch [242/2500], Loss: 0.5739187002182007\n",
      "Epoch [1/3], Batch [243/2500], Loss: 0.44908037781715393\n",
      "Epoch [1/3], Batch [244/2500], Loss: 0.3340013921260834\n",
      "Epoch [1/3], Batch [245/2500], Loss: 0.1580663025379181\n",
      "Epoch [1/3], Batch [246/2500], Loss: 0.46459344029426575\n",
      "Epoch [1/3], Batch [247/2500], Loss: 0.4813166558742523\n",
      "Epoch [1/3], Batch [248/2500], Loss: 0.3250207006931305\n",
      "Epoch [1/3], Batch [249/2500], Loss: 0.295687735080719\n",
      "Epoch [1/3], Batch [250/2500], Loss: 0.3416762053966522\n",
      "Epoch [1/3], Batch [251/2500], Loss: 0.615391194820404\n",
      "Epoch [1/3], Batch [252/2500], Loss: 0.33030933141708374\n",
      "Epoch [1/3], Batch [253/2500], Loss: 0.2610330581665039\n",
      "Epoch [1/3], Batch [254/2500], Loss: 0.4285438656806946\n",
      "Epoch [1/3], Batch [255/2500], Loss: 0.4381330609321594\n",
      "Epoch [1/3], Batch [256/2500], Loss: 0.37474510073661804\n",
      "Epoch [1/3], Batch [257/2500], Loss: 0.36400794982910156\n",
      "Epoch [1/3], Batch [258/2500], Loss: 0.40907421708106995\n",
      "Epoch [1/3], Batch [259/2500], Loss: 0.280398428440094\n",
      "Epoch [1/3], Batch [260/2500], Loss: 0.29967600107192993\n",
      "Epoch [1/3], Batch [261/2500], Loss: 0.3793722987174988\n",
      "Epoch [1/3], Batch [262/2500], Loss: 0.39543649554252625\n",
      "Epoch [1/3], Batch [263/2500], Loss: 0.37306123971939087\n",
      "Epoch [1/3], Batch [264/2500], Loss: 0.22700436413288116\n",
      "Epoch [1/3], Batch [265/2500], Loss: 0.5275276899337769\n",
      "Epoch [1/3], Batch [266/2500], Loss: 0.4037712812423706\n",
      "Epoch [1/3], Batch [267/2500], Loss: 0.29709339141845703\n",
      "Epoch [1/3], Batch [268/2500], Loss: 0.2618621289730072\n",
      "Epoch [1/3], Batch [269/2500], Loss: 0.32464954257011414\n",
      "Epoch [1/3], Batch [270/2500], Loss: 0.49091941118240356\n",
      "Epoch [1/3], Batch [271/2500], Loss: 0.38384103775024414\n",
      "Epoch [1/3], Batch [272/2500], Loss: 0.15372414886951447\n",
      "Epoch [1/3], Batch [273/2500], Loss: 0.5341129302978516\n",
      "Epoch [1/3], Batch [274/2500], Loss: 0.20912683010101318\n",
      "Epoch [1/3], Batch [275/2500], Loss: 0.2665875256061554\n",
      "Epoch [1/3], Batch [276/2500], Loss: 0.3263014554977417\n",
      "Epoch [1/3], Batch [277/2500], Loss: 0.14107973873615265\n",
      "Epoch [1/3], Batch [278/2500], Loss: 0.11206957697868347\n",
      "Epoch [1/3], Batch [279/2500], Loss: 0.5872609615325928\n",
      "Epoch [1/3], Batch [280/2500], Loss: 0.31367045640945435\n",
      "Epoch [1/3], Batch [281/2500], Loss: 0.16700759530067444\n",
      "Epoch [1/3], Batch [282/2500], Loss: 0.34832054376602173\n",
      "Epoch [1/3], Batch [283/2500], Loss: 0.13422858715057373\n",
      "Epoch [1/3], Batch [284/2500], Loss: 0.4438241422176361\n",
      "Epoch [1/3], Batch [285/2500], Loss: 0.5252330899238586\n",
      "Epoch [1/3], Batch [286/2500], Loss: 0.2865850627422333\n",
      "Epoch [1/3], Batch [287/2500], Loss: 0.2340390682220459\n",
      "Epoch [1/3], Batch [288/2500], Loss: 0.23023486137390137\n",
      "Epoch [1/3], Batch [289/2500], Loss: 0.21863317489624023\n",
      "Epoch [1/3], Batch [290/2500], Loss: 0.2546815574169159\n",
      "Epoch [1/3], Batch [291/2500], Loss: 0.418609082698822\n",
      "Epoch [1/3], Batch [292/2500], Loss: 0.2345103621482849\n",
      "Epoch [1/3], Batch [293/2500], Loss: 0.6162012219429016\n",
      "Epoch [1/3], Batch [294/2500], Loss: 0.34497058391571045\n",
      "Epoch [1/3], Batch [295/2500], Loss: 0.2924222946166992\n",
      "Epoch [1/3], Batch [296/2500], Loss: 0.355327844619751\n",
      "Epoch [1/3], Batch [297/2500], Loss: 0.3634616732597351\n",
      "Epoch [1/3], Batch [298/2500], Loss: 0.38950175046920776\n",
      "Epoch [1/3], Batch [299/2500], Loss: 0.2785399258136749\n",
      "Epoch [1/3], Batch [300/2500], Loss: 0.4089823365211487\n",
      "Epoch [1/3], Batch [301/2500], Loss: 0.4075952172279358\n",
      "Epoch [1/3], Batch [302/2500], Loss: 0.3292747139930725\n",
      "Epoch [1/3], Batch [303/2500], Loss: 0.42914485931396484\n",
      "Epoch [1/3], Batch [304/2500], Loss: 0.45611608028411865\n",
      "Epoch [1/3], Batch [305/2500], Loss: 0.41122981905937195\n",
      "Epoch [1/3], Batch [306/2500], Loss: 0.3694518804550171\n",
      "Epoch [1/3], Batch [307/2500], Loss: 0.3274245858192444\n",
      "Epoch [1/3], Batch [308/2500], Loss: 0.5468968749046326\n",
      "Epoch [1/3], Batch [309/2500], Loss: 0.30082669854164124\n",
      "Epoch [1/3], Batch [310/2500], Loss: 0.340999037027359\n",
      "Epoch [1/3], Batch [311/2500], Loss: 0.44844645261764526\n",
      "Epoch [1/3], Batch [312/2500], Loss: 0.23657700419425964\n",
      "Epoch [1/3], Batch [313/2500], Loss: 0.46859267354011536\n",
      "Epoch [1/3], Batch [314/2500], Loss: 0.4980936646461487\n",
      "Epoch [1/3], Batch [315/2500], Loss: 0.1811625361442566\n",
      "Epoch [1/3], Batch [316/2500], Loss: 0.4209732115268707\n",
      "Epoch [1/3], Batch [317/2500], Loss: 0.3817564845085144\n",
      "Epoch [1/3], Batch [318/2500], Loss: 0.24090956151485443\n",
      "Epoch [1/3], Batch [319/2500], Loss: 0.1750769168138504\n",
      "Epoch [1/3], Batch [320/2500], Loss: 0.7792375683784485\n",
      "Epoch [1/3], Batch [321/2500], Loss: 0.500425398349762\n",
      "Epoch [1/3], Batch [322/2500], Loss: 0.3887123465538025\n",
      "Epoch [1/3], Batch [323/2500], Loss: 0.2650371789932251\n",
      "Epoch [1/3], Batch [324/2500], Loss: 0.20571646094322205\n",
      "Epoch [1/3], Batch [325/2500], Loss: 0.3906741440296173\n",
      "Epoch [1/3], Batch [326/2500], Loss: 0.38642418384552\n",
      "Epoch [1/3], Batch [327/2500], Loss: 0.2873854637145996\n",
      "Epoch [1/3], Batch [328/2500], Loss: 0.39120644330978394\n",
      "Epoch [1/3], Batch [329/2500], Loss: 0.16426080465316772\n",
      "Epoch [1/3], Batch [330/2500], Loss: 0.15283004939556122\n",
      "Epoch [1/3], Batch [331/2500], Loss: 0.32716459035873413\n",
      "Epoch [1/3], Batch [332/2500], Loss: 0.3940078318119049\n",
      "Epoch [1/3], Batch [333/2500], Loss: 0.47237589955329895\n",
      "Epoch [1/3], Batch [334/2500], Loss: 0.5206883549690247\n",
      "Epoch [1/3], Batch [335/2500], Loss: 0.3402608036994934\n",
      "Epoch [1/3], Batch [336/2500], Loss: 0.25887641310691833\n",
      "Epoch [1/3], Batch [337/2500], Loss: 0.2221166342496872\n",
      "Epoch [1/3], Batch [338/2500], Loss: 0.38554131984710693\n",
      "Epoch [1/3], Batch [339/2500], Loss: 0.570435643196106\n",
      "Epoch [1/3], Batch [340/2500], Loss: 0.3796864449977875\n",
      "Epoch [1/3], Batch [341/2500], Loss: 0.31737038493156433\n",
      "Epoch [1/3], Batch [342/2500], Loss: 0.34593328833580017\n",
      "Epoch [1/3], Batch [343/2500], Loss: 0.363502562046051\n",
      "Epoch [1/3], Batch [344/2500], Loss: 0.23478370904922485\n",
      "Epoch [1/3], Batch [345/2500], Loss: 0.22018581628799438\n",
      "Epoch [1/3], Batch [346/2500], Loss: 0.24341949820518494\n",
      "Epoch [1/3], Batch [347/2500], Loss: 0.35757508873939514\n",
      "Epoch [1/3], Batch [348/2500], Loss: 0.2720044255256653\n",
      "Epoch [1/3], Batch [349/2500], Loss: 0.2948669493198395\n",
      "Epoch [1/3], Batch [350/2500], Loss: 0.3435165286064148\n",
      "Epoch [1/3], Batch [351/2500], Loss: 0.4051499664783478\n",
      "Epoch [1/3], Batch [352/2500], Loss: 0.4015641212463379\n",
      "Epoch [1/3], Batch [353/2500], Loss: 0.3443535268306732\n",
      "Epoch [1/3], Batch [354/2500], Loss: 0.2908564805984497\n",
      "Epoch [1/3], Batch [355/2500], Loss: 0.41628897190093994\n",
      "Epoch [1/3], Batch [356/2500], Loss: 0.11630550026893616\n",
      "Epoch [1/3], Batch [357/2500], Loss: 0.2379387468099594\n",
      "Epoch [1/3], Batch [358/2500], Loss: 0.33673498034477234\n",
      "Epoch [1/3], Batch [359/2500], Loss: 0.22829459607601166\n",
      "Epoch [1/3], Batch [360/2500], Loss: 0.2322530448436737\n",
      "Epoch [1/3], Batch [361/2500], Loss: 0.12881764769554138\n",
      "Epoch [1/3], Batch [362/2500], Loss: 0.5660783052444458\n",
      "Epoch [1/3], Batch [363/2500], Loss: 0.42554864287376404\n",
      "Epoch [1/3], Batch [364/2500], Loss: 0.43766042590141296\n",
      "Epoch [1/3], Batch [365/2500], Loss: 0.4959879517555237\n",
      "Epoch [1/3], Batch [366/2500], Loss: 0.4322342872619629\n",
      "Epoch [1/3], Batch [367/2500], Loss: 0.27385056018829346\n",
      "Epoch [1/3], Batch [368/2500], Loss: 0.2819138169288635\n",
      "Epoch [1/3], Batch [369/2500], Loss: 0.214758038520813\n",
      "Epoch [1/3], Batch [370/2500], Loss: 0.23389585316181183\n",
      "Epoch [1/3], Batch [371/2500], Loss: 0.5504310131072998\n",
      "Epoch [1/3], Batch [372/2500], Loss: 0.3012135326862335\n",
      "Epoch [1/3], Batch [373/2500], Loss: 0.43613797426223755\n",
      "Epoch [1/3], Batch [374/2500], Loss: 0.25158223509788513\n",
      "Epoch [1/3], Batch [375/2500], Loss: 0.3415733575820923\n",
      "Epoch [1/3], Batch [376/2500], Loss: 0.2263096421957016\n",
      "Epoch [1/3], Batch [377/2500], Loss: 0.3030214011669159\n",
      "Epoch [1/3], Batch [378/2500], Loss: 0.5118285417556763\n",
      "Epoch [1/3], Batch [379/2500], Loss: 0.38143616914749146\n",
      "Epoch [1/3], Batch [380/2500], Loss: 0.3505871295928955\n",
      "Epoch [1/3], Batch [381/2500], Loss: 0.3982706069946289\n",
      "Epoch [1/3], Batch [382/2500], Loss: 0.4412073493003845\n",
      "Epoch [1/3], Batch [383/2500], Loss: 0.3378918170928955\n",
      "Epoch [1/3], Batch [384/2500], Loss: 0.3845985233783722\n",
      "Epoch [1/3], Batch [385/2500], Loss: 0.23537638783454895\n",
      "Epoch [1/3], Batch [386/2500], Loss: 0.3264082670211792\n",
      "Epoch [1/3], Batch [387/2500], Loss: 0.5256138443946838\n",
      "Epoch [1/3], Batch [388/2500], Loss: 0.37626686692237854\n",
      "Epoch [1/3], Batch [389/2500], Loss: 0.3435952067375183\n",
      "Epoch [1/3], Batch [390/2500], Loss: 0.39291566610336304\n",
      "Epoch [1/3], Batch [391/2500], Loss: 0.3947988748550415\n",
      "Epoch [1/3], Batch [392/2500], Loss: 0.24143584072589874\n",
      "Epoch [1/3], Batch [393/2500], Loss: 0.34448665380477905\n",
      "Epoch [1/3], Batch [394/2500], Loss: 0.24152304232120514\n",
      "Epoch [1/3], Batch [395/2500], Loss: 0.3294743001461029\n",
      "Epoch [1/3], Batch [396/2500], Loss: 0.2673315405845642\n",
      "Epoch [1/3], Batch [397/2500], Loss: 0.41229310631752014\n",
      "Epoch [1/3], Batch [398/2500], Loss: 0.46256425976753235\n",
      "Epoch [1/3], Batch [399/2500], Loss: 0.3435421288013458\n",
      "Epoch [1/3], Batch [400/2500], Loss: 0.20156195759773254\n",
      "Epoch [1/3], Batch [401/2500], Loss: 0.2562410235404968\n",
      "Epoch [1/3], Batch [402/2500], Loss: 0.5151479840278625\n",
      "Epoch [1/3], Batch [403/2500], Loss: 0.2924847900867462\n",
      "Epoch [1/3], Batch [404/2500], Loss: 0.5923536419868469\n",
      "Epoch [1/3], Batch [405/2500], Loss: 0.24163959920406342\n",
      "Epoch [1/3], Batch [406/2500], Loss: 0.33410707116127014\n",
      "Epoch [1/3], Batch [407/2500], Loss: 0.4746975302696228\n",
      "Epoch [1/3], Batch [408/2500], Loss: 0.26894256472587585\n",
      "Epoch [1/3], Batch [409/2500], Loss: 0.2610822021961212\n",
      "Epoch [1/3], Batch [410/2500], Loss: 0.2957517206668854\n",
      "Epoch [1/3], Batch [411/2500], Loss: 0.46423283219337463\n",
      "Epoch [1/3], Batch [412/2500], Loss: 0.3276296555995941\n",
      "Epoch [1/3], Batch [413/2500], Loss: 0.2938087582588196\n",
      "Epoch [1/3], Batch [414/2500], Loss: 0.22064325213432312\n",
      "Epoch [1/3], Batch [415/2500], Loss: 0.27981123328208923\n",
      "Epoch [1/3], Batch [416/2500], Loss: 0.2924799919128418\n",
      "Epoch [1/3], Batch [417/2500], Loss: 0.2413090467453003\n",
      "Epoch [1/3], Batch [418/2500], Loss: 0.39021405577659607\n",
      "Epoch [1/3], Batch [419/2500], Loss: 0.46238651871681213\n",
      "Epoch [1/3], Batch [420/2500], Loss: 0.4463476240634918\n",
      "Epoch [1/3], Batch [421/2500], Loss: 0.3948669135570526\n",
      "Epoch [1/3], Batch [422/2500], Loss: 0.4213975667953491\n",
      "Epoch [1/3], Batch [423/2500], Loss: 0.26436418294906616\n",
      "Epoch [1/3], Batch [424/2500], Loss: 0.2216779589653015\n",
      "Epoch [1/3], Batch [425/2500], Loss: 0.2797295153141022\n",
      "Epoch [1/3], Batch [426/2500], Loss: 0.31639498472213745\n",
      "Epoch [1/3], Batch [427/2500], Loss: 0.37969422340393066\n",
      "Epoch [1/3], Batch [428/2500], Loss: 0.3929547965526581\n",
      "Epoch [1/3], Batch [429/2500], Loss: 0.3793659210205078\n",
      "Epoch [1/3], Batch [430/2500], Loss: 0.6877854466438293\n",
      "Epoch [1/3], Batch [431/2500], Loss: 0.37678438425064087\n",
      "Epoch [1/3], Batch [432/2500], Loss: 0.27562880516052246\n",
      "Epoch [1/3], Batch [433/2500], Loss: 0.2581191062927246\n",
      "Epoch [1/3], Batch [434/2500], Loss: 0.20487090945243835\n",
      "Epoch [1/3], Batch [435/2500], Loss: 0.4625622630119324\n",
      "Epoch [1/3], Batch [436/2500], Loss: 0.48272448778152466\n",
      "Epoch [1/3], Batch [437/2500], Loss: 0.314449280500412\n",
      "Epoch [1/3], Batch [438/2500], Loss: 0.30193063616752625\n",
      "Epoch [1/3], Batch [439/2500], Loss: 0.44438597559928894\n",
      "Epoch [1/3], Batch [440/2500], Loss: 0.2514861822128296\n",
      "Epoch [1/3], Batch [441/2500], Loss: 0.5864176154136658\n",
      "Epoch [1/3], Batch [442/2500], Loss: 0.20153012871742249\n",
      "Epoch [1/3], Batch [443/2500], Loss: 0.3589126765727997\n",
      "Epoch [1/3], Batch [444/2500], Loss: 0.36777693033218384\n",
      "Epoch [1/3], Batch [445/2500], Loss: 0.2075696438550949\n",
      "Epoch [1/3], Batch [446/2500], Loss: 0.26066842675209045\n",
      "Epoch [1/3], Batch [447/2500], Loss: 0.3744739592075348\n",
      "Epoch [1/3], Batch [448/2500], Loss: 0.4980395436286926\n",
      "Epoch [1/3], Batch [449/2500], Loss: 0.5607521533966064\n",
      "Epoch [1/3], Batch [450/2500], Loss: 0.4030361473560333\n",
      "Epoch [1/3], Batch [451/2500], Loss: 0.5707352161407471\n",
      "Epoch [1/3], Batch [452/2500], Loss: 0.37823668122291565\n",
      "Epoch [1/3], Batch [453/2500], Loss: 0.34535059332847595\n",
      "Epoch [1/3], Batch [454/2500], Loss: 0.3323904871940613\n",
      "Epoch [1/3], Batch [455/2500], Loss: 0.3180493712425232\n",
      "Epoch [1/3], Batch [456/2500], Loss: 0.4520043730735779\n",
      "Epoch [1/3], Batch [457/2500], Loss: 0.40817609429359436\n",
      "Epoch [1/3], Batch [458/2500], Loss: 0.3446369767189026\n",
      "Epoch [1/3], Batch [459/2500], Loss: 0.27862781286239624\n",
      "Epoch [1/3], Batch [460/2500], Loss: 0.33996081352233887\n",
      "Epoch [1/3], Batch [461/2500], Loss: 0.5671284794807434\n",
      "Epoch [1/3], Batch [462/2500], Loss: 0.20737871527671814\n",
      "Epoch [1/3], Batch [463/2500], Loss: 0.21863746643066406\n",
      "Epoch [1/3], Batch [464/2500], Loss: 0.18811927735805511\n",
      "Epoch [1/3], Batch [465/2500], Loss: 0.4818308651447296\n",
      "Epoch [1/3], Batch [466/2500], Loss: 0.32269585132598877\n",
      "Epoch [1/3], Batch [467/2500], Loss: 0.8031682372093201\n",
      "Epoch [1/3], Batch [468/2500], Loss: 0.2705347537994385\n",
      "Epoch [1/3], Batch [469/2500], Loss: 0.28914421796798706\n",
      "Epoch [1/3], Batch [470/2500], Loss: 0.45871660113334656\n",
      "Epoch [1/3], Batch [471/2500], Loss: 0.3425408601760864\n",
      "Epoch [1/3], Batch [472/2500], Loss: 0.16399675607681274\n",
      "Epoch [1/3], Batch [473/2500], Loss: 0.4362335503101349\n",
      "Epoch [1/3], Batch [474/2500], Loss: 0.32192903757095337\n",
      "Epoch [1/3], Batch [475/2500], Loss: 0.14808478951454163\n",
      "Epoch [1/3], Batch [476/2500], Loss: 0.5654650926589966\n",
      "Epoch [1/3], Batch [477/2500], Loss: 0.13704484701156616\n",
      "Epoch [1/3], Batch [478/2500], Loss: 0.6580180525779724\n",
      "Epoch [1/3], Batch [479/2500], Loss: 0.22975529730319977\n",
      "Epoch [1/3], Batch [480/2500], Loss: 0.5285834074020386\n",
      "Epoch [1/3], Batch [481/2500], Loss: 0.2840365767478943\n",
      "Epoch [1/3], Batch [482/2500], Loss: 0.3952520787715912\n",
      "Epoch [1/3], Batch [483/2500], Loss: 0.39466214179992676\n",
      "Epoch [1/3], Batch [484/2500], Loss: 0.38773930072784424\n",
      "Epoch [1/3], Batch [485/2500], Loss: 0.3643408417701721\n",
      "Epoch [1/3], Batch [486/2500], Loss: 0.5110299587249756\n",
      "Epoch [1/3], Batch [487/2500], Loss: 0.4117445945739746\n",
      "Epoch [1/3], Batch [488/2500], Loss: 0.36822834610939026\n",
      "Epoch [1/3], Batch [489/2500], Loss: 0.27677595615386963\n",
      "Epoch [1/3], Batch [490/2500], Loss: 0.38014885783195496\n",
      "Epoch [1/3], Batch [491/2500], Loss: 0.4477574825286865\n",
      "Epoch [1/3], Batch [492/2500], Loss: 0.27859601378440857\n",
      "Epoch [1/3], Batch [493/2500], Loss: 0.39544764161109924\n",
      "Epoch [1/3], Batch [494/2500], Loss: 0.4249430000782013\n",
      "Epoch [1/3], Batch [495/2500], Loss: 0.237163245677948\n",
      "Epoch [1/3], Batch [496/2500], Loss: 0.21943198144435883\n",
      "Epoch [1/3], Batch [497/2500], Loss: 0.1939089149236679\n",
      "Epoch [1/3], Batch [498/2500], Loss: 0.5119238495826721\n",
      "Epoch [1/3], Batch [499/2500], Loss: 0.14218121767044067\n",
      "Epoch [1/3], Batch [500/2500], Loss: 0.543560266494751\n",
      "Epoch [1/3], Batch [501/2500], Loss: 0.4169071912765503\n",
      "Epoch [1/3], Batch [502/2500], Loss: 0.5236812829971313\n",
      "Epoch [1/3], Batch [503/2500], Loss: 0.3132033050060272\n",
      "Epoch [1/3], Batch [504/2500], Loss: 0.42401444911956787\n",
      "Epoch [1/3], Batch [505/2500], Loss: 0.5191691517829895\n",
      "Epoch [1/3], Batch [506/2500], Loss: 0.5096091628074646\n",
      "Epoch [1/3], Batch [507/2500], Loss: 0.3521439731121063\n",
      "Epoch [1/3], Batch [508/2500], Loss: 0.21727527678012848\n",
      "Epoch [1/3], Batch [509/2500], Loss: 0.32438045740127563\n",
      "Epoch [1/3], Batch [510/2500], Loss: 0.47066840529441833\n",
      "Epoch [1/3], Batch [511/2500], Loss: 0.2972520589828491\n",
      "Epoch [1/3], Batch [512/2500], Loss: 0.3020535707473755\n",
      "Epoch [1/3], Batch [513/2500], Loss: 0.35901162028312683\n",
      "Epoch [1/3], Batch [514/2500], Loss: 0.33829089999198914\n",
      "Epoch [1/3], Batch [515/2500], Loss: 0.2897489368915558\n",
      "Epoch [1/3], Batch [516/2500], Loss: 0.30246415734291077\n",
      "Epoch [1/3], Batch [517/2500], Loss: 0.4078354835510254\n",
      "Epoch [1/3], Batch [518/2500], Loss: 0.4034687578678131\n",
      "Epoch [1/3], Batch [519/2500], Loss: 0.3195419907569885\n",
      "Epoch [1/3], Batch [520/2500], Loss: 0.2809253931045532\n",
      "Epoch [1/3], Batch [521/2500], Loss: 0.3859001398086548\n",
      "Epoch [1/3], Batch [522/2500], Loss: 0.3056676983833313\n",
      "Epoch [1/3], Batch [523/2500], Loss: 0.49129149317741394\n",
      "Epoch [1/3], Batch [524/2500], Loss: 0.4182284474372864\n",
      "Epoch [1/3], Batch [525/2500], Loss: 0.48253971338272095\n",
      "Epoch [1/3], Batch [526/2500], Loss: 0.4196796119213104\n",
      "Epoch [1/3], Batch [527/2500], Loss: 0.5355290770530701\n",
      "Epoch [1/3], Batch [528/2500], Loss: 0.31642603874206543\n",
      "Epoch [1/3], Batch [529/2500], Loss: 0.34791675209999084\n",
      "Epoch [1/3], Batch [530/2500], Loss: 0.28450900316238403\n",
      "Epoch [1/3], Batch [531/2500], Loss: 0.34840747714042664\n",
      "Epoch [1/3], Batch [532/2500], Loss: 0.5143193602561951\n",
      "Epoch [1/3], Batch [533/2500], Loss: 0.40933042764663696\n",
      "Epoch [1/3], Batch [534/2500], Loss: 0.1934053599834442\n",
      "Epoch [1/3], Batch [535/2500], Loss: 0.3096824586391449\n",
      "Epoch [1/3], Batch [536/2500], Loss: 0.24346773326396942\n",
      "Epoch [1/3], Batch [537/2500], Loss: 0.4120103120803833\n",
      "Epoch [1/3], Batch [538/2500], Loss: 0.19256989657878876\n",
      "Epoch [1/3], Batch [539/2500], Loss: 0.33025187253952026\n",
      "Epoch [1/3], Batch [540/2500], Loss: 0.4714321792125702\n",
      "Epoch [1/3], Batch [541/2500], Loss: 0.2720542848110199\n",
      "Epoch [1/3], Batch [542/2500], Loss: 0.4608231484889984\n",
      "Epoch [1/3], Batch [543/2500], Loss: 0.47679585218429565\n",
      "Epoch [1/3], Batch [544/2500], Loss: 0.19694016873836517\n",
      "Epoch [1/3], Batch [545/2500], Loss: 0.2775161564350128\n",
      "Epoch [1/3], Batch [546/2500], Loss: 0.5941512584686279\n",
      "Epoch [1/3], Batch [547/2500], Loss: 0.2260703593492508\n",
      "Epoch [1/3], Batch [548/2500], Loss: 0.4563944339752197\n",
      "Epoch [1/3], Batch [549/2500], Loss: 0.2972108721733093\n",
      "Epoch [1/3], Batch [550/2500], Loss: 0.28577786684036255\n",
      "Epoch [1/3], Batch [551/2500], Loss: 0.38883909583091736\n",
      "Epoch [1/3], Batch [552/2500], Loss: 0.35731810331344604\n",
      "Epoch [1/3], Batch [553/2500], Loss: 0.3517065942287445\n",
      "Epoch [1/3], Batch [554/2500], Loss: 0.2529882490634918\n",
      "Epoch [1/3], Batch [555/2500], Loss: 0.300960510969162\n",
      "Epoch [1/3], Batch [556/2500], Loss: 0.3572915196418762\n",
      "Epoch [1/3], Batch [557/2500], Loss: 0.2904128134250641\n",
      "Epoch [1/3], Batch [558/2500], Loss: 0.28176143765449524\n",
      "Epoch [1/3], Batch [559/2500], Loss: 0.31262168288230896\n",
      "Epoch [1/3], Batch [560/2500], Loss: 0.33278417587280273\n",
      "Epoch [1/3], Batch [561/2500], Loss: 0.5382606983184814\n",
      "Epoch [1/3], Batch [562/2500], Loss: 0.26681387424468994\n",
      "Epoch [1/3], Batch [563/2500], Loss: 0.22720937430858612\n",
      "Epoch [1/3], Batch [564/2500], Loss: 0.2726929187774658\n",
      "Epoch [1/3], Batch [565/2500], Loss: 0.24139750003814697\n",
      "Epoch [1/3], Batch [566/2500], Loss: 0.3019177317619324\n",
      "Epoch [1/3], Batch [567/2500], Loss: 0.39700615406036377\n",
      "Epoch [1/3], Batch [568/2500], Loss: 0.21046726405620575\n",
      "Epoch [1/3], Batch [569/2500], Loss: 0.3672636151313782\n",
      "Epoch [1/3], Batch [570/2500], Loss: 0.4441518783569336\n",
      "Epoch [1/3], Batch [571/2500], Loss: 0.2808360457420349\n",
      "Epoch [1/3], Batch [572/2500], Loss: 0.16130289435386658\n",
      "Epoch [1/3], Batch [573/2500], Loss: 0.4284781813621521\n",
      "Epoch [1/3], Batch [574/2500], Loss: 0.22168822586536407\n",
      "Epoch [1/3], Batch [575/2500], Loss: 0.3816601634025574\n",
      "Epoch [1/3], Batch [576/2500], Loss: 0.21728560328483582\n",
      "Epoch [1/3], Batch [577/2500], Loss: 0.48470166325569153\n",
      "Epoch [1/3], Batch [578/2500], Loss: 0.4328726530075073\n",
      "Epoch [1/3], Batch [579/2500], Loss: 0.3538750410079956\n",
      "Epoch [1/3], Batch [580/2500], Loss: 0.18113461136817932\n",
      "Epoch [1/3], Batch [581/2500], Loss: 0.38237830996513367\n",
      "Epoch [1/3], Batch [582/2500], Loss: 0.32134735584259033\n",
      "Epoch [1/3], Batch [583/2500], Loss: 0.5041159391403198\n",
      "Epoch [1/3], Batch [584/2500], Loss: 0.3135012984275818\n",
      "Epoch [1/3], Batch [585/2500], Loss: 0.22370241582393646\n",
      "Epoch [1/3], Batch [586/2500], Loss: 0.33811938762664795\n",
      "Epoch [1/3], Batch [587/2500], Loss: 0.2656381130218506\n",
      "Epoch [1/3], Batch [588/2500], Loss: 0.1288328319787979\n",
      "Epoch [1/3], Batch [589/2500], Loss: 0.09366608411073685\n",
      "Epoch [1/3], Batch [590/2500], Loss: 0.12891843914985657\n",
      "Epoch [1/3], Batch [591/2500], Loss: 0.29272133111953735\n",
      "Epoch [1/3], Batch [592/2500], Loss: 0.10600320994853973\n",
      "Epoch [1/3], Batch [593/2500], Loss: 0.26382821798324585\n",
      "Epoch [1/3], Batch [594/2500], Loss: 0.2630380690097809\n",
      "Epoch [1/3], Batch [595/2500], Loss: 0.35653775930404663\n",
      "Epoch [1/3], Batch [596/2500], Loss: 0.25488871335983276\n",
      "Epoch [1/3], Batch [597/2500], Loss: 0.3558776378631592\n",
      "Epoch [1/3], Batch [598/2500], Loss: 0.49754393100738525\n",
      "Epoch [1/3], Batch [599/2500], Loss: 0.31174734234809875\n",
      "Epoch [1/3], Batch [600/2500], Loss: 0.641869843006134\n",
      "Epoch [1/3], Batch [601/2500], Loss: 0.3223595917224884\n",
      "Epoch [1/3], Batch [602/2500], Loss: 0.43253058195114136\n",
      "Epoch [1/3], Batch [603/2500], Loss: 0.34905314445495605\n",
      "Epoch [1/3], Batch [604/2500], Loss: 0.3558735251426697\n",
      "Epoch [1/3], Batch [605/2500], Loss: 0.30815252661705017\n",
      "Epoch [1/3], Batch [606/2500], Loss: 0.14781111478805542\n",
      "Epoch [1/3], Batch [607/2500], Loss: 0.35024359822273254\n",
      "Epoch [1/3], Batch [608/2500], Loss: 0.3772397041320801\n",
      "Epoch [1/3], Batch [609/2500], Loss: 0.30297887325286865\n",
      "Epoch [1/3], Batch [610/2500], Loss: 0.44831740856170654\n",
      "Epoch [1/3], Batch [611/2500], Loss: 0.3601838946342468\n",
      "Epoch [1/3], Batch [612/2500], Loss: 0.31886205077171326\n",
      "Epoch [1/3], Batch [613/2500], Loss: 0.2419620305299759\n",
      "Epoch [1/3], Batch [614/2500], Loss: 0.3674297034740448\n",
      "Epoch [1/3], Batch [615/2500], Loss: 0.3637467324733734\n",
      "Epoch [1/3], Batch [616/2500], Loss: 0.34315064549446106\n",
      "Epoch [1/3], Batch [617/2500], Loss: 0.28328391909599304\n",
      "Epoch [1/3], Batch [618/2500], Loss: 0.39444500207901\n",
      "Epoch [1/3], Batch [619/2500], Loss: 0.3200298845767975\n",
      "Epoch [1/3], Batch [620/2500], Loss: 0.3414856195449829\n",
      "Epoch [1/3], Batch [621/2500], Loss: 0.2490471452474594\n",
      "Epoch [1/3], Batch [622/2500], Loss: 0.18026532232761383\n",
      "Epoch [1/3], Batch [623/2500], Loss: 0.4914337694644928\n",
      "Epoch [1/3], Batch [624/2500], Loss: 0.36592355370521545\n",
      "Epoch [1/3], Batch [625/2500], Loss: 0.13876575231552124\n",
      "Epoch [1/3], Batch [626/2500], Loss: 0.25029340386390686\n",
      "Epoch [1/3], Batch [627/2500], Loss: 0.13425306975841522\n",
      "Epoch [1/3], Batch [628/2500], Loss: 0.37006014585494995\n",
      "Epoch [1/3], Batch [629/2500], Loss: 0.27499112486839294\n",
      "Epoch [1/3], Batch [630/2500], Loss: 0.5935066342353821\n",
      "Epoch [1/3], Batch [631/2500], Loss: 0.24054870009422302\n",
      "Epoch [1/3], Batch [632/2500], Loss: 0.3405861556529999\n",
      "Epoch [1/3], Batch [633/2500], Loss: 0.20778298377990723\n",
      "Epoch [1/3], Batch [634/2500], Loss: 0.4110674560070038\n",
      "Epoch [1/3], Batch [635/2500], Loss: 0.4141383469104767\n",
      "Epoch [1/3], Batch [636/2500], Loss: 0.3049463629722595\n",
      "Epoch [1/3], Batch [637/2500], Loss: 0.2520829737186432\n",
      "Epoch [1/3], Batch [638/2500], Loss: 0.3286724090576172\n",
      "Epoch [1/3], Batch [639/2500], Loss: 0.29082465171813965\n",
      "Epoch [1/3], Batch [640/2500], Loss: 0.3148816227912903\n",
      "Epoch [1/3], Batch [641/2500], Loss: 0.420836478471756\n",
      "Epoch [1/3], Batch [642/2500], Loss: 0.40529367327690125\n",
      "Epoch [1/3], Batch [643/2500], Loss: 0.4340013265609741\n",
      "Epoch [1/3], Batch [644/2500], Loss: 0.26265475153923035\n",
      "Epoch [1/3], Batch [645/2500], Loss: 0.33530697226524353\n",
      "Epoch [1/3], Batch [646/2500], Loss: 0.238850399851799\n",
      "Epoch [1/3], Batch [647/2500], Loss: 0.24396125972270966\n",
      "Epoch [1/3], Batch [648/2500], Loss: 0.35112860798835754\n",
      "Epoch [1/3], Batch [649/2500], Loss: 0.4274212718009949\n",
      "Epoch [1/3], Batch [650/2500], Loss: 0.35523584485054016\n",
      "Epoch [1/3], Batch [651/2500], Loss: 0.3564578592777252\n",
      "Epoch [1/3], Batch [652/2500], Loss: 0.29442867636680603\n",
      "Epoch [1/3], Batch [653/2500], Loss: 0.46344590187072754\n",
      "Epoch [1/3], Batch [654/2500], Loss: 0.17836427688598633\n",
      "Epoch [1/3], Batch [655/2500], Loss: 0.30226758122444153\n",
      "Epoch [1/3], Batch [656/2500], Loss: 0.2648492753505707\n",
      "Epoch [1/3], Batch [657/2500], Loss: 0.2067856788635254\n",
      "Epoch [1/3], Batch [658/2500], Loss: 0.20721814036369324\n",
      "Epoch [1/3], Batch [659/2500], Loss: 0.18548497557640076\n",
      "Epoch [1/3], Batch [660/2500], Loss: 0.3722175061702728\n",
      "Epoch [1/3], Batch [661/2500], Loss: 0.24912738800048828\n",
      "Epoch [1/3], Batch [662/2500], Loss: 0.19180139899253845\n",
      "Epoch [1/3], Batch [663/2500], Loss: 0.32841193675994873\n",
      "Epoch [1/3], Batch [664/2500], Loss: 0.42290955781936646\n",
      "Epoch [1/3], Batch [665/2500], Loss: 0.6883918642997742\n",
      "Epoch [1/3], Batch [666/2500], Loss: 0.19878625869750977\n",
      "Epoch [1/3], Batch [667/2500], Loss: 0.21510344743728638\n",
      "Epoch [1/3], Batch [668/2500], Loss: 0.46723583340644836\n",
      "Epoch [1/3], Batch [669/2500], Loss: 0.34944698214530945\n",
      "Epoch [1/3], Batch [670/2500], Loss: 0.10095743089914322\n",
      "Epoch [1/3], Batch [671/2500], Loss: 0.3044583797454834\n",
      "Epoch [1/3], Batch [672/2500], Loss: 0.2857632637023926\n",
      "Epoch [1/3], Batch [673/2500], Loss: 0.3548637628555298\n",
      "Epoch [1/3], Batch [674/2500], Loss: 0.3042638897895813\n",
      "Epoch [1/3], Batch [675/2500], Loss: 0.2499009519815445\n",
      "Epoch [1/3], Batch [676/2500], Loss: 0.21385180950164795\n",
      "Epoch [1/3], Batch [677/2500], Loss: 0.3037306070327759\n",
      "Epoch [1/3], Batch [678/2500], Loss: 0.3852067291736603\n",
      "Epoch [1/3], Batch [679/2500], Loss: 0.3730091154575348\n",
      "Epoch [1/3], Batch [680/2500], Loss: 0.2903660535812378\n",
      "Epoch [1/3], Batch [681/2500], Loss: 0.2602930963039398\n",
      "Epoch [1/3], Batch [682/2500], Loss: 0.3841758370399475\n",
      "Epoch [1/3], Batch [683/2500], Loss: 0.28994321823120117\n",
      "Epoch [1/3], Batch [684/2500], Loss: 0.27607908844947815\n",
      "Epoch [1/3], Batch [685/2500], Loss: 0.411153107881546\n",
      "Epoch [1/3], Batch [686/2500], Loss: 0.2483176290988922\n",
      "Epoch [1/3], Batch [687/2500], Loss: 0.30553901195526123\n",
      "Epoch [1/3], Batch [688/2500], Loss: 0.37236541509628296\n",
      "Epoch [1/3], Batch [689/2500], Loss: 0.29742518067359924\n",
      "Epoch [1/3], Batch [690/2500], Loss: 0.24282115697860718\n",
      "Epoch [1/3], Batch [691/2500], Loss: 0.5353208184242249\n",
      "Epoch [1/3], Batch [692/2500], Loss: 0.4225418269634247\n",
      "Epoch [1/3], Batch [693/2500], Loss: 0.344496488571167\n",
      "Epoch [1/3], Batch [694/2500], Loss: 0.3438222110271454\n",
      "Epoch [1/3], Batch [695/2500], Loss: 0.4204126000404358\n",
      "Epoch [1/3], Batch [696/2500], Loss: 0.17711029946804047\n",
      "Epoch [1/3], Batch [697/2500], Loss: 0.2764553427696228\n",
      "Epoch [1/3], Batch [698/2500], Loss: 0.27467745542526245\n",
      "Epoch [1/3], Batch [699/2500], Loss: 0.13498803973197937\n",
      "Epoch [1/3], Batch [700/2500], Loss: 0.30242663621902466\n",
      "Epoch [1/3], Batch [701/2500], Loss: 0.20689938962459564\n",
      "Epoch [1/3], Batch [702/2500], Loss: 0.4167852997779846\n",
      "Epoch [1/3], Batch [703/2500], Loss: 0.5094937682151794\n",
      "Epoch [1/3], Batch [704/2500], Loss: 0.44587093591690063\n",
      "Epoch [1/3], Batch [705/2500], Loss: 0.31388694047927856\n",
      "Epoch [1/3], Batch [706/2500], Loss: 0.6156932711601257\n",
      "Epoch [1/3], Batch [707/2500], Loss: 0.2110820710659027\n",
      "Epoch [1/3], Batch [708/2500], Loss: 0.09226429462432861\n",
      "Epoch [1/3], Batch [709/2500], Loss: 0.5320502519607544\n",
      "Epoch [1/3], Batch [710/2500], Loss: 0.20953796803951263\n",
      "Epoch [1/3], Batch [711/2500], Loss: 0.1831553727388382\n",
      "Epoch [1/3], Batch [712/2500], Loss: 0.3617168962955475\n",
      "Epoch [1/3], Batch [713/2500], Loss: 0.29880568385124207\n",
      "Epoch [1/3], Batch [714/2500], Loss: 0.45994338393211365\n",
      "Epoch [1/3], Batch [715/2500], Loss: 0.4461013674736023\n",
      "Epoch [1/3], Batch [716/2500], Loss: 0.33041489124298096\n",
      "Epoch [1/3], Batch [717/2500], Loss: 0.2180878072977066\n",
      "Epoch [1/3], Batch [718/2500], Loss: 0.348539263010025\n",
      "Epoch [1/3], Batch [719/2500], Loss: 0.22586047649383545\n",
      "Epoch [1/3], Batch [720/2500], Loss: 0.2459489107131958\n",
      "Epoch [1/3], Batch [721/2500], Loss: 0.33515024185180664\n",
      "Epoch [1/3], Batch [722/2500], Loss: 0.22812563180923462\n",
      "Epoch [1/3], Batch [723/2500], Loss: 0.41748684644699097\n",
      "Epoch [1/3], Batch [724/2500], Loss: 0.30474257469177246\n",
      "Epoch [1/3], Batch [725/2500], Loss: 0.5236348509788513\n",
      "Epoch [1/3], Batch [726/2500], Loss: 0.27000516653060913\n",
      "Epoch [1/3], Batch [727/2500], Loss: 0.25322964787483215\n",
      "Epoch [1/3], Batch [728/2500], Loss: 0.2519177496433258\n",
      "Epoch [1/3], Batch [729/2500], Loss: 0.24626877903938293\n",
      "Epoch [1/3], Batch [730/2500], Loss: 0.2905232608318329\n",
      "Epoch [1/3], Batch [731/2500], Loss: 0.20080140233039856\n",
      "Epoch [1/3], Batch [732/2500], Loss: 0.2490786910057068\n",
      "Epoch [1/3], Batch [733/2500], Loss: 0.27931153774261475\n",
      "Epoch [1/3], Batch [734/2500], Loss: 0.22315137088298798\n",
      "Epoch [1/3], Batch [735/2500], Loss: 0.1734199970960617\n",
      "Epoch [1/3], Batch [736/2500], Loss: 0.19457516074180603\n",
      "Epoch [1/3], Batch [737/2500], Loss: 0.4441991150379181\n",
      "Epoch [1/3], Batch [738/2500], Loss: 0.19782470166683197\n",
      "Epoch [1/3], Batch [739/2500], Loss: 0.17685475945472717\n",
      "Epoch [1/3], Batch [740/2500], Loss: 0.36597520112991333\n",
      "Epoch [1/3], Batch [741/2500], Loss: 0.40623483061790466\n",
      "Epoch [1/3], Batch [742/2500], Loss: 0.21174728870391846\n",
      "Epoch [1/3], Batch [743/2500], Loss: 0.5132177472114563\n",
      "Epoch [1/3], Batch [744/2500], Loss: 0.3230835795402527\n",
      "Epoch [1/3], Batch [745/2500], Loss: 0.18241789937019348\n",
      "Epoch [1/3], Batch [746/2500], Loss: 0.15247571468353271\n",
      "Epoch [1/3], Batch [747/2500], Loss: 0.4203169643878937\n",
      "Epoch [1/3], Batch [748/2500], Loss: 0.3901683986186981\n",
      "Epoch [1/3], Batch [749/2500], Loss: 0.15841044485569\n",
      "Epoch [1/3], Batch [750/2500], Loss: 0.29473501443862915\n",
      "Epoch [1/3], Batch [751/2500], Loss: 0.2130466252565384\n",
      "Epoch [1/3], Batch [752/2500], Loss: 0.24598108232021332\n",
      "Epoch [1/3], Batch [753/2500], Loss: 0.1493733823299408\n",
      "Epoch [1/3], Batch [754/2500], Loss: 0.42833584547042847\n",
      "Epoch [1/3], Batch [755/2500], Loss: 0.17249085009098053\n",
      "Epoch [1/3], Batch [756/2500], Loss: 0.2536648213863373\n",
      "Epoch [1/3], Batch [757/2500], Loss: 0.5298992395401001\n",
      "Epoch [1/3], Batch [758/2500], Loss: 0.1473006159067154\n",
      "Epoch [1/3], Batch [759/2500], Loss: 0.3255785405635834\n",
      "Epoch [1/3], Batch [760/2500], Loss: 0.18681852519512177\n",
      "Epoch [1/3], Batch [761/2500], Loss: 0.5360068678855896\n",
      "Epoch [1/3], Batch [762/2500], Loss: 0.24374136328697205\n",
      "Epoch [1/3], Batch [763/2500], Loss: 0.29291895031929016\n",
      "Epoch [1/3], Batch [764/2500], Loss: 0.08782906830310822\n",
      "Epoch [1/3], Batch [765/2500], Loss: 0.3731084167957306\n",
      "Epoch [1/3], Batch [766/2500], Loss: 0.1861354410648346\n",
      "Epoch [1/3], Batch [767/2500], Loss: 0.09803194552659988\n",
      "Epoch [1/3], Batch [768/2500], Loss: 0.21376734972000122\n",
      "Epoch [1/3], Batch [769/2500], Loss: 0.26964569091796875\n",
      "Epoch [1/3], Batch [770/2500], Loss: 0.5814325213432312\n",
      "Epoch [1/3], Batch [771/2500], Loss: 0.2693210244178772\n",
      "Epoch [1/3], Batch [772/2500], Loss: 0.18234995007514954\n",
      "Epoch [1/3], Batch [773/2500], Loss: 0.49817362427711487\n",
      "Epoch [1/3], Batch [774/2500], Loss: 0.37525129318237305\n",
      "Epoch [1/3], Batch [775/2500], Loss: 0.1476406455039978\n",
      "Epoch [1/3], Batch [776/2500], Loss: 0.18044155836105347\n",
      "Epoch [1/3], Batch [777/2500], Loss: 0.22022180259227753\n",
      "Epoch [1/3], Batch [778/2500], Loss: 0.440876305103302\n",
      "Epoch [1/3], Batch [779/2500], Loss: 0.3042967617511749\n",
      "Epoch [1/3], Batch [780/2500], Loss: 0.25380584597587585\n",
      "Epoch [1/3], Batch [781/2500], Loss: 0.26965558528900146\n",
      "Epoch [1/3], Batch [782/2500], Loss: 0.5708667635917664\n",
      "Epoch [1/3], Batch [783/2500], Loss: 0.24053291976451874\n",
      "Epoch [1/3], Batch [784/2500], Loss: 0.3847717344760895\n",
      "Epoch [1/3], Batch [785/2500], Loss: 0.289288729429245\n",
      "Epoch [1/3], Batch [786/2500], Loss: 0.292926549911499\n",
      "Epoch [1/3], Batch [787/2500], Loss: 0.12141824513673782\n",
      "Epoch [1/3], Batch [788/2500], Loss: 0.30609649419784546\n",
      "Epoch [1/3], Batch [789/2500], Loss: 0.3920425474643707\n",
      "Epoch [1/3], Batch [790/2500], Loss: 0.24441057443618774\n",
      "Epoch [1/3], Batch [791/2500], Loss: 0.7307363748550415\n",
      "Epoch [1/3], Batch [792/2500], Loss: 0.20543847978115082\n",
      "Epoch [1/3], Batch [793/2500], Loss: 0.27970778942108154\n",
      "Epoch [1/3], Batch [794/2500], Loss: 0.20138700306415558\n",
      "Epoch [1/3], Batch [795/2500], Loss: 0.46109578013420105\n",
      "Epoch [1/3], Batch [796/2500], Loss: 0.10117198526859283\n",
      "Epoch [1/3], Batch [797/2500], Loss: 0.44795167446136475\n",
      "Epoch [1/3], Batch [798/2500], Loss: 0.20219358801841736\n",
      "Epoch [1/3], Batch [799/2500], Loss: 0.27436259388923645\n",
      "Epoch [1/3], Batch [800/2500], Loss: 0.27855566143989563\n",
      "Epoch [1/3], Batch [801/2500], Loss: 0.3204255998134613\n",
      "Epoch [1/3], Batch [802/2500], Loss: 0.2806589603424072\n",
      "Epoch [1/3], Batch [803/2500], Loss: 0.46307554841041565\n",
      "Epoch [1/3], Batch [804/2500], Loss: 0.23230676352977753\n",
      "Epoch [1/3], Batch [805/2500], Loss: 0.3815082609653473\n",
      "Epoch [1/3], Batch [806/2500], Loss: 0.3390195667743683\n",
      "Epoch [1/3], Batch [807/2500], Loss: 0.3846690058708191\n",
      "Epoch [1/3], Batch [808/2500], Loss: 0.3038114309310913\n",
      "Epoch [1/3], Batch [809/2500], Loss: 0.39025449752807617\n",
      "Epoch [1/3], Batch [810/2500], Loss: 0.28238701820373535\n",
      "Epoch [1/3], Batch [811/2500], Loss: 0.4221997857093811\n",
      "Epoch [1/3], Batch [812/2500], Loss: 0.4924304783344269\n",
      "Epoch [1/3], Batch [813/2500], Loss: 0.23980261385440826\n",
      "Epoch [1/3], Batch [814/2500], Loss: 0.402964323759079\n",
      "Epoch [1/3], Batch [815/2500], Loss: 0.22637644410133362\n",
      "Epoch [1/3], Batch [816/2500], Loss: 0.18993280827999115\n",
      "Epoch [1/3], Batch [817/2500], Loss: 0.11130271852016449\n",
      "Epoch [1/3], Batch [818/2500], Loss: 0.11535555124282837\n",
      "Epoch [1/3], Batch [819/2500], Loss: 0.46113088726997375\n",
      "Epoch [1/3], Batch [820/2500], Loss: 0.11520116776227951\n",
      "Epoch [1/3], Batch [821/2500], Loss: 0.4627493619918823\n",
      "Epoch [1/3], Batch [822/2500], Loss: 0.25461533665657043\n",
      "Epoch [1/3], Batch [823/2500], Loss: 0.6247764825820923\n",
      "Epoch [1/3], Batch [824/2500], Loss: 0.06633497029542923\n",
      "Epoch [1/3], Batch [825/2500], Loss: 0.3558201491832733\n",
      "Epoch [1/3], Batch [826/2500], Loss: 0.09359431266784668\n",
      "Epoch [1/3], Batch [827/2500], Loss: 0.31017640233039856\n",
      "Epoch [1/3], Batch [828/2500], Loss: 0.2567862272262573\n",
      "Epoch [1/3], Batch [829/2500], Loss: 0.30724036693573\n",
      "Epoch [1/3], Batch [830/2500], Loss: 0.3251647651195526\n",
      "Epoch [1/3], Batch [831/2500], Loss: 0.0920046716928482\n",
      "Epoch [1/3], Batch [832/2500], Loss: 0.12349619716405869\n",
      "Epoch [1/3], Batch [833/2500], Loss: 0.49619096517562866\n",
      "Epoch [1/3], Batch [834/2500], Loss: 0.2104060798883438\n",
      "Epoch [1/3], Batch [835/2500], Loss: 0.2826802134513855\n",
      "Epoch [1/3], Batch [836/2500], Loss: 0.21071583032608032\n",
      "Epoch [1/3], Batch [837/2500], Loss: 0.37671056389808655\n",
      "Epoch [1/3], Batch [838/2500], Loss: 0.3447708487510681\n",
      "Epoch [1/3], Batch [839/2500], Loss: 0.3998684883117676\n",
      "Epoch [1/3], Batch [840/2500], Loss: 0.4342035949230194\n",
      "Epoch [1/3], Batch [841/2500], Loss: 0.3301926553249359\n",
      "Epoch [1/3], Batch [842/2500], Loss: 0.3971268832683563\n",
      "Epoch [1/3], Batch [843/2500], Loss: 0.515300452709198\n",
      "Epoch [1/3], Batch [844/2500], Loss: 0.2973066568374634\n",
      "Epoch [1/3], Batch [845/2500], Loss: 0.15559116005897522\n",
      "Epoch [1/3], Batch [846/2500], Loss: 0.12863771617412567\n",
      "Epoch [1/3], Batch [847/2500], Loss: 0.40313658118247986\n",
      "Epoch [1/3], Batch [848/2500], Loss: 0.2632899582386017\n",
      "Epoch [1/3], Batch [849/2500], Loss: 0.2957476079463959\n",
      "Epoch [1/3], Batch [850/2500], Loss: 0.18260882794857025\n",
      "Epoch [1/3], Batch [851/2500], Loss: 0.300552636384964\n",
      "Epoch [1/3], Batch [852/2500], Loss: 0.4467617869377136\n",
      "Epoch [1/3], Batch [853/2500], Loss: 0.2831652760505676\n",
      "Epoch [1/3], Batch [854/2500], Loss: 0.1511698067188263\n",
      "Epoch [1/3], Batch [855/2500], Loss: 0.15658697485923767\n",
      "Epoch [1/3], Batch [856/2500], Loss: 0.14997290074825287\n",
      "Epoch [1/3], Batch [857/2500], Loss: 0.15079928934574127\n",
      "Epoch [1/3], Batch [858/2500], Loss: 0.21404777467250824\n",
      "Epoch [1/3], Batch [859/2500], Loss: 0.15558411180973053\n",
      "Epoch [1/3], Batch [860/2500], Loss: 0.4401742219924927\n",
      "Epoch [1/3], Batch [861/2500], Loss: 0.3392306864261627\n",
      "Epoch [1/3], Batch [862/2500], Loss: 0.18223659694194794\n",
      "Epoch [1/3], Batch [863/2500], Loss: 0.2767263650894165\n",
      "Epoch [1/3], Batch [864/2500], Loss: 0.09803003072738647\n",
      "Epoch [1/3], Batch [865/2500], Loss: 0.48000553250312805\n",
      "Epoch [1/3], Batch [866/2500], Loss: 0.1595550924539566\n",
      "Epoch [1/3], Batch [867/2500], Loss: 0.04346572607755661\n",
      "Epoch [1/3], Batch [868/2500], Loss: 0.08501069992780685\n",
      "Epoch [1/3], Batch [869/2500], Loss: 0.29378417134284973\n",
      "Epoch [1/3], Batch [870/2500], Loss: 0.2526480555534363\n",
      "Epoch [1/3], Batch [871/2500], Loss: 0.07547503709793091\n",
      "Epoch [1/3], Batch [872/2500], Loss: 0.1638389527797699\n",
      "Epoch [1/3], Batch [873/2500], Loss: 0.11575321853160858\n",
      "Epoch [1/3], Batch [874/2500], Loss: 0.23479297757148743\n",
      "Epoch [1/3], Batch [875/2500], Loss: 0.11152958124876022\n",
      "Epoch [1/3], Batch [876/2500], Loss: 0.47681117057800293\n",
      "Epoch [1/3], Batch [877/2500], Loss: 0.47904834151268005\n",
      "Epoch [1/3], Batch [878/2500], Loss: 0.7605515122413635\n",
      "Epoch [1/3], Batch [879/2500], Loss: 0.23908422887325287\n",
      "Epoch [1/3], Batch [880/2500], Loss: 0.10343886911869049\n",
      "Epoch [1/3], Batch [881/2500], Loss: 0.12762339413166046\n",
      "Epoch [1/3], Batch [882/2500], Loss: 0.373132586479187\n",
      "Epoch [1/3], Batch [883/2500], Loss: 0.1909925937652588\n",
      "Epoch [1/3], Batch [884/2500], Loss: 0.2122337520122528\n",
      "Epoch [1/3], Batch [885/2500], Loss: 0.299837201833725\n",
      "Epoch [1/3], Batch [886/2500], Loss: 0.1488080620765686\n",
      "Epoch [1/3], Batch [887/2500], Loss: 0.22527293860912323\n",
      "Epoch [1/3], Batch [888/2500], Loss: 0.42372894287109375\n",
      "Epoch [1/3], Batch [889/2500], Loss: 0.2984216511249542\n",
      "Epoch [1/3], Batch [890/2500], Loss: 0.47626134753227234\n",
      "Epoch [1/3], Batch [891/2500], Loss: 0.18644224107265472\n",
      "Epoch [1/3], Batch [892/2500], Loss: 0.19124440848827362\n",
      "Epoch [1/3], Batch [893/2500], Loss: 0.25462085008621216\n",
      "Epoch [1/3], Batch [894/2500], Loss: 0.25913041830062866\n",
      "Epoch [1/3], Batch [895/2500], Loss: 0.23780794441699982\n",
      "Epoch [1/3], Batch [896/2500], Loss: 0.17431291937828064\n",
      "Epoch [1/3], Batch [897/2500], Loss: 0.21913817524909973\n",
      "Epoch [1/3], Batch [898/2500], Loss: 0.3788035809993744\n",
      "Epoch [1/3], Batch [899/2500], Loss: 0.37061211466789246\n",
      "Epoch [1/3], Batch [900/2500], Loss: 0.2748646140098572\n",
      "Epoch [1/3], Batch [901/2500], Loss: 0.4397716820240021\n",
      "Epoch [1/3], Batch [902/2500], Loss: 0.18519562482833862\n",
      "Epoch [1/3], Batch [903/2500], Loss: 0.35931283235549927\n",
      "Epoch [1/3], Batch [904/2500], Loss: 0.21396175026893616\n",
      "Epoch [1/3], Batch [905/2500], Loss: 0.5966439843177795\n",
      "Epoch [1/3], Batch [906/2500], Loss: 0.432373046875\n",
      "Epoch [1/3], Batch [907/2500], Loss: 0.15146051347255707\n",
      "Epoch [1/3], Batch [908/2500], Loss: 0.2606937885284424\n",
      "Epoch [1/3], Batch [909/2500], Loss: 0.23681016266345978\n",
      "Epoch [1/3], Batch [910/2500], Loss: 0.25127020478248596\n",
      "Epoch [1/3], Batch [911/2500], Loss: 0.3735591173171997\n",
      "Epoch [1/3], Batch [912/2500], Loss: 0.1990906447172165\n",
      "Epoch [1/3], Batch [913/2500], Loss: 0.20399311184883118\n",
      "Epoch [1/3], Batch [914/2500], Loss: 0.3223316967487335\n",
      "Epoch [1/3], Batch [915/2500], Loss: 0.21597087383270264\n",
      "Epoch [1/3], Batch [916/2500], Loss: 0.0473833829164505\n",
      "Epoch [1/3], Batch [917/2500], Loss: 0.3213772177696228\n",
      "Epoch [1/3], Batch [918/2500], Loss: 0.2551286518573761\n",
      "Epoch [1/3], Batch [919/2500], Loss: 0.18535475432872772\n",
      "Epoch [1/3], Batch [920/2500], Loss: 0.178032785654068\n",
      "Epoch [1/3], Batch [921/2500], Loss: 0.17786820232868195\n",
      "Epoch [1/3], Batch [922/2500], Loss: 0.44406402111053467\n",
      "Epoch [1/3], Batch [923/2500], Loss: 0.26135632395744324\n",
      "Epoch [1/3], Batch [924/2500], Loss: 0.3284899890422821\n",
      "Epoch [1/3], Batch [925/2500], Loss: 0.03733033686876297\n",
      "Epoch [1/3], Batch [926/2500], Loss: 0.16277126967906952\n",
      "Epoch [1/3], Batch [927/2500], Loss: 0.22911357879638672\n",
      "Epoch [1/3], Batch [928/2500], Loss: 0.12215505540370941\n",
      "Epoch [1/3], Batch [929/2500], Loss: 0.09793396294116974\n",
      "Epoch [1/3], Batch [930/2500], Loss: 0.15659594535827637\n",
      "Epoch [1/3], Batch [931/2500], Loss: 0.306645005941391\n",
      "Epoch [1/3], Batch [932/2500], Loss: 0.31274059414863586\n",
      "Epoch [1/3], Batch [933/2500], Loss: 0.1140802651643753\n",
      "Epoch [1/3], Batch [934/2500], Loss: 0.29079678654670715\n",
      "Epoch [1/3], Batch [935/2500], Loss: 0.5704899430274963\n",
      "Epoch [1/3], Batch [936/2500], Loss: 0.16704438626766205\n",
      "Epoch [1/3], Batch [937/2500], Loss: 0.060499969869852066\n",
      "Epoch [1/3], Batch [938/2500], Loss: 0.23339220881462097\n",
      "Epoch [1/3], Batch [939/2500], Loss: 0.19504323601722717\n",
      "Epoch [1/3], Batch [940/2500], Loss: 0.40195104479789734\n",
      "Epoch [1/3], Batch [941/2500], Loss: 0.27144479751586914\n",
      "Epoch [1/3], Batch [942/2500], Loss: 0.5413547158241272\n",
      "Epoch [1/3], Batch [943/2500], Loss: 0.4109417200088501\n",
      "Epoch [1/3], Batch [944/2500], Loss: 0.4981299936771393\n",
      "Epoch [1/3], Batch [945/2500], Loss: 0.42137935757637024\n",
      "Epoch [1/3], Batch [946/2500], Loss: 0.2845456004142761\n",
      "Epoch [1/3], Batch [947/2500], Loss: 1.2803064584732056\n",
      "Epoch [1/3], Batch [948/2500], Loss: 0.08388420194387436\n",
      "Epoch [1/3], Batch [949/2500], Loss: 0.1927022933959961\n",
      "Epoch [1/3], Batch [950/2500], Loss: 0.2591797709465027\n",
      "Epoch [1/3], Batch [951/2500], Loss: 0.2461291402578354\n",
      "Epoch [1/3], Batch [952/2500], Loss: 0.37988319993019104\n",
      "Epoch [1/3], Batch [953/2500], Loss: 0.3007080554962158\n",
      "Epoch [1/3], Batch [954/2500], Loss: 0.6226280927658081\n",
      "Epoch [1/3], Batch [955/2500], Loss: 0.1998109519481659\n",
      "Epoch [1/3], Batch [956/2500], Loss: 0.4621678590774536\n",
      "Epoch [1/3], Batch [957/2500], Loss: 0.1376902014017105\n",
      "Epoch [1/3], Batch [958/2500], Loss: 0.2747383117675781\n",
      "Epoch [1/3], Batch [959/2500], Loss: 0.19415946304798126\n",
      "Epoch [1/3], Batch [960/2500], Loss: 0.29763415455818176\n",
      "Epoch [1/3], Batch [961/2500], Loss: 0.17735286056995392\n",
      "Epoch [1/3], Batch [962/2500], Loss: 0.5534728765487671\n",
      "Epoch [1/3], Batch [963/2500], Loss: 0.13881295919418335\n",
      "Epoch [1/3], Batch [964/2500], Loss: 0.41437622904777527\n",
      "Epoch [1/3], Batch [965/2500], Loss: 0.22199572622776031\n",
      "Epoch [1/3], Batch [966/2500], Loss: 0.402021199464798\n",
      "Epoch [1/3], Batch [967/2500], Loss: 0.16433081030845642\n",
      "Epoch [1/3], Batch [968/2500], Loss: 0.0901731476187706\n",
      "Epoch [1/3], Batch [969/2500], Loss: 0.35670965909957886\n",
      "Epoch [1/3], Batch [970/2500], Loss: 0.20882004499435425\n",
      "Epoch [1/3], Batch [971/2500], Loss: 0.2132987231016159\n",
      "Epoch [1/3], Batch [972/2500], Loss: 0.20600776374340057\n",
      "Epoch [1/3], Batch [973/2500], Loss: 0.28870853781700134\n",
      "Epoch [1/3], Batch [974/2500], Loss: 0.27247947454452515\n",
      "Epoch [1/3], Batch [975/2500], Loss: 0.228805810213089\n",
      "Epoch [1/3], Batch [976/2500], Loss: 0.09868904948234558\n",
      "Epoch [1/3], Batch [977/2500], Loss: 0.2679625153541565\n",
      "Epoch [1/3], Batch [978/2500], Loss: 0.17913956940174103\n",
      "Epoch [1/3], Batch [979/2500], Loss: 0.13313445448875427\n",
      "Epoch [1/3], Batch [980/2500], Loss: 0.2680923640727997\n",
      "Epoch [1/3], Batch [981/2500], Loss: 0.08597894757986069\n",
      "Epoch [1/3], Batch [982/2500], Loss: 0.10130761563777924\n",
      "Epoch [1/3], Batch [983/2500], Loss: 0.2871444821357727\n",
      "Epoch [1/3], Batch [984/2500], Loss: 0.3269771337509155\n",
      "Epoch [1/3], Batch [985/2500], Loss: 0.2598314583301544\n",
      "Epoch [1/3], Batch [986/2500], Loss: 0.23006875813007355\n",
      "Epoch [1/3], Batch [987/2500], Loss: 0.2785937786102295\n",
      "Epoch [1/3], Batch [988/2500], Loss: 0.22978800535202026\n",
      "Epoch [1/3], Batch [989/2500], Loss: 0.09951431304216385\n",
      "Epoch [1/3], Batch [990/2500], Loss: 0.3548987805843353\n",
      "Epoch [1/3], Batch [991/2500], Loss: 0.2080308347940445\n",
      "Epoch [1/3], Batch [992/2500], Loss: 0.2679121792316437\n",
      "Epoch [1/3], Batch [993/2500], Loss: 0.18060989677906036\n",
      "Epoch [1/3], Batch [994/2500], Loss: 0.13224002718925476\n",
      "Epoch [1/3], Batch [995/2500], Loss: 0.24500170350074768\n",
      "Epoch [1/3], Batch [996/2500], Loss: 0.2075301557779312\n",
      "Epoch [1/3], Batch [997/2500], Loss: 0.21732330322265625\n",
      "Epoch [1/3], Batch [998/2500], Loss: 0.3406880795955658\n",
      "Epoch [1/3], Batch [999/2500], Loss: 0.11596162617206573\n",
      "Epoch [1/3], Batch [1000/2500], Loss: 0.1107979342341423\n",
      "Epoch [1/3], Batch [1001/2500], Loss: 0.4554373323917389\n",
      "Epoch [1/3], Batch [1002/2500], Loss: 0.252912312746048\n",
      "Epoch [1/3], Batch [1003/2500], Loss: 0.10078559815883636\n",
      "Epoch [1/3], Batch [1004/2500], Loss: 0.07284311950206757\n",
      "Epoch [1/3], Batch [1005/2500], Loss: 0.11637342721223831\n",
      "Epoch [1/3], Batch [1006/2500], Loss: 0.3146592676639557\n",
      "Epoch [1/3], Batch [1007/2500], Loss: 0.05122077092528343\n",
      "Epoch [1/3], Batch [1008/2500], Loss: 0.48465797305107117\n",
      "Epoch [1/3], Batch [1009/2500], Loss: 0.09558908641338348\n",
      "Epoch [1/3], Batch [1010/2500], Loss: 0.45160505175590515\n",
      "Epoch [1/3], Batch [1011/2500], Loss: 0.19000379741191864\n",
      "Epoch [1/3], Batch [1012/2500], Loss: 0.18233367800712585\n",
      "Epoch [1/3], Batch [1013/2500], Loss: 0.324196994304657\n",
      "Epoch [1/3], Batch [1014/2500], Loss: 0.33313778042793274\n",
      "Epoch [1/3], Batch [1015/2500], Loss: 0.1800890862941742\n",
      "Epoch [1/3], Batch [1016/2500], Loss: 0.37712129950523376\n",
      "Epoch [1/3], Batch [1017/2500], Loss: 0.35789427161216736\n",
      "Epoch [1/3], Batch [1018/2500], Loss: 0.24274466931819916\n",
      "Epoch [1/3], Batch [1019/2500], Loss: 0.24534760415554047\n",
      "Epoch [1/3], Batch [1020/2500], Loss: 0.26058176159858704\n",
      "Epoch [1/3], Batch [1021/2500], Loss: 0.36737728118896484\n",
      "Epoch [1/3], Batch [1022/2500], Loss: 0.07047925889492035\n",
      "Epoch [1/3], Batch [1023/2500], Loss: 0.29853197932243347\n",
      "Epoch [1/3], Batch [1024/2500], Loss: 0.05613626539707184\n",
      "Epoch [1/3], Batch [1025/2500], Loss: 0.1549653261899948\n",
      "Epoch [1/3], Batch [1026/2500], Loss: 0.3468363285064697\n",
      "Epoch [1/3], Batch [1027/2500], Loss: 0.15604987740516663\n",
      "Epoch [1/3], Batch [1028/2500], Loss: 0.2649702727794647\n",
      "Epoch [1/3], Batch [1029/2500], Loss: 0.4741120934486389\n",
      "Epoch [1/3], Batch [1030/2500], Loss: 0.3924465775489807\n",
      "Epoch [1/3], Batch [1031/2500], Loss: 0.33714982867240906\n",
      "Epoch [1/3], Batch [1032/2500], Loss: 0.14738337695598602\n",
      "Epoch [1/3], Batch [1033/2500], Loss: 0.43969810009002686\n",
      "Epoch [1/3], Batch [1034/2500], Loss: 0.5178419947624207\n",
      "Epoch [1/3], Batch [1035/2500], Loss: 0.34766483306884766\n",
      "Epoch [1/3], Batch [1036/2500], Loss: 0.09262216091156006\n",
      "Epoch [1/3], Batch [1037/2500], Loss: 0.15817904472351074\n",
      "Epoch [1/3], Batch [1038/2500], Loss: 0.10310208797454834\n",
      "Epoch [1/3], Batch [1039/2500], Loss: 0.3358537554740906\n",
      "Epoch [1/3], Batch [1040/2500], Loss: 0.2840805649757385\n",
      "Epoch [1/3], Batch [1041/2500], Loss: 0.21093980967998505\n",
      "Epoch [1/3], Batch [1042/2500], Loss: 0.19574934244155884\n",
      "Epoch [1/3], Batch [1043/2500], Loss: 0.2765108048915863\n",
      "Epoch [1/3], Batch [1044/2500], Loss: 0.0752878189086914\n",
      "Epoch [1/3], Batch [1045/2500], Loss: 0.11242188513278961\n",
      "Epoch [1/3], Batch [1046/2500], Loss: 0.4530041515827179\n",
      "Epoch [1/3], Batch [1047/2500], Loss: 0.2255471646785736\n",
      "Epoch [1/3], Batch [1048/2500], Loss: 0.43570590019226074\n",
      "Epoch [1/3], Batch [1049/2500], Loss: 0.11904141306877136\n",
      "Epoch [1/3], Batch [1050/2500], Loss: 0.2686387896537781\n",
      "Epoch [1/3], Batch [1051/2500], Loss: 0.09879904985427856\n",
      "Epoch [1/3], Batch [1052/2500], Loss: 0.38064226508140564\n",
      "Epoch [1/3], Batch [1053/2500], Loss: 0.19474060833454132\n",
      "Epoch [1/3], Batch [1054/2500], Loss: 0.04473142325878143\n",
      "Epoch [1/3], Batch [1055/2500], Loss: 0.07060772180557251\n",
      "Epoch [1/3], Batch [1056/2500], Loss: 0.22461143136024475\n",
      "Epoch [1/3], Batch [1057/2500], Loss: 0.05161873996257782\n",
      "Epoch [1/3], Batch [1058/2500], Loss: 0.07146541774272919\n",
      "Epoch [1/3], Batch [1059/2500], Loss: 0.13890357315540314\n",
      "Epoch [1/3], Batch [1060/2500], Loss: 0.13563646376132965\n",
      "Epoch [1/3], Batch [1061/2500], Loss: 0.27080237865448\n",
      "Epoch [1/3], Batch [1062/2500], Loss: 0.34345364570617676\n",
      "Epoch [1/3], Batch [1063/2500], Loss: 0.08016722649335861\n",
      "Epoch [1/3], Batch [1064/2500], Loss: 0.4522419571876526\n",
      "Epoch [1/3], Batch [1065/2500], Loss: 0.30280107259750366\n",
      "Epoch [1/3], Batch [1066/2500], Loss: 0.10649842768907547\n",
      "Epoch [1/3], Batch [1067/2500], Loss: 0.09314767271280289\n",
      "Epoch [1/3], Batch [1068/2500], Loss: 0.280672162771225\n",
      "Epoch [1/3], Batch [1069/2500], Loss: 0.25857019424438477\n",
      "Epoch [1/3], Batch [1070/2500], Loss: 0.41686198115348816\n",
      "Epoch [1/3], Batch [1071/2500], Loss: 0.2521880865097046\n",
      "Epoch [1/3], Batch [1072/2500], Loss: 0.2936832308769226\n",
      "Epoch [1/3], Batch [1073/2500], Loss: 0.0698736384510994\n",
      "Epoch [1/3], Batch [1074/2500], Loss: 0.5031958222389221\n",
      "Epoch [1/3], Batch [1075/2500], Loss: 0.19196848571300507\n",
      "Epoch [1/3], Batch [1076/2500], Loss: 0.15339283645153046\n",
      "Epoch [1/3], Batch [1077/2500], Loss: 0.3388574421405792\n",
      "Epoch [1/3], Batch [1078/2500], Loss: 0.2680000364780426\n",
      "Epoch [1/3], Batch [1079/2500], Loss: 0.11898470669984818\n",
      "Epoch [1/3], Batch [1080/2500], Loss: 0.19286546111106873\n",
      "Epoch [1/3], Batch [1081/2500], Loss: 0.31458064913749695\n",
      "Epoch [1/3], Batch [1082/2500], Loss: 0.12726862728595734\n",
      "Epoch [1/3], Batch [1083/2500], Loss: 0.27836379408836365\n",
      "Epoch [1/3], Batch [1084/2500], Loss: 0.1374950259923935\n",
      "Epoch [1/3], Batch [1085/2500], Loss: 0.18581131100654602\n",
      "Epoch [1/3], Batch [1086/2500], Loss: 0.13969942927360535\n",
      "Epoch [1/3], Batch [1087/2500], Loss: 0.15341582894325256\n",
      "Epoch [1/3], Batch [1088/2500], Loss: 0.11553263664245605\n",
      "Epoch [1/3], Batch [1089/2500], Loss: 0.17472580075263977\n",
      "Epoch [1/3], Batch [1090/2500], Loss: 0.6135153770446777\n",
      "Epoch [1/3], Batch [1091/2500], Loss: 0.034900128841400146\n",
      "Epoch [1/3], Batch [1092/2500], Loss: 0.2742448151111603\n",
      "Epoch [1/3], Batch [1093/2500], Loss: 0.18640653789043427\n",
      "Epoch [1/3], Batch [1094/2500], Loss: 0.36968666315078735\n",
      "Epoch [1/3], Batch [1095/2500], Loss: 0.21876901388168335\n",
      "Epoch [1/3], Batch [1096/2500], Loss: 0.3805086612701416\n",
      "Epoch [1/3], Batch [1097/2500], Loss: 0.8458440899848938\n",
      "Epoch [1/3], Batch [1098/2500], Loss: 0.19228358566761017\n",
      "Epoch [1/3], Batch [1099/2500], Loss: 0.3981676697731018\n",
      "Epoch [1/3], Batch [1100/2500], Loss: 0.10415232181549072\n",
      "Epoch [1/3], Batch [1101/2500], Loss: 0.41154614090919495\n",
      "Epoch [1/3], Batch [1102/2500], Loss: 0.29744094610214233\n",
      "Epoch [1/3], Batch [1103/2500], Loss: 0.42591628432273865\n",
      "Epoch [1/3], Batch [1104/2500], Loss: 0.27054718136787415\n",
      "Epoch [1/3], Batch [1105/2500], Loss: 0.09864911437034607\n",
      "Epoch [1/3], Batch [1106/2500], Loss: 0.2366933375597\n",
      "Epoch [1/3], Batch [1107/2500], Loss: 0.22012177109718323\n",
      "Epoch [1/3], Batch [1108/2500], Loss: 0.22107520699501038\n",
      "Epoch [1/3], Batch [1109/2500], Loss: 0.11920132488012314\n",
      "Epoch [1/3], Batch [1110/2500], Loss: 0.1959271878004074\n",
      "Epoch [1/3], Batch [1111/2500], Loss: 0.23158085346221924\n",
      "Epoch [1/3], Batch [1112/2500], Loss: 0.31438207626342773\n",
      "Epoch [1/3], Batch [1113/2500], Loss: 0.29105421900749207\n",
      "Epoch [1/3], Batch [1114/2500], Loss: 0.05725859850645065\n",
      "Epoch [1/3], Batch [1115/2500], Loss: 0.5908340215682983\n",
      "Epoch [1/3], Batch [1116/2500], Loss: 0.14866110682487488\n",
      "Epoch [1/3], Batch [1117/2500], Loss: 0.4637952446937561\n",
      "Epoch [1/3], Batch [1118/2500], Loss: 0.31421056389808655\n",
      "Epoch [1/3], Batch [1119/2500], Loss: 0.11907579004764557\n",
      "Epoch [1/3], Batch [1120/2500], Loss: 0.21801061928272247\n",
      "Epoch [1/3], Batch [1121/2500], Loss: 0.17831392586231232\n",
      "Epoch [1/3], Batch [1122/2500], Loss: 0.31398576498031616\n",
      "Epoch [1/3], Batch [1123/2500], Loss: 0.2798965871334076\n",
      "Epoch [1/3], Batch [1124/2500], Loss: 0.33543553948402405\n",
      "Epoch [1/3], Batch [1125/2500], Loss: 0.18505984544754028\n",
      "Epoch [1/3], Batch [1126/2500], Loss: 0.24241870641708374\n",
      "Epoch [1/3], Batch [1127/2500], Loss: 0.1484263688325882\n",
      "Epoch [1/3], Batch [1128/2500], Loss: 0.4186928868293762\n",
      "Epoch [1/3], Batch [1129/2500], Loss: 0.08908668160438538\n",
      "Epoch [1/3], Batch [1130/2500], Loss: 0.3589012920856476\n",
      "Epoch [1/3], Batch [1131/2500], Loss: 0.16807684302330017\n",
      "Epoch [1/3], Batch [1132/2500], Loss: 0.23809821903705597\n",
      "Epoch [1/3], Batch [1133/2500], Loss: 0.3102101981639862\n",
      "Epoch [1/3], Batch [1134/2500], Loss: 0.2174854725599289\n",
      "Epoch [1/3], Batch [1135/2500], Loss: 0.15142680704593658\n",
      "Epoch [1/3], Batch [1136/2500], Loss: 0.1695389747619629\n",
      "Epoch [1/3], Batch [1137/2500], Loss: 0.30029192566871643\n",
      "Epoch [1/3], Batch [1138/2500], Loss: 0.2833841145038605\n",
      "Epoch [1/3], Batch [1139/2500], Loss: 0.13059449195861816\n",
      "Epoch [1/3], Batch [1140/2500], Loss: 0.2754455804824829\n",
      "Epoch [1/3], Batch [1141/2500], Loss: 0.23930266499519348\n",
      "Epoch [1/3], Batch [1142/2500], Loss: 0.1848507821559906\n",
      "Epoch [1/3], Batch [1143/2500], Loss: 0.12480249255895615\n",
      "Epoch [1/3], Batch [1144/2500], Loss: 0.15764030814170837\n",
      "Epoch [1/3], Batch [1145/2500], Loss: 0.27772682905197144\n",
      "Epoch [1/3], Batch [1146/2500], Loss: 0.05073937028646469\n",
      "Epoch [1/3], Batch [1147/2500], Loss: 0.10430426895618439\n",
      "Epoch [1/3], Batch [1148/2500], Loss: 0.09255532920360565\n",
      "Epoch [1/3], Batch [1149/2500], Loss: 0.3657117486000061\n",
      "Epoch [1/3], Batch [1150/2500], Loss: 0.38093557953834534\n",
      "Epoch [1/3], Batch [1151/2500], Loss: 0.4256212115287781\n",
      "Epoch [1/3], Batch [1152/2500], Loss: 0.23489980399608612\n",
      "Epoch [1/3], Batch [1153/2500], Loss: 0.41466978192329407\n",
      "Epoch [1/3], Batch [1154/2500], Loss: 0.4716343283653259\n",
      "Epoch [1/3], Batch [1155/2500], Loss: 0.11555590480566025\n",
      "Epoch [1/3], Batch [1156/2500], Loss: 0.49898895621299744\n",
      "Epoch [1/3], Batch [1157/2500], Loss: 0.4458830654621124\n",
      "Epoch [1/3], Batch [1158/2500], Loss: 0.31744149327278137\n",
      "Epoch [1/3], Batch [1159/2500], Loss: 0.12117843329906464\n",
      "Epoch [1/3], Batch [1160/2500], Loss: 0.30578914284706116\n",
      "Epoch [1/3], Batch [1161/2500], Loss: 0.12259258329868317\n",
      "Epoch [1/3], Batch [1162/2500], Loss: 0.23754462599754333\n",
      "Epoch [1/3], Batch [1163/2500], Loss: 0.10571333765983582\n",
      "Epoch [1/3], Batch [1164/2500], Loss: 0.10863746702671051\n",
      "Epoch [1/3], Batch [1165/2500], Loss: 0.07596135884523392\n",
      "Epoch [1/3], Batch [1166/2500], Loss: 0.22178980708122253\n",
      "Epoch [1/3], Batch [1167/2500], Loss: 0.12111034989356995\n",
      "Epoch [1/3], Batch [1168/2500], Loss: 0.041613318026065826\n",
      "Epoch [1/3], Batch [1169/2500], Loss: 0.7722970843315125\n",
      "Epoch [1/3], Batch [1170/2500], Loss: 0.4048730731010437\n",
      "Epoch [1/3], Batch [1171/2500], Loss: 0.3851087987422943\n",
      "Epoch [1/3], Batch [1172/2500], Loss: 0.14412474632263184\n",
      "Epoch [1/3], Batch [1173/2500], Loss: 0.541750967502594\n",
      "Epoch [1/3], Batch [1174/2500], Loss: 0.15287382900714874\n",
      "Epoch [1/3], Batch [1175/2500], Loss: 0.24636130034923553\n",
      "Epoch [1/3], Batch [1176/2500], Loss: 0.2111397683620453\n",
      "Epoch [1/3], Batch [1177/2500], Loss: 0.358430415391922\n",
      "Epoch [1/3], Batch [1178/2500], Loss: 0.47923925518989563\n",
      "Epoch [1/3], Batch [1179/2500], Loss: 0.23093515634536743\n",
      "Epoch [1/3], Batch [1180/2500], Loss: 0.17846226692199707\n",
      "Epoch [1/3], Batch [1181/2500], Loss: 0.35012128949165344\n",
      "Epoch [1/3], Batch [1182/2500], Loss: 0.18606707453727722\n",
      "Epoch [1/3], Batch [1183/2500], Loss: 0.1488800197839737\n",
      "Epoch [1/3], Batch [1184/2500], Loss: 0.2748055160045624\n",
      "Epoch [1/3], Batch [1185/2500], Loss: 0.1475486010313034\n",
      "Epoch [1/3], Batch [1186/2500], Loss: 0.14605818688869476\n",
      "Epoch [1/3], Batch [1187/2500], Loss: 0.11162936687469482\n",
      "Epoch [1/3], Batch [1188/2500], Loss: 0.25610312819480896\n",
      "Epoch [1/3], Batch [1189/2500], Loss: 0.22990404069423676\n",
      "Epoch [1/3], Batch [1190/2500], Loss: 0.17813441157341003\n",
      "Epoch [1/3], Batch [1191/2500], Loss: 0.25845858454704285\n",
      "Epoch [1/3], Batch [1192/2500], Loss: 0.2896153926849365\n",
      "Epoch [1/3], Batch [1193/2500], Loss: 0.1938587874174118\n",
      "Epoch [1/3], Batch [1194/2500], Loss: 0.30596375465393066\n",
      "Epoch [1/3], Batch [1195/2500], Loss: 0.09813462942838669\n",
      "Epoch [1/3], Batch [1196/2500], Loss: 0.1808922290802002\n",
      "Epoch [1/3], Batch [1197/2500], Loss: 0.4053072929382324\n",
      "Epoch [1/3], Batch [1198/2500], Loss: 0.23353616893291473\n",
      "Epoch [1/3], Batch [1199/2500], Loss: 0.2018480896949768\n",
      "Epoch [1/3], Batch [1200/2500], Loss: 0.1796724647283554\n",
      "Epoch [1/3], Batch [1201/2500], Loss: 0.3797060251235962\n",
      "Epoch [1/3], Batch [1202/2500], Loss: 0.11630561947822571\n",
      "Epoch [1/3], Batch [1203/2500], Loss: 0.4613478183746338\n",
      "Epoch [1/3], Batch [1204/2500], Loss: 0.2945968210697174\n",
      "Epoch [1/3], Batch [1205/2500], Loss: 0.6108070611953735\n",
      "Epoch [1/3], Batch [1206/2500], Loss: 0.25641536712646484\n",
      "Epoch [1/3], Batch [1207/2500], Loss: 0.23188556730747223\n",
      "Epoch [1/3], Batch [1208/2500], Loss: 0.09381997585296631\n",
      "Epoch [1/3], Batch [1209/2500], Loss: 0.1606123000383377\n",
      "Epoch [1/3], Batch [1210/2500], Loss: 0.6179823279380798\n",
      "Epoch [1/3], Batch [1211/2500], Loss: 0.22289153933525085\n",
      "Epoch [1/3], Batch [1212/2500], Loss: 0.3063981235027313\n",
      "Epoch [1/3], Batch [1213/2500], Loss: 0.6459870338439941\n",
      "Epoch [1/3], Batch [1214/2500], Loss: 0.3198850452899933\n",
      "Epoch [1/3], Batch [1215/2500], Loss: 0.21269376575946808\n",
      "Epoch [1/3], Batch [1216/2500], Loss: 0.2608333230018616\n",
      "Epoch [1/3], Batch [1217/2500], Loss: 0.09703980386257172\n",
      "Epoch [1/3], Batch [1218/2500], Loss: 0.10422375798225403\n",
      "Epoch [1/3], Batch [1219/2500], Loss: 0.2731636166572571\n",
      "Epoch [1/3], Batch [1220/2500], Loss: 0.056431323289871216\n",
      "Epoch [1/3], Batch [1221/2500], Loss: 0.4718824028968811\n",
      "Epoch [1/3], Batch [1222/2500], Loss: 0.13880248367786407\n",
      "Epoch [1/3], Batch [1223/2500], Loss: 0.15189813077449799\n",
      "Epoch [1/3], Batch [1224/2500], Loss: 0.22953402996063232\n",
      "Epoch [1/3], Batch [1225/2500], Loss: 0.16533778607845306\n",
      "Epoch [1/3], Batch [1226/2500], Loss: 0.43837374448776245\n",
      "Epoch [1/3], Batch [1227/2500], Loss: 0.22260414063930511\n",
      "Epoch [1/3], Batch [1228/2500], Loss: 0.26853662729263306\n",
      "Epoch [1/3], Batch [1229/2500], Loss: 0.30714577436447144\n",
      "Epoch [1/3], Batch [1230/2500], Loss: 0.1537134051322937\n",
      "Epoch [1/3], Batch [1231/2500], Loss: 0.430986225605011\n",
      "Epoch [1/3], Batch [1232/2500], Loss: 0.2601138949394226\n",
      "Epoch [1/3], Batch [1233/2500], Loss: 0.11700989305973053\n",
      "Epoch [1/3], Batch [1234/2500], Loss: 0.17636770009994507\n",
      "Epoch [1/3], Batch [1235/2500], Loss: 0.46483319997787476\n",
      "Epoch [1/3], Batch [1236/2500], Loss: 0.11776833236217499\n",
      "Epoch [1/3], Batch [1237/2500], Loss: 0.363140344619751\n",
      "Epoch [1/3], Batch [1238/2500], Loss: 0.14835773408412933\n",
      "Epoch [1/3], Batch [1239/2500], Loss: 0.2452191263437271\n",
      "Epoch [1/3], Batch [1240/2500], Loss: 0.15947940945625305\n",
      "Epoch [1/3], Batch [1241/2500], Loss: 0.161734476685524\n",
      "Epoch [1/3], Batch [1242/2500], Loss: 0.1864803284406662\n",
      "Epoch [1/3], Batch [1243/2500], Loss: 0.08575978875160217\n",
      "Epoch [1/3], Batch [1244/2500], Loss: 0.0672840029001236\n",
      "Epoch [1/3], Batch [1245/2500], Loss: 0.38175851106643677\n",
      "Epoch [1/3], Batch [1246/2500], Loss: 0.5043150782585144\n",
      "Epoch [1/3], Batch [1247/2500], Loss: 0.13858003914356232\n",
      "Epoch [1/3], Batch [1248/2500], Loss: 0.2792295217514038\n",
      "Epoch [1/3], Batch [1249/2500], Loss: 0.136336088180542\n",
      "Epoch [1/3], Batch [1250/2500], Loss: 0.06943172216415405\n",
      "Epoch [1/3], Batch [1251/2500], Loss: 0.3184834122657776\n",
      "Epoch [1/3], Batch [1252/2500], Loss: 0.11329799890518188\n",
      "Epoch [1/3], Batch [1253/2500], Loss: 0.18943361937999725\n",
      "Epoch [1/3], Batch [1254/2500], Loss: 0.12467579543590546\n",
      "Epoch [1/3], Batch [1255/2500], Loss: 0.2866436839103699\n",
      "Epoch [1/3], Batch [1256/2500], Loss: 0.09658759832382202\n",
      "Epoch [1/3], Batch [1257/2500], Loss: 0.12946368753910065\n",
      "Epoch [1/3], Batch [1258/2500], Loss: 0.19568373262882233\n",
      "Epoch [1/3], Batch [1259/2500], Loss: 0.15289592742919922\n",
      "Epoch [1/3], Batch [1260/2500], Loss: 0.4320274889469147\n",
      "Epoch [1/3], Batch [1261/2500], Loss: 0.27380838990211487\n",
      "Epoch [1/3], Batch [1262/2500], Loss: 0.052233386784791946\n",
      "Epoch [1/3], Batch [1263/2500], Loss: 0.4317823350429535\n",
      "Epoch [1/3], Batch [1264/2500], Loss: 0.04014028608798981\n",
      "Epoch [1/3], Batch [1265/2500], Loss: 0.2257765680551529\n",
      "Epoch [1/3], Batch [1266/2500], Loss: 0.37542709708213806\n",
      "Epoch [1/3], Batch [1267/2500], Loss: 0.037575140595436096\n",
      "Epoch [1/3], Batch [1268/2500], Loss: 0.3764006197452545\n",
      "Epoch [1/3], Batch [1269/2500], Loss: 0.29985517263412476\n",
      "Epoch [1/3], Batch [1270/2500], Loss: 0.4770769476890564\n",
      "Epoch [1/3], Batch [1271/2500], Loss: 0.21341080963611603\n",
      "Epoch [1/3], Batch [1272/2500], Loss: 0.5613179206848145\n",
      "Epoch [1/3], Batch [1273/2500], Loss: 0.19077250361442566\n",
      "Epoch [1/3], Batch [1274/2500], Loss: 0.20696409046649933\n",
      "Epoch [1/3], Batch [1275/2500], Loss: 0.455405592918396\n",
      "Epoch [1/3], Batch [1276/2500], Loss: 0.4841119050979614\n",
      "Epoch [1/3], Batch [1277/2500], Loss: 0.057796411216259\n",
      "Epoch [1/3], Batch [1278/2500], Loss: 0.6368584036827087\n",
      "Epoch [1/3], Batch [1279/2500], Loss: 0.13344214856624603\n",
      "Epoch [1/3], Batch [1280/2500], Loss: 0.1976008117198944\n",
      "Epoch [1/3], Batch [1281/2500], Loss: 0.08638748526573181\n",
      "Epoch [1/3], Batch [1282/2500], Loss: 0.09453325718641281\n",
      "Epoch [1/3], Batch [1283/2500], Loss: 0.2115611433982849\n",
      "Epoch [1/3], Batch [1284/2500], Loss: 0.4608810842037201\n",
      "Epoch [1/3], Batch [1285/2500], Loss: 0.4434622526168823\n",
      "Epoch [1/3], Batch [1286/2500], Loss: 0.19917739927768707\n",
      "Epoch [1/3], Batch [1287/2500], Loss: 0.15750306844711304\n",
      "Epoch [1/3], Batch [1288/2500], Loss: 0.21330703794956207\n",
      "Epoch [1/3], Batch [1289/2500], Loss: 0.3151263892650604\n",
      "Epoch [1/3], Batch [1290/2500], Loss: 0.43311402201652527\n",
      "Epoch [1/3], Batch [1291/2500], Loss: 0.2772356867790222\n",
      "Epoch [1/3], Batch [1292/2500], Loss: 0.15141838788986206\n",
      "Epoch [1/3], Batch [1293/2500], Loss: 0.5128178596496582\n",
      "Epoch [1/3], Batch [1294/2500], Loss: 0.1356355845928192\n",
      "Epoch [1/3], Batch [1295/2500], Loss: 0.29532983899116516\n",
      "Epoch [1/3], Batch [1296/2500], Loss: 0.4594975709915161\n",
      "Epoch [1/3], Batch [1297/2500], Loss: 0.34383881092071533\n",
      "Epoch [1/3], Batch [1298/2500], Loss: 0.289311945438385\n",
      "Epoch [1/3], Batch [1299/2500], Loss: 0.1798553168773651\n",
      "Epoch [1/3], Batch [1300/2500], Loss: 0.2896216809749603\n",
      "Epoch [1/3], Batch [1301/2500], Loss: 0.30191221833229065\n",
      "Epoch [1/3], Batch [1302/2500], Loss: 0.11591853946447372\n",
      "Epoch [1/3], Batch [1303/2500], Loss: 0.1863902509212494\n",
      "Epoch [1/3], Batch [1304/2500], Loss: 0.07180938124656677\n",
      "Epoch [1/3], Batch [1305/2500], Loss: 0.16752073168754578\n",
      "Epoch [1/3], Batch [1306/2500], Loss: 0.1854150891304016\n",
      "Epoch [1/3], Batch [1307/2500], Loss: 0.09640975296497345\n",
      "Epoch [1/3], Batch [1308/2500], Loss: 0.2786353528499603\n",
      "Epoch [1/3], Batch [1309/2500], Loss: 0.154502272605896\n",
      "Epoch [1/3], Batch [1310/2500], Loss: 0.29725736379623413\n",
      "Epoch [1/3], Batch [1311/2500], Loss: 0.2738686203956604\n",
      "Epoch [1/3], Batch [1312/2500], Loss: 0.11160647869110107\n",
      "Epoch [1/3], Batch [1313/2500], Loss: 0.5956178307533264\n",
      "Epoch [1/3], Batch [1314/2500], Loss: 0.14642229676246643\n",
      "Epoch [1/3], Batch [1315/2500], Loss: 0.15623003244400024\n",
      "Epoch [1/3], Batch [1316/2500], Loss: 0.08363372087478638\n",
      "Epoch [1/3], Batch [1317/2500], Loss: 0.4269587993621826\n",
      "Epoch [1/3], Batch [1318/2500], Loss: 0.41944268345832825\n",
      "Epoch [1/3], Batch [1319/2500], Loss: 0.16722220182418823\n",
      "Epoch [1/3], Batch [1320/2500], Loss: 0.30579090118408203\n",
      "Epoch [1/3], Batch [1321/2500], Loss: 0.22226043045520782\n",
      "Epoch [1/3], Batch [1322/2500], Loss: 0.049218349158763885\n",
      "Epoch [1/3], Batch [1323/2500], Loss: 0.36525025963783264\n",
      "Epoch [1/3], Batch [1324/2500], Loss: 0.1052207499742508\n",
      "Epoch [1/3], Batch [1325/2500], Loss: 0.11477182805538177\n",
      "Epoch [1/3], Batch [1326/2500], Loss: 0.22999463975429535\n",
      "Epoch [1/3], Batch [1327/2500], Loss: 0.5168433785438538\n",
      "Epoch [1/3], Batch [1328/2500], Loss: 0.15308822691440582\n",
      "Epoch [1/3], Batch [1329/2500], Loss: 0.21473954617977142\n",
      "Epoch [1/3], Batch [1330/2500], Loss: 0.09110546857118607\n",
      "Epoch [1/3], Batch [1331/2500], Loss: 0.04433858394622803\n",
      "Epoch [1/3], Batch [1332/2500], Loss: 0.08027152717113495\n",
      "Epoch [1/3], Batch [1333/2500], Loss: 0.19420376420021057\n",
      "Epoch [1/3], Batch [1334/2500], Loss: 0.47392746806144714\n",
      "Epoch [1/3], Batch [1335/2500], Loss: 0.034997954964637756\n",
      "Epoch [1/3], Batch [1336/2500], Loss: 0.4887475371360779\n",
      "Epoch [1/3], Batch [1337/2500], Loss: 0.07844260334968567\n",
      "Epoch [1/3], Batch [1338/2500], Loss: 0.35014063119888306\n",
      "Epoch [1/3], Batch [1339/2500], Loss: 0.3283414840698242\n",
      "Epoch [1/3], Batch [1340/2500], Loss: 0.43305739760398865\n",
      "Epoch [1/3], Batch [1341/2500], Loss: 0.13661178946495056\n",
      "Epoch [1/3], Batch [1342/2500], Loss: 0.048989295959472656\n",
      "Epoch [1/3], Batch [1343/2500], Loss: 0.16063880920410156\n",
      "Epoch [1/3], Batch [1344/2500], Loss: 0.30272507667541504\n",
      "Epoch [1/3], Batch [1345/2500], Loss: 0.39364174008369446\n",
      "Epoch [1/3], Batch [1346/2500], Loss: 0.22245100140571594\n",
      "Epoch [1/3], Batch [1347/2500], Loss: 0.31354475021362305\n",
      "Epoch [1/3], Batch [1348/2500], Loss: 0.4213487207889557\n",
      "Epoch [1/3], Batch [1349/2500], Loss: 0.19741849601268768\n",
      "Epoch [1/3], Batch [1350/2500], Loss: 0.07362792640924454\n",
      "Epoch [1/3], Batch [1351/2500], Loss: 0.10245158523321152\n",
      "Epoch [1/3], Batch [1352/2500], Loss: 0.16421233117580414\n",
      "Epoch [1/3], Batch [1353/2500], Loss: 0.5247095823287964\n",
      "Epoch [1/3], Batch [1354/2500], Loss: 0.23888085782527924\n",
      "Epoch [1/3], Batch [1355/2500], Loss: 0.652737021446228\n",
      "Epoch [1/3], Batch [1356/2500], Loss: 0.541915237903595\n",
      "Epoch [1/3], Batch [1357/2500], Loss: 0.4168279469013214\n",
      "Epoch [1/3], Batch [1358/2500], Loss: 0.1790168136358261\n",
      "Epoch [1/3], Batch [1359/2500], Loss: 0.09574385732412338\n",
      "Epoch [1/3], Batch [1360/2500], Loss: 0.1541593372821808\n",
      "Epoch [1/3], Batch [1361/2500], Loss: 0.7874578237533569\n",
      "Epoch [1/3], Batch [1362/2500], Loss: 0.11849460005760193\n",
      "Epoch [1/3], Batch [1363/2500], Loss: 0.1386364996433258\n",
      "Epoch [1/3], Batch [1364/2500], Loss: 0.23713484406471252\n",
      "Epoch [1/3], Batch [1365/2500], Loss: 0.238651305437088\n",
      "Epoch [1/3], Batch [1366/2500], Loss: 0.2308652698993683\n",
      "Epoch [1/3], Batch [1367/2500], Loss: 0.3954249918460846\n",
      "Epoch [1/3], Batch [1368/2500], Loss: 0.29624849557876587\n",
      "Epoch [1/3], Batch [1369/2500], Loss: 0.23265156149864197\n",
      "Epoch [1/3], Batch [1370/2500], Loss: 0.08307422697544098\n",
      "Epoch [1/3], Batch [1371/2500], Loss: 0.40951693058013916\n",
      "Epoch [1/3], Batch [1372/2500], Loss: 0.08110526949167252\n",
      "Epoch [1/3], Batch [1373/2500], Loss: 0.2689633071422577\n",
      "Epoch [1/3], Batch [1374/2500], Loss: 0.41346275806427\n",
      "Epoch [1/3], Batch [1375/2500], Loss: 0.21558327972888947\n",
      "Epoch [1/3], Batch [1376/2500], Loss: 0.23471079766750336\n",
      "Epoch [1/3], Batch [1377/2500], Loss: 0.28584200143814087\n",
      "Epoch [1/3], Batch [1378/2500], Loss: 0.1558021456003189\n",
      "Epoch [1/3], Batch [1379/2500], Loss: 0.2888016700744629\n",
      "Epoch [1/3], Batch [1380/2500], Loss: 0.2839891016483307\n",
      "Epoch [1/3], Batch [1381/2500], Loss: 0.2076420783996582\n",
      "Epoch [1/3], Batch [1382/2500], Loss: 0.30778729915618896\n",
      "Epoch [1/3], Batch [1383/2500], Loss: 0.5992360711097717\n",
      "Epoch [1/3], Batch [1384/2500], Loss: 0.22675170004367828\n",
      "Epoch [1/3], Batch [1385/2500], Loss: 0.3733711838722229\n",
      "Epoch [1/3], Batch [1386/2500], Loss: 0.084409698843956\n",
      "Epoch [1/3], Batch [1387/2500], Loss: 0.09556225687265396\n",
      "Epoch [1/3], Batch [1388/2500], Loss: 0.3194856643676758\n",
      "Epoch [1/3], Batch [1389/2500], Loss: 0.1624358594417572\n",
      "Epoch [1/3], Batch [1390/2500], Loss: 0.05523207411170006\n",
      "Epoch [1/3], Batch [1391/2500], Loss: 0.13514837622642517\n",
      "Epoch [1/3], Batch [1392/2500], Loss: 0.1373610496520996\n",
      "Epoch [1/3], Batch [1393/2500], Loss: 0.3314898610115051\n",
      "Epoch [1/3], Batch [1394/2500], Loss: 0.271503210067749\n",
      "Epoch [1/3], Batch [1395/2500], Loss: 0.25891342759132385\n",
      "Epoch [1/3], Batch [1396/2500], Loss: 0.35035431385040283\n",
      "Epoch [1/3], Batch [1397/2500], Loss: 0.15575698018074036\n",
      "Epoch [1/3], Batch [1398/2500], Loss: 0.31525272130966187\n",
      "Epoch [1/3], Batch [1399/2500], Loss: 0.1940108686685562\n",
      "Epoch [1/3], Batch [1400/2500], Loss: 0.23161064088344574\n",
      "Epoch [1/3], Batch [1401/2500], Loss: 0.27597567439079285\n",
      "Epoch [1/3], Batch [1402/2500], Loss: 0.15878811478614807\n",
      "Epoch [1/3], Batch [1403/2500], Loss: 0.49935606122016907\n",
      "Epoch [1/3], Batch [1404/2500], Loss: 0.18596398830413818\n",
      "Epoch [1/3], Batch [1405/2500], Loss: 0.36407309770584106\n",
      "Epoch [1/3], Batch [1406/2500], Loss: 0.11467363685369492\n",
      "Epoch [1/3], Batch [1407/2500], Loss: 0.2874116003513336\n",
      "Epoch [1/3], Batch [1408/2500], Loss: 0.3307247757911682\n",
      "Epoch [1/3], Batch [1409/2500], Loss: 0.40451374650001526\n",
      "Epoch [1/3], Batch [1410/2500], Loss: 0.14656122028827667\n",
      "Epoch [1/3], Batch [1411/2500], Loss: 0.1948302835226059\n",
      "Epoch [1/3], Batch [1412/2500], Loss: 0.15467797219753265\n",
      "Epoch [1/3], Batch [1413/2500], Loss: 0.049855753779411316\n",
      "Epoch [1/3], Batch [1414/2500], Loss: 0.37135234475135803\n",
      "Epoch [1/3], Batch [1415/2500], Loss: 0.33763015270233154\n",
      "Epoch [1/3], Batch [1416/2500], Loss: 0.3078596591949463\n",
      "Epoch [1/3], Batch [1417/2500], Loss: 0.2493392378091812\n",
      "Epoch [1/3], Batch [1418/2500], Loss: 0.186135396361351\n",
      "Epoch [1/3], Batch [1419/2500], Loss: 0.2608829140663147\n",
      "Epoch [1/3], Batch [1420/2500], Loss: 0.3832261562347412\n",
      "Epoch [1/3], Batch [1421/2500], Loss: 0.03218726068735123\n",
      "Epoch [1/3], Batch [1422/2500], Loss: 0.09370400011539459\n",
      "Epoch [1/3], Batch [1423/2500], Loss: 0.08826053887605667\n",
      "Epoch [1/3], Batch [1424/2500], Loss: 0.4584512412548065\n",
      "Epoch [1/3], Batch [1425/2500], Loss: 0.1891920566558838\n",
      "Epoch [1/3], Batch [1426/2500], Loss: 0.1112767830491066\n",
      "Epoch [1/3], Batch [1427/2500], Loss: 0.05586539953947067\n",
      "Epoch [1/3], Batch [1428/2500], Loss: 0.23987683653831482\n",
      "Epoch [1/3], Batch [1429/2500], Loss: 0.8030702471733093\n",
      "Epoch [1/3], Batch [1430/2500], Loss: 0.20605090260505676\n",
      "Epoch [1/3], Batch [1431/2500], Loss: 0.46364593505859375\n",
      "Epoch [1/3], Batch [1432/2500], Loss: 0.05719975382089615\n",
      "Epoch [1/3], Batch [1433/2500], Loss: 0.059142161160707474\n",
      "Epoch [1/3], Batch [1434/2500], Loss: 0.1499398797750473\n",
      "Epoch [1/3], Batch [1435/2500], Loss: 0.18626108765602112\n",
      "Epoch [1/3], Batch [1436/2500], Loss: 0.6353815793991089\n",
      "Epoch [1/3], Batch [1437/2500], Loss: 0.18200154602527618\n",
      "Epoch [1/3], Batch [1438/2500], Loss: 0.20041804015636444\n",
      "Epoch [1/3], Batch [1439/2500], Loss: 0.30153223872184753\n",
      "Epoch [1/3], Batch [1440/2500], Loss: 0.26725661754608154\n",
      "Epoch [1/3], Batch [1441/2500], Loss: 0.40029239654541016\n",
      "Epoch [1/3], Batch [1442/2500], Loss: 0.10532932728528976\n",
      "Epoch [1/3], Batch [1443/2500], Loss: 0.2824621796607971\n",
      "Epoch [1/3], Batch [1444/2500], Loss: 0.14634868502616882\n",
      "Epoch [1/3], Batch [1445/2500], Loss: 0.15095631778240204\n",
      "Epoch [1/3], Batch [1446/2500], Loss: 0.31533268094062805\n",
      "Epoch [1/3], Batch [1447/2500], Loss: 0.24973517656326294\n",
      "Epoch [1/3], Batch [1448/2500], Loss: 0.18909932672977448\n",
      "Epoch [1/3], Batch [1449/2500], Loss: 0.23884549736976624\n",
      "Epoch [1/3], Batch [1450/2500], Loss: 0.2861224114894867\n",
      "Epoch [1/3], Batch [1451/2500], Loss: 0.48113778233528137\n",
      "Epoch [1/3], Batch [1452/2500], Loss: 0.44687074422836304\n",
      "Epoch [1/3], Batch [1453/2500], Loss: 0.37137898802757263\n",
      "Epoch [1/3], Batch [1454/2500], Loss: 0.4127616286277771\n",
      "Epoch [1/3], Batch [1455/2500], Loss: 0.20368781685829163\n",
      "Epoch [1/3], Batch [1456/2500], Loss: 0.17283502221107483\n",
      "Epoch [1/3], Batch [1457/2500], Loss: 0.340121328830719\n",
      "Epoch [1/3], Batch [1458/2500], Loss: 0.278441458940506\n",
      "Epoch [1/3], Batch [1459/2500], Loss: 0.1351572424173355\n",
      "Epoch [1/3], Batch [1460/2500], Loss: 0.29247748851776123\n",
      "Epoch [1/3], Batch [1461/2500], Loss: 0.24693605303764343\n",
      "Epoch [1/3], Batch [1462/2500], Loss: 0.11900573968887329\n",
      "Epoch [1/3], Batch [1463/2500], Loss: 0.19654589891433716\n",
      "Epoch [1/3], Batch [1464/2500], Loss: 0.46957576274871826\n",
      "Epoch [1/3], Batch [1465/2500], Loss: 0.07546408474445343\n",
      "Epoch [1/3], Batch [1466/2500], Loss: 0.47512176632881165\n",
      "Epoch [1/3], Batch [1467/2500], Loss: 0.3289515972137451\n",
      "Epoch [1/3], Batch [1468/2500], Loss: 0.25004836916923523\n",
      "Epoch [1/3], Batch [1469/2500], Loss: 0.34937870502471924\n",
      "Epoch [1/3], Batch [1470/2500], Loss: 0.13386347889900208\n",
      "Epoch [1/3], Batch [1471/2500], Loss: 0.29023200273513794\n",
      "Epoch [1/3], Batch [1472/2500], Loss: 0.15922628343105316\n",
      "Epoch [1/3], Batch [1473/2500], Loss: 0.28512996435165405\n",
      "Epoch [1/3], Batch [1474/2500], Loss: 0.0303172767162323\n",
      "Epoch [1/3], Batch [1475/2500], Loss: 0.03328091651201248\n",
      "Epoch [1/3], Batch [1476/2500], Loss: 0.51777184009552\n",
      "Epoch [1/3], Batch [1477/2500], Loss: 0.35454875230789185\n",
      "Epoch [1/3], Batch [1478/2500], Loss: 0.15594355762004852\n",
      "Epoch [1/3], Batch [1479/2500], Loss: 0.2255154252052307\n",
      "Epoch [1/3], Batch [1480/2500], Loss: 0.3028210401535034\n",
      "Epoch [1/3], Batch [1481/2500], Loss: 0.25649717450141907\n",
      "Epoch [1/3], Batch [1482/2500], Loss: 0.47023090720176697\n",
      "Epoch [1/3], Batch [1483/2500], Loss: 0.6303311586380005\n",
      "Epoch [1/3], Batch [1484/2500], Loss: 0.1478382647037506\n",
      "Epoch [1/3], Batch [1485/2500], Loss: 0.2374429553747177\n",
      "Epoch [1/3], Batch [1486/2500], Loss: 0.24339117109775543\n",
      "Epoch [1/3], Batch [1487/2500], Loss: 0.08794527500867844\n",
      "Epoch [1/3], Batch [1488/2500], Loss: 0.10220041871070862\n",
      "Epoch [1/3], Batch [1489/2500], Loss: 0.09964865446090698\n",
      "Epoch [1/3], Batch [1490/2500], Loss: 0.10974374413490295\n",
      "Epoch [1/3], Batch [1491/2500], Loss: 0.43383437395095825\n",
      "Epoch [1/3], Batch [1492/2500], Loss: 0.4884607195854187\n",
      "Epoch [1/3], Batch [1493/2500], Loss: 0.4030236005783081\n",
      "Epoch [1/3], Batch [1494/2500], Loss: 0.271586149930954\n",
      "Epoch [1/3], Batch [1495/2500], Loss: 0.2405855804681778\n",
      "Epoch [1/3], Batch [1496/2500], Loss: 0.07350604981184006\n",
      "Epoch [1/3], Batch [1497/2500], Loss: 0.13933074474334717\n",
      "Epoch [1/3], Batch [1498/2500], Loss: 0.24721121788024902\n",
      "Epoch [1/3], Batch [1499/2500], Loss: 0.23355360329151154\n",
      "Epoch [1/3], Batch [1500/2500], Loss: 0.19078081846237183\n",
      "Epoch [1/3], Batch [1501/2500], Loss: 0.2919918894767761\n",
      "Epoch [1/3], Batch [1502/2500], Loss: 0.14064782857894897\n",
      "Epoch [1/3], Batch [1503/2500], Loss: 0.342526912689209\n",
      "Epoch [1/3], Batch [1504/2500], Loss: 0.09135908633470535\n",
      "Epoch [1/3], Batch [1505/2500], Loss: 0.02515215240418911\n",
      "Epoch [1/3], Batch [1506/2500], Loss: 0.15736892819404602\n",
      "Epoch [1/3], Batch [1507/2500], Loss: 0.22139067947864532\n",
      "Epoch [1/3], Batch [1508/2500], Loss: 0.32168713212013245\n",
      "Epoch [1/3], Batch [1509/2500], Loss: 0.12165509164333344\n",
      "Epoch [1/3], Batch [1510/2500], Loss: 0.9528476595878601\n",
      "Epoch [1/3], Batch [1511/2500], Loss: 0.47889721393585205\n",
      "Epoch [1/3], Batch [1512/2500], Loss: 0.16133348643779755\n",
      "Epoch [1/3], Batch [1513/2500], Loss: 0.17722678184509277\n",
      "Epoch [1/3], Batch [1514/2500], Loss: 0.6623556017875671\n",
      "Epoch [1/3], Batch [1515/2500], Loss: 0.18570955097675323\n",
      "Epoch [1/3], Batch [1516/2500], Loss: 0.41849285364151\n",
      "Epoch [1/3], Batch [1517/2500], Loss: 0.10654285550117493\n",
      "Epoch [1/3], Batch [1518/2500], Loss: 0.08194444328546524\n",
      "Epoch [1/3], Batch [1519/2500], Loss: 0.20628586411476135\n",
      "Epoch [1/3], Batch [1520/2500], Loss: 0.3836475610733032\n",
      "Epoch [1/3], Batch [1521/2500], Loss: 0.2611965537071228\n",
      "Epoch [1/3], Batch [1522/2500], Loss: 0.11311788856983185\n",
      "Epoch [1/3], Batch [1523/2500], Loss: 0.20450066030025482\n",
      "Epoch [1/3], Batch [1524/2500], Loss: 0.28884512186050415\n",
      "Epoch [1/3], Batch [1525/2500], Loss: 0.47282516956329346\n",
      "Epoch [1/3], Batch [1526/2500], Loss: 0.6492241024971008\n",
      "Epoch [1/3], Batch [1527/2500], Loss: 0.10260745882987976\n",
      "Epoch [1/3], Batch [1528/2500], Loss: 0.15520459413528442\n",
      "Epoch [1/3], Batch [1529/2500], Loss: 0.21944458782672882\n",
      "Epoch [1/3], Batch [1530/2500], Loss: 0.35351887345314026\n",
      "Epoch [1/3], Batch [1531/2500], Loss: 0.09205581992864609\n",
      "Epoch [1/3], Batch [1532/2500], Loss: 0.24838480353355408\n",
      "Epoch [1/3], Batch [1533/2500], Loss: 0.2150217890739441\n",
      "Epoch [1/3], Batch [1534/2500], Loss: 0.38898903131484985\n",
      "Epoch [1/3], Batch [1535/2500], Loss: 0.10586689412593842\n",
      "Epoch [1/3], Batch [1536/2500], Loss: 0.08827997744083405\n",
      "Epoch [1/3], Batch [1537/2500], Loss: 0.25003522634506226\n",
      "Epoch [1/3], Batch [1538/2500], Loss: 0.27033647894859314\n",
      "Epoch [1/3], Batch [1539/2500], Loss: 0.5685833692550659\n",
      "Epoch [1/3], Batch [1540/2500], Loss: 0.41966748237609863\n",
      "Epoch [1/3], Batch [1541/2500], Loss: 0.2418643683195114\n",
      "Epoch [1/3], Batch [1542/2500], Loss: 0.35241633653640747\n",
      "Epoch [1/3], Batch [1543/2500], Loss: 0.1921699047088623\n",
      "Epoch [1/3], Batch [1544/2500], Loss: 0.1441810578107834\n",
      "Epoch [1/3], Batch [1545/2500], Loss: 0.25012147426605225\n",
      "Epoch [1/3], Batch [1546/2500], Loss: 0.13530369102954865\n",
      "Epoch [1/3], Batch [1547/2500], Loss: 0.403594434261322\n",
      "Epoch [1/3], Batch [1548/2500], Loss: 0.15053506195545197\n",
      "Epoch [1/3], Batch [1549/2500], Loss: 0.1676335483789444\n",
      "Epoch [1/3], Batch [1550/2500], Loss: 0.30655914545059204\n",
      "Epoch [1/3], Batch [1551/2500], Loss: 0.25266703963279724\n",
      "Epoch [1/3], Batch [1552/2500], Loss: 0.08085629343986511\n",
      "Epoch [1/3], Batch [1553/2500], Loss: 0.07579436898231506\n",
      "Epoch [1/3], Batch [1554/2500], Loss: 0.2362271249294281\n",
      "Epoch [1/3], Batch [1555/2500], Loss: 0.1353648453950882\n",
      "Epoch [1/3], Batch [1556/2500], Loss: 0.14597338438034058\n",
      "Epoch [1/3], Batch [1557/2500], Loss: 0.2696162164211273\n",
      "Epoch [1/3], Batch [1558/2500], Loss: 0.31779244542121887\n",
      "Epoch [1/3], Batch [1559/2500], Loss: 0.3124349117279053\n",
      "Epoch [1/3], Batch [1560/2500], Loss: 0.21715475618839264\n",
      "Epoch [1/3], Batch [1561/2500], Loss: 0.3596532344818115\n",
      "Epoch [1/3], Batch [1562/2500], Loss: 0.1718185544013977\n",
      "Epoch [1/3], Batch [1563/2500], Loss: 0.4808528423309326\n",
      "Epoch [1/3], Batch [1564/2500], Loss: 0.03666362911462784\n",
      "Epoch [1/3], Batch [1565/2500], Loss: 0.3998042345046997\n",
      "Epoch [1/3], Batch [1566/2500], Loss: 0.2062239944934845\n",
      "Epoch [1/3], Batch [1567/2500], Loss: 0.19985541701316833\n",
      "Epoch [1/3], Batch [1568/2500], Loss: 0.35895276069641113\n",
      "Epoch [1/3], Batch [1569/2500], Loss: 0.20347389578819275\n",
      "Epoch [1/3], Batch [1570/2500], Loss: 0.546904444694519\n",
      "Epoch [1/3], Batch [1571/2500], Loss: 0.07855784147977829\n",
      "Epoch [1/3], Batch [1572/2500], Loss: 0.17595426738262177\n",
      "Epoch [1/3], Batch [1573/2500], Loss: 0.23511113226413727\n",
      "Epoch [1/3], Batch [1574/2500], Loss: 0.30561545491218567\n",
      "Epoch [1/3], Batch [1575/2500], Loss: 0.11999759823083878\n",
      "Epoch [1/3], Batch [1576/2500], Loss: 0.4018053412437439\n",
      "Epoch [1/3], Batch [1577/2500], Loss: 0.12519922852516174\n",
      "Epoch [1/3], Batch [1578/2500], Loss: 0.45042726397514343\n",
      "Epoch [1/3], Batch [1579/2500], Loss: 0.23875433206558228\n",
      "Epoch [1/3], Batch [1580/2500], Loss: 0.12969885766506195\n",
      "Epoch [1/3], Batch [1581/2500], Loss: 0.19434691965579987\n",
      "Epoch [1/3], Batch [1582/2500], Loss: 0.2625901699066162\n",
      "Epoch [1/3], Batch [1583/2500], Loss: 0.19321218132972717\n",
      "Epoch [1/3], Batch [1584/2500], Loss: 0.15230810642242432\n",
      "Epoch [1/3], Batch [1585/2500], Loss: 0.18828266859054565\n",
      "Epoch [1/3], Batch [1586/2500], Loss: 0.30146530270576477\n",
      "Epoch [1/3], Batch [1587/2500], Loss: 0.15424013137817383\n",
      "Epoch [1/3], Batch [1588/2500], Loss: 0.16146455705165863\n",
      "Epoch [1/3], Batch [1589/2500], Loss: 0.03201204910874367\n",
      "Epoch [1/3], Batch [1590/2500], Loss: 0.3153536915779114\n",
      "Epoch [1/3], Batch [1591/2500], Loss: 0.6719475388526917\n",
      "Epoch [1/3], Batch [1592/2500], Loss: 0.3589002192020416\n",
      "Epoch [1/3], Batch [1593/2500], Loss: 0.10878586769104004\n",
      "Epoch [1/3], Batch [1594/2500], Loss: 0.08151961863040924\n",
      "Epoch [1/3], Batch [1595/2500], Loss: 0.06165197864174843\n",
      "Epoch [1/3], Batch [1596/2500], Loss: 0.4048618972301483\n",
      "Epoch [1/3], Batch [1597/2500], Loss: 0.1563033163547516\n",
      "Epoch [1/3], Batch [1598/2500], Loss: 0.26042434573173523\n",
      "Epoch [1/3], Batch [1599/2500], Loss: 0.097553551197052\n",
      "Epoch [1/3], Batch [1600/2500], Loss: 0.20857971906661987\n",
      "Epoch [1/3], Batch [1601/2500], Loss: 0.4378114640712738\n",
      "Epoch [1/3], Batch [1602/2500], Loss: 0.27696970105171204\n",
      "Epoch [1/3], Batch [1603/2500], Loss: 0.11637818813323975\n",
      "Epoch [1/3], Batch [1604/2500], Loss: 0.3295086622238159\n",
      "Epoch [1/3], Batch [1605/2500], Loss: 0.020653707906603813\n",
      "Epoch [1/3], Batch [1606/2500], Loss: 0.1919822245836258\n",
      "Epoch [1/3], Batch [1607/2500], Loss: 0.429981529712677\n",
      "Epoch [1/3], Batch [1608/2500], Loss: 0.061284299939870834\n",
      "Epoch [1/3], Batch [1609/2500], Loss: 0.21354934573173523\n",
      "Epoch [1/3], Batch [1610/2500], Loss: 0.39160996675491333\n",
      "Epoch [1/3], Batch [1611/2500], Loss: 0.24539780616760254\n",
      "Epoch [1/3], Batch [1612/2500], Loss: 0.09319152683019638\n",
      "Epoch [1/3], Batch [1613/2500], Loss: 0.2141527235507965\n",
      "Epoch [1/3], Batch [1614/2500], Loss: 0.2977551221847534\n",
      "Epoch [1/3], Batch [1615/2500], Loss: 0.1885286420583725\n",
      "Epoch [1/3], Batch [1616/2500], Loss: 0.1965392380952835\n",
      "Epoch [1/3], Batch [1617/2500], Loss: 0.11346670985221863\n",
      "Epoch [1/3], Batch [1618/2500], Loss: 0.224277064204216\n",
      "Epoch [1/3], Batch [1619/2500], Loss: 0.25072017312049866\n",
      "Epoch [1/3], Batch [1620/2500], Loss: 0.18932969868183136\n",
      "Epoch [1/3], Batch [1621/2500], Loss: 0.1868349015712738\n",
      "Epoch [1/3], Batch [1622/2500], Loss: 0.16071899235248566\n",
      "Epoch [1/3], Batch [1623/2500], Loss: 0.44633299112319946\n",
      "Epoch [1/3], Batch [1624/2500], Loss: 0.12366178631782532\n",
      "Epoch [1/3], Batch [1625/2500], Loss: 0.29991981387138367\n",
      "Epoch [1/3], Batch [1626/2500], Loss: 0.14656248688697815\n",
      "Epoch [1/3], Batch [1627/2500], Loss: 0.16564087569713593\n",
      "Epoch [1/3], Batch [1628/2500], Loss: 0.16272461414337158\n",
      "Epoch [1/3], Batch [1629/2500], Loss: 0.20727655291557312\n",
      "Epoch [1/3], Batch [1630/2500], Loss: 0.4583231806755066\n",
      "Epoch [1/3], Batch [1631/2500], Loss: 0.12417560070753098\n",
      "Epoch [1/3], Batch [1632/2500], Loss: 0.2207408994436264\n",
      "Epoch [1/3], Batch [1633/2500], Loss: 0.24483589828014374\n",
      "Epoch [1/3], Batch [1634/2500], Loss: 0.24876263737678528\n",
      "Epoch [1/3], Batch [1635/2500], Loss: 0.0612550750374794\n",
      "Epoch [1/3], Batch [1636/2500], Loss: 0.2478369027376175\n",
      "Epoch [1/3], Batch [1637/2500], Loss: 0.22836250066757202\n",
      "Epoch [1/3], Batch [1638/2500], Loss: 0.5822084546089172\n",
      "Epoch [1/3], Batch [1639/2500], Loss: 0.3603653311729431\n",
      "Epoch [1/3], Batch [1640/2500], Loss: 0.19785967469215393\n",
      "Epoch [1/3], Batch [1641/2500], Loss: 0.14394977688789368\n",
      "Epoch [1/3], Batch [1642/2500], Loss: 0.36843985319137573\n",
      "Epoch [1/3], Batch [1643/2500], Loss: 0.16450084745883942\n",
      "Epoch [1/3], Batch [1644/2500], Loss: 0.3132147192955017\n",
      "Epoch [1/3], Batch [1645/2500], Loss: 0.1672697514295578\n",
      "Epoch [1/3], Batch [1646/2500], Loss: 0.3596510887145996\n",
      "Epoch [1/3], Batch [1647/2500], Loss: 0.4397350251674652\n",
      "Epoch [1/3], Batch [1648/2500], Loss: 0.7105081677436829\n",
      "Epoch [1/3], Batch [1649/2500], Loss: 0.18388843536376953\n",
      "Epoch [1/3], Batch [1650/2500], Loss: 0.1914047747850418\n",
      "Epoch [1/3], Batch [1651/2500], Loss: 0.12191818654537201\n",
      "Epoch [1/3], Batch [1652/2500], Loss: 0.10729694366455078\n",
      "Epoch [1/3], Batch [1653/2500], Loss: 0.29221585392951965\n",
      "Epoch [1/3], Batch [1654/2500], Loss: 0.051215559244155884\n",
      "Epoch [1/3], Batch [1655/2500], Loss: 0.23012390732765198\n",
      "Epoch [1/3], Batch [1656/2500], Loss: 0.07729693502187729\n",
      "Epoch [1/3], Batch [1657/2500], Loss: 0.5213969349861145\n",
      "Epoch [1/3], Batch [1658/2500], Loss: 0.2496587634086609\n",
      "Epoch [1/3], Batch [1659/2500], Loss: 0.16061483323574066\n",
      "Epoch [1/3], Batch [1660/2500], Loss: 0.3640396296977997\n",
      "Epoch [1/3], Batch [1661/2500], Loss: 0.3771894872188568\n",
      "Epoch [1/3], Batch [1662/2500], Loss: 0.22237755358219147\n",
      "Epoch [1/3], Batch [1663/2500], Loss: 0.30396324396133423\n",
      "Epoch [1/3], Batch [1664/2500], Loss: 0.2354186326265335\n",
      "Epoch [1/3], Batch [1665/2500], Loss: 0.3450254797935486\n",
      "Epoch [1/3], Batch [1666/2500], Loss: 0.3259628117084503\n",
      "Epoch [1/3], Batch [1667/2500], Loss: 0.5645045638084412\n",
      "Epoch [1/3], Batch [1668/2500], Loss: 0.45714515447616577\n",
      "Epoch [1/3], Batch [1669/2500], Loss: 0.0992172434926033\n",
      "Epoch [1/3], Batch [1670/2500], Loss: 0.3679269850254059\n",
      "Epoch [1/3], Batch [1671/2500], Loss: 0.5144194960594177\n",
      "Epoch [1/3], Batch [1672/2500], Loss: 0.14397555589675903\n",
      "Epoch [1/3], Batch [1673/2500], Loss: 0.10280284285545349\n",
      "Epoch [1/3], Batch [1674/2500], Loss: 0.23994602262973785\n",
      "Epoch [1/3], Batch [1675/2500], Loss: 0.4074224531650543\n",
      "Epoch [1/3], Batch [1676/2500], Loss: 0.17035652697086334\n",
      "Epoch [1/3], Batch [1677/2500], Loss: 0.2086014747619629\n",
      "Epoch [1/3], Batch [1678/2500], Loss: 0.2379455417394638\n",
      "Epoch [1/3], Batch [1679/2500], Loss: 0.13201801478862762\n",
      "Epoch [1/3], Batch [1680/2500], Loss: 0.09983090311288834\n",
      "Epoch [1/3], Batch [1681/2500], Loss: 0.025630265474319458\n",
      "Epoch [1/3], Batch [1682/2500], Loss: 0.23039428889751434\n",
      "Epoch [1/3], Batch [1683/2500], Loss: 0.23775802552700043\n",
      "Epoch [1/3], Batch [1684/2500], Loss: 0.6661902070045471\n",
      "Epoch [1/3], Batch [1685/2500], Loss: 0.6097723841667175\n",
      "Epoch [1/3], Batch [1686/2500], Loss: 0.5067682862281799\n",
      "Epoch [1/3], Batch [1687/2500], Loss: 0.22465038299560547\n",
      "Epoch [1/3], Batch [1688/2500], Loss: 0.2639911472797394\n",
      "Epoch [1/3], Batch [1689/2500], Loss: 0.20345468819141388\n",
      "Epoch [1/3], Batch [1690/2500], Loss: 0.29724767804145813\n",
      "Epoch [1/3], Batch [1691/2500], Loss: 0.5216188430786133\n",
      "Epoch [1/3], Batch [1692/2500], Loss: 0.5089643001556396\n",
      "Epoch [1/3], Batch [1693/2500], Loss: 0.24812574684619904\n",
      "Epoch [1/3], Batch [1694/2500], Loss: 0.2197120487689972\n",
      "Epoch [1/3], Batch [1695/2500], Loss: 0.17884868383407593\n",
      "Epoch [1/3], Batch [1696/2500], Loss: 0.3002745807170868\n",
      "Epoch [1/3], Batch [1697/2500], Loss: 0.3843225836753845\n",
      "Epoch [1/3], Batch [1698/2500], Loss: 0.1607843041419983\n",
      "Epoch [1/3], Batch [1699/2500], Loss: 0.11055157333612442\n",
      "Epoch [1/3], Batch [1700/2500], Loss: 0.17247073352336884\n",
      "Epoch [1/3], Batch [1701/2500], Loss: 0.15855185687541962\n",
      "Epoch [1/3], Batch [1702/2500], Loss: 0.18482472002506256\n",
      "Epoch [1/3], Batch [1703/2500], Loss: 0.2360258847475052\n",
      "Epoch [1/3], Batch [1704/2500], Loss: 0.25387752056121826\n",
      "Epoch [1/3], Batch [1705/2500], Loss: 0.5493994355201721\n",
      "Epoch [1/3], Batch [1706/2500], Loss: 0.43309396505355835\n",
      "Epoch [1/3], Batch [1707/2500], Loss: 0.5800556540489197\n",
      "Epoch [1/3], Batch [1708/2500], Loss: 0.14139266312122345\n",
      "Epoch [1/3], Batch [1709/2500], Loss: 0.11363141983747482\n",
      "Epoch [1/3], Batch [1710/2500], Loss: 0.23739799857139587\n",
      "Epoch [1/3], Batch [1711/2500], Loss: 0.2787855863571167\n",
      "Epoch [1/3], Batch [1712/2500], Loss: 0.5549535751342773\n",
      "Epoch [1/3], Batch [1713/2500], Loss: 0.2476038783788681\n",
      "Epoch [1/3], Batch [1714/2500], Loss: 0.6871504783630371\n",
      "Epoch [1/3], Batch [1715/2500], Loss: 0.28999006748199463\n",
      "Epoch [1/3], Batch [1716/2500], Loss: 0.2913777530193329\n",
      "Epoch [1/3], Batch [1717/2500], Loss: 0.11911296099424362\n",
      "Epoch [1/3], Batch [1718/2500], Loss: 0.13182199001312256\n",
      "Epoch [1/3], Batch [1719/2500], Loss: 0.3562111556529999\n",
      "Epoch [1/3], Batch [1720/2500], Loss: 0.2922068238258362\n",
      "Epoch [1/3], Batch [1721/2500], Loss: 0.20182769000530243\n",
      "Epoch [1/3], Batch [1722/2500], Loss: 0.3754471242427826\n",
      "Epoch [1/3], Batch [1723/2500], Loss: 0.26851606369018555\n",
      "Epoch [1/3], Batch [1724/2500], Loss: 0.27139362692832947\n",
      "Epoch [1/3], Batch [1725/2500], Loss: 0.1599508672952652\n",
      "Epoch [1/3], Batch [1726/2500], Loss: 0.16208717226982117\n",
      "Epoch [1/3], Batch [1727/2500], Loss: 0.20996592938899994\n",
      "Epoch [1/3], Batch [1728/2500], Loss: 0.2046138197183609\n",
      "Epoch [1/3], Batch [1729/2500], Loss: 0.400410532951355\n",
      "Epoch [1/3], Batch [1730/2500], Loss: 0.19463741779327393\n",
      "Epoch [1/3], Batch [1731/2500], Loss: 0.12057025730609894\n",
      "Epoch [1/3], Batch [1732/2500], Loss: 0.13118965923786163\n",
      "Epoch [1/3], Batch [1733/2500], Loss: 0.33712130784988403\n",
      "Epoch [1/3], Batch [1734/2500], Loss: 0.19636863470077515\n",
      "Epoch [1/3], Batch [1735/2500], Loss: 0.23899659514427185\n",
      "Epoch [1/3], Batch [1736/2500], Loss: 0.9624103307723999\n",
      "Epoch [1/3], Batch [1737/2500], Loss: 0.28989529609680176\n",
      "Epoch [1/3], Batch [1738/2500], Loss: 0.12297051399946213\n",
      "Epoch [1/3], Batch [1739/2500], Loss: 0.1563132405281067\n",
      "Epoch [1/3], Batch [1740/2500], Loss: 0.12039204686880112\n",
      "Epoch [1/3], Batch [1741/2500], Loss: 0.06253361701965332\n",
      "Epoch [1/3], Batch [1742/2500], Loss: 0.2831602692604065\n",
      "Epoch [1/3], Batch [1743/2500], Loss: 0.45203036069869995\n",
      "Epoch [1/3], Batch [1744/2500], Loss: 0.22071950137615204\n",
      "Epoch [1/3], Batch [1745/2500], Loss: 0.18343651294708252\n",
      "Epoch [1/3], Batch [1746/2500], Loss: 0.18963530659675598\n",
      "Epoch [1/3], Batch [1747/2500], Loss: 0.173833966255188\n",
      "Epoch [1/3], Batch [1748/2500], Loss: 0.171920508146286\n",
      "Epoch [1/3], Batch [1749/2500], Loss: 0.36242708563804626\n",
      "Epoch [1/3], Batch [1750/2500], Loss: 0.313979834318161\n",
      "Epoch [1/3], Batch [1751/2500], Loss: 0.2140672653913498\n",
      "Epoch [1/3], Batch [1752/2500], Loss: 0.08521390706300735\n",
      "Epoch [1/3], Batch [1753/2500], Loss: 0.3517652750015259\n",
      "Epoch [1/3], Batch [1754/2500], Loss: 0.12280590832233429\n",
      "Epoch [1/3], Batch [1755/2500], Loss: 0.08307749778032303\n",
      "Epoch [1/3], Batch [1756/2500], Loss: 0.08764588087797165\n",
      "Epoch [1/3], Batch [1757/2500], Loss: 0.05658353120088577\n",
      "Epoch [1/3], Batch [1758/2500], Loss: 0.3357831537723541\n",
      "Epoch [1/3], Batch [1759/2500], Loss: 0.17300206422805786\n",
      "Epoch [1/3], Batch [1760/2500], Loss: 0.1927550584077835\n",
      "Epoch [1/3], Batch [1761/2500], Loss: 0.38291317224502563\n",
      "Epoch [1/3], Batch [1762/2500], Loss: 0.04458541050553322\n",
      "Epoch [1/3], Batch [1763/2500], Loss: 0.7703371644020081\n",
      "Epoch [1/3], Batch [1764/2500], Loss: 0.4367195963859558\n",
      "Epoch [1/3], Batch [1765/2500], Loss: 0.47245243191719055\n",
      "Epoch [1/3], Batch [1766/2500], Loss: 0.30872392654418945\n",
      "Epoch [1/3], Batch [1767/2500], Loss: 0.46132802963256836\n",
      "Epoch [1/3], Batch [1768/2500], Loss: 0.07106323540210724\n",
      "Epoch [1/3], Batch [1769/2500], Loss: 0.31497299671173096\n",
      "Epoch [1/3], Batch [1770/2500], Loss: 0.16490207612514496\n",
      "Epoch [1/3], Batch [1771/2500], Loss: 0.12906724214553833\n",
      "Epoch [1/3], Batch [1772/2500], Loss: 0.07901172339916229\n",
      "Epoch [1/3], Batch [1773/2500], Loss: 0.06290893256664276\n",
      "Epoch [1/3], Batch [1774/2500], Loss: 0.7508947253227234\n",
      "Epoch [1/3], Batch [1775/2500], Loss: 0.6792476177215576\n",
      "Epoch [1/3], Batch [1776/2500], Loss: 0.0856478214263916\n",
      "Epoch [1/3], Batch [1777/2500], Loss: 0.20887978374958038\n",
      "Epoch [1/3], Batch [1778/2500], Loss: 0.39478808641433716\n",
      "Epoch [1/3], Batch [1779/2500], Loss: 0.24840274453163147\n",
      "Epoch [1/3], Batch [1780/2500], Loss: 0.5257151126861572\n",
      "Epoch [1/3], Batch [1781/2500], Loss: 0.28905633091926575\n",
      "Epoch [1/3], Batch [1782/2500], Loss: 0.3055464029312134\n",
      "Epoch [1/3], Batch [1783/2500], Loss: 0.2768069803714752\n",
      "Epoch [1/3], Batch [1784/2500], Loss: 0.2852444052696228\n",
      "Epoch [1/3], Batch [1785/2500], Loss: 0.14500370621681213\n",
      "Epoch [1/3], Batch [1786/2500], Loss: 0.2966691851615906\n",
      "Epoch [1/3], Batch [1787/2500], Loss: 0.2327672839164734\n",
      "Epoch [1/3], Batch [1788/2500], Loss: 0.34282469749450684\n",
      "Epoch [1/3], Batch [1789/2500], Loss: 0.2917822003364563\n",
      "Epoch [1/3], Batch [1790/2500], Loss: 0.3703659176826477\n",
      "Epoch [1/3], Batch [1791/2500], Loss: 0.2694975435733795\n",
      "Epoch [1/3], Batch [1792/2500], Loss: 0.40279537439346313\n",
      "Epoch [1/3], Batch [1793/2500], Loss: 0.2442074418067932\n",
      "Epoch [1/3], Batch [1794/2500], Loss: 0.3020486533641815\n",
      "Epoch [1/3], Batch [1795/2500], Loss: 0.1443776786327362\n",
      "Epoch [1/3], Batch [1796/2500], Loss: 0.31123438477516174\n",
      "Epoch [1/3], Batch [1797/2500], Loss: 0.23332764208316803\n",
      "Epoch [1/3], Batch [1798/2500], Loss: 0.15880286693572998\n",
      "Epoch [1/3], Batch [1799/2500], Loss: 0.19240733981132507\n",
      "Epoch [1/3], Batch [1800/2500], Loss: 0.3560187518596649\n",
      "Epoch [1/3], Batch [1801/2500], Loss: 0.10944191366434097\n",
      "Epoch [1/3], Batch [1802/2500], Loss: 0.3325430452823639\n",
      "Epoch [1/3], Batch [1803/2500], Loss: 0.46242421865463257\n",
      "Epoch [1/3], Batch [1804/2500], Loss: 0.04571942239999771\n",
      "Epoch [1/3], Batch [1805/2500], Loss: 0.5574684739112854\n",
      "Epoch [1/3], Batch [1806/2500], Loss: 0.037775661796331406\n",
      "Epoch [1/3], Batch [1807/2500], Loss: 0.08174505829811096\n",
      "Epoch [1/3], Batch [1808/2500], Loss: 0.16789408028125763\n",
      "Epoch [1/3], Batch [1809/2500], Loss: 0.1396838277578354\n",
      "Epoch [1/3], Batch [1810/2500], Loss: 0.09562031179666519\n",
      "Epoch [1/3], Batch [1811/2500], Loss: 0.15560869872570038\n",
      "Epoch [1/3], Batch [1812/2500], Loss: 0.44055038690567017\n",
      "Epoch [1/3], Batch [1813/2500], Loss: 0.18913336098194122\n",
      "Epoch [1/3], Batch [1814/2500], Loss: 0.17336705327033997\n",
      "Epoch [1/3], Batch [1815/2500], Loss: 0.22393372654914856\n",
      "Epoch [1/3], Batch [1816/2500], Loss: 0.10693645477294922\n",
      "Epoch [1/3], Batch [1817/2500], Loss: 0.3720073103904724\n",
      "Epoch [1/3], Batch [1818/2500], Loss: 0.16974462568759918\n",
      "Epoch [1/3], Batch [1819/2500], Loss: 0.5290963649749756\n",
      "Epoch [1/3], Batch [1820/2500], Loss: 0.2620623707771301\n",
      "Epoch [1/3], Batch [1821/2500], Loss: 0.5458985567092896\n",
      "Epoch [1/3], Batch [1822/2500], Loss: 0.18336759507656097\n",
      "Epoch [1/3], Batch [1823/2500], Loss: 0.14442189037799835\n",
      "Epoch [1/3], Batch [1824/2500], Loss: 0.40044263005256653\n",
      "Epoch [1/3], Batch [1825/2500], Loss: 0.2736462652683258\n",
      "Epoch [1/3], Batch [1826/2500], Loss: 0.08662524819374084\n",
      "Epoch [1/3], Batch [1827/2500], Loss: 0.3233558237552643\n",
      "Epoch [1/3], Batch [1828/2500], Loss: 0.24793322384357452\n",
      "Epoch [1/3], Batch [1829/2500], Loss: 0.25443169474601746\n",
      "Epoch [1/3], Batch [1830/2500], Loss: 0.46949341893196106\n",
      "Epoch [1/3], Batch [1831/2500], Loss: 0.1418810784816742\n",
      "Epoch [1/3], Batch [1832/2500], Loss: 0.13842782378196716\n",
      "Epoch [1/3], Batch [1833/2500], Loss: 0.749501645565033\n",
      "Epoch [1/3], Batch [1834/2500], Loss: 0.4140722155570984\n",
      "Epoch [1/3], Batch [1835/2500], Loss: 0.24300633370876312\n",
      "Epoch [1/3], Batch [1836/2500], Loss: 0.3236069977283478\n",
      "Epoch [1/3], Batch [1837/2500], Loss: 0.39145639538764954\n",
      "Epoch [1/3], Batch [1838/2500], Loss: 0.296453595161438\n",
      "Epoch [1/3], Batch [1839/2500], Loss: 0.2303260862827301\n",
      "Epoch [1/3], Batch [1840/2500], Loss: 0.19060055911540985\n",
      "Epoch [1/3], Batch [1841/2500], Loss: 0.10912352800369263\n",
      "Epoch [1/3], Batch [1842/2500], Loss: 0.251006543636322\n",
      "Epoch [1/3], Batch [1843/2500], Loss: 0.41125592589378357\n",
      "Epoch [1/3], Batch [1844/2500], Loss: 0.20741486549377441\n",
      "Epoch [1/3], Batch [1845/2500], Loss: 0.24595913290977478\n",
      "Epoch [1/3], Batch [1846/2500], Loss: 0.23183095455169678\n",
      "Epoch [1/3], Batch [1847/2500], Loss: 0.18571224808692932\n",
      "Epoch [1/3], Batch [1848/2500], Loss: 0.23225082457065582\n",
      "Epoch [1/3], Batch [1849/2500], Loss: 0.41194918751716614\n",
      "Epoch [1/3], Batch [1850/2500], Loss: 0.4393972158432007\n",
      "Epoch [1/3], Batch [1851/2500], Loss: 0.14525018632411957\n",
      "Epoch [1/3], Batch [1852/2500], Loss: 0.3872159421443939\n",
      "Epoch [1/3], Batch [1853/2500], Loss: 0.25915902853012085\n",
      "Epoch [1/3], Batch [1854/2500], Loss: 0.1937645822763443\n",
      "Epoch [1/3], Batch [1855/2500], Loss: 0.17593875527381897\n",
      "Epoch [1/3], Batch [1856/2500], Loss: 0.11277365684509277\n",
      "Epoch [1/3], Batch [1857/2500], Loss: 0.43087026476860046\n",
      "Epoch [1/3], Batch [1858/2500], Loss: 0.19592876732349396\n",
      "Epoch [1/3], Batch [1859/2500], Loss: 0.3433881103992462\n",
      "Epoch [1/3], Batch [1860/2500], Loss: 0.14940811693668365\n",
      "Epoch [1/3], Batch [1861/2500], Loss: 0.21586167812347412\n",
      "Epoch [1/3], Batch [1862/2500], Loss: 0.0934160128235817\n",
      "Epoch [1/3], Batch [1863/2500], Loss: 0.4756407141685486\n",
      "Epoch [1/3], Batch [1864/2500], Loss: 0.05441731587052345\n",
      "Epoch [1/3], Batch [1865/2500], Loss: 0.4584478735923767\n",
      "Epoch [1/3], Batch [1866/2500], Loss: 0.2539312243461609\n",
      "Epoch [1/3], Batch [1867/2500], Loss: 0.06146973744034767\n",
      "Epoch [1/3], Batch [1868/2500], Loss: 0.20459720492362976\n",
      "Epoch [1/3], Batch [1869/2500], Loss: 0.5307503938674927\n",
      "Epoch [1/3], Batch [1870/2500], Loss: 0.05319494009017944\n",
      "Epoch [1/3], Batch [1871/2500], Loss: 0.09762775897979736\n",
      "Epoch [1/3], Batch [1872/2500], Loss: 0.1515675038099289\n",
      "Epoch [1/3], Batch [1873/2500], Loss: 0.33986690640449524\n",
      "Epoch [1/3], Batch [1874/2500], Loss: 0.43189537525177\n",
      "Epoch [1/3], Batch [1875/2500], Loss: 0.2804965674877167\n",
      "Epoch [1/3], Batch [1876/2500], Loss: 0.22194041311740875\n",
      "Epoch [1/3], Batch [1877/2500], Loss: 0.051879994571208954\n",
      "Epoch [1/3], Batch [1878/2500], Loss: 0.3071427047252655\n",
      "Epoch [1/3], Batch [1879/2500], Loss: 0.13268649578094482\n",
      "Epoch [1/3], Batch [1880/2500], Loss: 0.18207032978534698\n",
      "Epoch [1/3], Batch [1881/2500], Loss: 0.3170316815376282\n",
      "Epoch [1/3], Batch [1882/2500], Loss: 0.21545976400375366\n",
      "Epoch [1/3], Batch [1883/2500], Loss: 0.16409575939178467\n",
      "Epoch [1/3], Batch [1884/2500], Loss: 0.1746072918176651\n",
      "Epoch [1/3], Batch [1885/2500], Loss: 0.31962335109710693\n",
      "Epoch [1/3], Batch [1886/2500], Loss: 0.1391887664794922\n",
      "Epoch [1/3], Batch [1887/2500], Loss: 0.21375462412834167\n",
      "Epoch [1/3], Batch [1888/2500], Loss: 0.18681032955646515\n",
      "Epoch [1/3], Batch [1889/2500], Loss: 0.10563191771507263\n",
      "Epoch [1/3], Batch [1890/2500], Loss: 0.6863439083099365\n",
      "Epoch [1/3], Batch [1891/2500], Loss: 0.1246635764837265\n",
      "Epoch [1/3], Batch [1892/2500], Loss: 0.16278356313705444\n",
      "Epoch [1/3], Batch [1893/2500], Loss: 0.11558910459280014\n",
      "Epoch [1/3], Batch [1894/2500], Loss: 0.1278434544801712\n",
      "Epoch [1/3], Batch [1895/2500], Loss: 0.17794093489646912\n",
      "Epoch [1/3], Batch [1896/2500], Loss: 0.04161401093006134\n",
      "Epoch [1/3], Batch [1897/2500], Loss: 0.4110705852508545\n",
      "Epoch [1/3], Batch [1898/2500], Loss: 0.3239283859729767\n",
      "Epoch [1/3], Batch [1899/2500], Loss: 0.2855583429336548\n",
      "Epoch [1/3], Batch [1900/2500], Loss: 0.44652867317199707\n",
      "Epoch [1/3], Batch [1901/2500], Loss: 0.20516467094421387\n",
      "Epoch [1/3], Batch [1902/2500], Loss: 0.6788110733032227\n",
      "Epoch [1/3], Batch [1903/2500], Loss: 0.3108038008213043\n",
      "Epoch [1/3], Batch [1904/2500], Loss: 0.10391449928283691\n",
      "Epoch [1/3], Batch [1905/2500], Loss: 0.08631446212530136\n",
      "Epoch [1/3], Batch [1906/2500], Loss: 0.06771831214427948\n",
      "Epoch [1/3], Batch [1907/2500], Loss: 0.16259080171585083\n",
      "Epoch [1/3], Batch [1908/2500], Loss: 0.2896413803100586\n",
      "Epoch [1/3], Batch [1909/2500], Loss: 0.2439504712820053\n",
      "Epoch [1/3], Batch [1910/2500], Loss: 0.1842345893383026\n",
      "Epoch [1/3], Batch [1911/2500], Loss: 0.21111832559108734\n",
      "Epoch [1/3], Batch [1912/2500], Loss: 0.34522393345832825\n",
      "Epoch [1/3], Batch [1913/2500], Loss: 0.4057556092739105\n",
      "Epoch [1/3], Batch [1914/2500], Loss: 0.3198656141757965\n",
      "Epoch [1/3], Batch [1915/2500], Loss: 0.3155593276023865\n",
      "Epoch [1/3], Batch [1916/2500], Loss: 0.09987088292837143\n",
      "Epoch [1/3], Batch [1917/2500], Loss: 0.3136318027973175\n",
      "Epoch [1/3], Batch [1918/2500], Loss: 0.13217540085315704\n",
      "Epoch [1/3], Batch [1919/2500], Loss: 0.2336944043636322\n",
      "Epoch [1/3], Batch [1920/2500], Loss: 0.3368595242500305\n",
      "Epoch [1/3], Batch [1921/2500], Loss: 0.277168869972229\n",
      "Epoch [1/3], Batch [1922/2500], Loss: 0.25587573647499084\n",
      "Epoch [1/3], Batch [1923/2500], Loss: 0.07603373378515244\n",
      "Epoch [1/3], Batch [1924/2500], Loss: 0.07638449966907501\n",
      "Epoch [1/3], Batch [1925/2500], Loss: 0.47372424602508545\n",
      "Epoch [1/3], Batch [1926/2500], Loss: 0.1839337944984436\n",
      "Epoch [1/3], Batch [1927/2500], Loss: 0.13757219910621643\n",
      "Epoch [1/3], Batch [1928/2500], Loss: 0.09268400073051453\n",
      "Epoch [1/3], Batch [1929/2500], Loss: 0.18238961696624756\n",
      "Epoch [1/3], Batch [1930/2500], Loss: 0.1812981814146042\n",
      "Epoch [1/3], Batch [1931/2500], Loss: 0.08487220108509064\n",
      "Epoch [1/3], Batch [1932/2500], Loss: 0.02432895451784134\n",
      "Epoch [1/3], Batch [1933/2500], Loss: 0.1572367250919342\n",
      "Epoch [1/3], Batch [1934/2500], Loss: 0.06866749376058578\n",
      "Epoch [1/3], Batch [1935/2500], Loss: 0.15813428163528442\n",
      "Epoch [1/3], Batch [1936/2500], Loss: 0.19726163148880005\n",
      "Epoch [1/3], Batch [1937/2500], Loss: 0.20964208245277405\n",
      "Epoch [1/3], Batch [1938/2500], Loss: 0.12170645594596863\n",
      "Epoch [1/3], Batch [1939/2500], Loss: 0.15452398359775543\n",
      "Epoch [1/3], Batch [1940/2500], Loss: 1.1736481189727783\n",
      "Epoch [1/3], Batch [1941/2500], Loss: 0.10091940313577652\n",
      "Epoch [1/3], Batch [1942/2500], Loss: 0.5667501091957092\n",
      "Epoch [1/3], Batch [1943/2500], Loss: 0.1797504723072052\n",
      "Epoch [1/3], Batch [1944/2500], Loss: 0.716195821762085\n",
      "Epoch [1/3], Batch [1945/2500], Loss: 0.1750214546918869\n",
      "Epoch [1/3], Batch [1946/2500], Loss: 0.07230541855096817\n",
      "Epoch [1/3], Batch [1947/2500], Loss: 0.18463973701000214\n",
      "Epoch [1/3], Batch [1948/2500], Loss: 0.16010445356369019\n",
      "Epoch [1/3], Batch [1949/2500], Loss: 0.0961245596408844\n",
      "Epoch [1/3], Batch [1950/2500], Loss: 0.15853248536586761\n",
      "Epoch [1/3], Batch [1951/2500], Loss: 0.3982568383216858\n",
      "Epoch [1/3], Batch [1952/2500], Loss: 0.42714181542396545\n",
      "Epoch [1/3], Batch [1953/2500], Loss: 0.15474843978881836\n",
      "Epoch [1/3], Batch [1954/2500], Loss: 0.07967467606067657\n",
      "Epoch [1/3], Batch [1955/2500], Loss: 0.1771567165851593\n",
      "Epoch [1/3], Batch [1956/2500], Loss: 0.24969933927059174\n",
      "Epoch [1/3], Batch [1957/2500], Loss: 0.1389033943414688\n",
      "Epoch [1/3], Batch [1958/2500], Loss: 0.2845451831817627\n",
      "Epoch [1/3], Batch [1959/2500], Loss: 0.284816712141037\n",
      "Epoch [1/3], Batch [1960/2500], Loss: 0.12068737298250198\n",
      "Epoch [1/3], Batch [1961/2500], Loss: 0.5428295731544495\n",
      "Epoch [1/3], Batch [1962/2500], Loss: 0.2615303099155426\n",
      "Epoch [1/3], Batch [1963/2500], Loss: 0.12341256439685822\n",
      "Epoch [1/3], Batch [1964/2500], Loss: 0.09239399433135986\n",
      "Epoch [1/3], Batch [1965/2500], Loss: 0.23584897816181183\n",
      "Epoch [1/3], Batch [1966/2500], Loss: 0.40592068433761597\n",
      "Epoch [1/3], Batch [1967/2500], Loss: 0.38077959418296814\n",
      "Epoch [1/3], Batch [1968/2500], Loss: 0.40121978521347046\n",
      "Epoch [1/3], Batch [1969/2500], Loss: 0.32252198457717896\n",
      "Epoch [1/3], Batch [1970/2500], Loss: 0.28214117884635925\n",
      "Epoch [1/3], Batch [1971/2500], Loss: 0.09796972572803497\n",
      "Epoch [1/3], Batch [1972/2500], Loss: 0.3008723556995392\n",
      "Epoch [1/3], Batch [1973/2500], Loss: 0.09617093205451965\n",
      "Epoch [1/3], Batch [1974/2500], Loss: 0.4048529267311096\n",
      "Epoch [1/3], Batch [1975/2500], Loss: 0.2657008767127991\n",
      "Epoch [1/3], Batch [1976/2500], Loss: 0.0626005008816719\n",
      "Epoch [1/3], Batch [1977/2500], Loss: 0.24368320405483246\n",
      "Epoch [1/3], Batch [1978/2500], Loss: 0.3382570147514343\n",
      "Epoch [1/3], Batch [1979/2500], Loss: 0.04896509274840355\n",
      "Epoch [1/3], Batch [1980/2500], Loss: 0.3818291425704956\n",
      "Epoch [1/3], Batch [1981/2500], Loss: 0.22507059574127197\n",
      "Epoch [1/3], Batch [1982/2500], Loss: 0.4671075642108917\n",
      "Epoch [1/3], Batch [1983/2500], Loss: 0.16981753706932068\n",
      "Epoch [1/3], Batch [1984/2500], Loss: 0.1848713457584381\n",
      "Epoch [1/3], Batch [1985/2500], Loss: 0.18198737502098083\n",
      "Epoch [1/3], Batch [1986/2500], Loss: 0.17572534084320068\n",
      "Epoch [1/3], Batch [1987/2500], Loss: 0.5258501768112183\n",
      "Epoch [1/3], Batch [1988/2500], Loss: 0.18911045789718628\n",
      "Epoch [1/3], Batch [1989/2500], Loss: 0.12299403548240662\n",
      "Epoch [1/3], Batch [1990/2500], Loss: 0.09438483417034149\n",
      "Epoch [1/3], Batch [1991/2500], Loss: 0.2914842963218689\n",
      "Epoch [1/3], Batch [1992/2500], Loss: 0.098233163356781\n",
      "Epoch [1/3], Batch [1993/2500], Loss: 0.24603034555912018\n",
      "Epoch [1/3], Batch [1994/2500], Loss: 0.22291959822177887\n",
      "Epoch [1/3], Batch [1995/2500], Loss: 0.18623584508895874\n",
      "Epoch [1/3], Batch [1996/2500], Loss: 0.3621094226837158\n",
      "Epoch [1/3], Batch [1997/2500], Loss: 0.13359038531780243\n",
      "Epoch [1/3], Batch [1998/2500], Loss: 0.37713423371315\n",
      "Epoch [1/3], Batch [1999/2500], Loss: 0.6428219079971313\n",
      "Epoch [1/3], Batch [2000/2500], Loss: 0.1798447072505951\n",
      "Epoch [1/3], Batch [2001/2500], Loss: 0.6670141816139221\n",
      "Epoch [1/3], Batch [2002/2500], Loss: 0.2554693818092346\n",
      "Epoch [1/3], Batch [2003/2500], Loss: 0.1969224363565445\n",
      "Epoch [1/3], Batch [2004/2500], Loss: 0.0813194215297699\n",
      "Epoch [1/3], Batch [2005/2500], Loss: 0.27493780851364136\n",
      "Epoch [1/3], Batch [2006/2500], Loss: 0.21323071420192719\n",
      "Epoch [1/3], Batch [2007/2500], Loss: 0.23693962395191193\n",
      "Epoch [1/3], Batch [2008/2500], Loss: 0.13684619963169098\n",
      "Epoch [1/3], Batch [2009/2500], Loss: 0.17631351947784424\n",
      "Epoch [1/3], Batch [2010/2500], Loss: 0.48237890005111694\n",
      "Epoch [1/3], Batch [2011/2500], Loss: 0.5667338371276855\n",
      "Epoch [1/3], Batch [2012/2500], Loss: 0.42121949791908264\n",
      "Epoch [1/3], Batch [2013/2500], Loss: 0.10183605551719666\n",
      "Epoch [1/3], Batch [2014/2500], Loss: 0.36816996335983276\n",
      "Epoch [1/3], Batch [2015/2500], Loss: 0.054637376219034195\n",
      "Epoch [1/3], Batch [2016/2500], Loss: 0.21202236413955688\n",
      "Epoch [1/3], Batch [2017/2500], Loss: 0.0644938126206398\n",
      "Epoch [1/3], Batch [2018/2500], Loss: 0.19821864366531372\n",
      "Epoch [1/3], Batch [2019/2500], Loss: 0.20047643780708313\n",
      "Epoch [1/3], Batch [2020/2500], Loss: 0.1175849437713623\n",
      "Epoch [1/3], Batch [2021/2500], Loss: 0.09770331531763077\n",
      "Epoch [1/3], Batch [2022/2500], Loss: 0.10321268439292908\n",
      "Epoch [1/3], Batch [2023/2500], Loss: 0.14129318296909332\n",
      "Epoch [1/3], Batch [2024/2500], Loss: 0.2573104202747345\n",
      "Epoch [1/3], Batch [2025/2500], Loss: 0.21644440293312073\n",
      "Epoch [1/3], Batch [2026/2500], Loss: 0.07555742561817169\n",
      "Epoch [1/3], Batch [2027/2500], Loss: 0.22251901030540466\n",
      "Epoch [1/3], Batch [2028/2500], Loss: 0.19898775219917297\n",
      "Epoch [1/3], Batch [2029/2500], Loss: 0.11637120693922043\n",
      "Epoch [1/3], Batch [2030/2500], Loss: 0.5955408811569214\n",
      "Epoch [1/3], Batch [2031/2500], Loss: 0.19393599033355713\n",
      "Epoch [1/3], Batch [2032/2500], Loss: 0.48327165842056274\n",
      "Epoch [1/3], Batch [2033/2500], Loss: 0.052463360130786896\n",
      "Epoch [1/3], Batch [2034/2500], Loss: 0.3463994264602661\n",
      "Epoch [1/3], Batch [2035/2500], Loss: 0.3314612805843353\n",
      "Epoch [1/3], Batch [2036/2500], Loss: 0.4476855397224426\n",
      "Epoch [1/3], Batch [2037/2500], Loss: 0.4037085175514221\n",
      "Epoch [1/3], Batch [2038/2500], Loss: 0.4477771520614624\n",
      "Epoch [1/3], Batch [2039/2500], Loss: 0.1943548172712326\n",
      "Epoch [1/3], Batch [2040/2500], Loss: 0.22852274775505066\n",
      "Epoch [1/3], Batch [2041/2500], Loss: 0.18120229244232178\n",
      "Epoch [1/3], Batch [2042/2500], Loss: 0.11572754383087158\n",
      "Epoch [1/3], Batch [2043/2500], Loss: 0.17789813876152039\n",
      "Epoch [1/3], Batch [2044/2500], Loss: 0.19426779448986053\n",
      "Epoch [1/3], Batch [2045/2500], Loss: 0.4642794728279114\n",
      "Epoch [1/3], Batch [2046/2500], Loss: 0.39927592873573303\n",
      "Epoch [1/3], Batch [2047/2500], Loss: 0.08857672661542892\n",
      "Epoch [1/3], Batch [2048/2500], Loss: 0.17823636531829834\n",
      "Epoch [1/3], Batch [2049/2500], Loss: 0.12541884183883667\n",
      "Epoch [1/3], Batch [2050/2500], Loss: 0.08945129811763763\n",
      "Epoch [1/3], Batch [2051/2500], Loss: 0.3152927756309509\n",
      "Epoch [1/3], Batch [2052/2500], Loss: 0.36675766110420227\n",
      "Epoch [1/3], Batch [2053/2500], Loss: 0.3647184371948242\n",
      "Epoch [1/3], Batch [2054/2500], Loss: 0.48016810417175293\n",
      "Epoch [1/3], Batch [2055/2500], Loss: 0.10112938284873962\n",
      "Epoch [1/3], Batch [2056/2500], Loss: 0.39155516028404236\n",
      "Epoch [1/3], Batch [2057/2500], Loss: 0.21566972136497498\n",
      "Epoch [1/3], Batch [2058/2500], Loss: 0.1773568093776703\n",
      "Epoch [1/3], Batch [2059/2500], Loss: 0.24175795912742615\n",
      "Epoch [1/3], Batch [2060/2500], Loss: 0.23038145899772644\n",
      "Epoch [1/3], Batch [2061/2500], Loss: 0.16639399528503418\n",
      "Epoch [1/3], Batch [2062/2500], Loss: 0.2538864016532898\n",
      "Epoch [1/3], Batch [2063/2500], Loss: 0.3075038492679596\n",
      "Epoch [1/3], Batch [2064/2500], Loss: 0.09705201536417007\n",
      "Epoch [1/3], Batch [2065/2500], Loss: 0.3288201093673706\n",
      "Epoch [1/3], Batch [2066/2500], Loss: 0.1811976134777069\n",
      "Epoch [1/3], Batch [2067/2500], Loss: 0.05014468729496002\n",
      "Epoch [1/3], Batch [2068/2500], Loss: 0.11667438596487045\n",
      "Epoch [1/3], Batch [2069/2500], Loss: 0.06658605486154556\n",
      "Epoch [1/3], Batch [2070/2500], Loss: 0.3051963448524475\n",
      "Epoch [1/3], Batch [2071/2500], Loss: 0.7091405987739563\n",
      "Epoch [1/3], Batch [2072/2500], Loss: 0.15464195609092712\n",
      "Epoch [1/3], Batch [2073/2500], Loss: 0.692875862121582\n",
      "Epoch [1/3], Batch [2074/2500], Loss: 0.11349274218082428\n",
      "Epoch [1/3], Batch [2075/2500], Loss: 0.08662647008895874\n",
      "Epoch [1/3], Batch [2076/2500], Loss: 0.3732881546020508\n",
      "Epoch [1/3], Batch [2077/2500], Loss: 0.05628371983766556\n",
      "Epoch [1/3], Batch [2078/2500], Loss: 0.20553579926490784\n",
      "Epoch [1/3], Batch [2079/2500], Loss: 0.5880988240242004\n",
      "Epoch [1/3], Batch [2080/2500], Loss: 0.29308441281318665\n",
      "Epoch [1/3], Batch [2081/2500], Loss: 0.06504892557859421\n",
      "Epoch [1/3], Batch [2082/2500], Loss: 0.2371961623430252\n",
      "Epoch [1/3], Batch [2083/2500], Loss: 0.13538408279418945\n",
      "Epoch [1/3], Batch [2084/2500], Loss: 0.06935213506221771\n",
      "Epoch [1/3], Batch [2085/2500], Loss: 0.34421950578689575\n",
      "Epoch [1/3], Batch [2086/2500], Loss: 0.45416656136512756\n",
      "Epoch [1/3], Batch [2087/2500], Loss: 0.3841250240802765\n",
      "Epoch [1/3], Batch [2088/2500], Loss: 0.3870176672935486\n",
      "Epoch [1/3], Batch [2089/2500], Loss: 0.09167283773422241\n",
      "Epoch [1/3], Batch [2090/2500], Loss: 0.12198732793331146\n",
      "Epoch [1/3], Batch [2091/2500], Loss: 0.190769225358963\n",
      "Epoch [1/3], Batch [2092/2500], Loss: 0.5386205911636353\n",
      "Epoch [1/3], Batch [2093/2500], Loss: 0.09340094774961472\n",
      "Epoch [1/3], Batch [2094/2500], Loss: 0.07960014790296555\n",
      "Epoch [1/3], Batch [2095/2500], Loss: 0.3364897072315216\n",
      "Epoch [1/3], Batch [2096/2500], Loss: 0.3949808180332184\n",
      "Epoch [1/3], Batch [2097/2500], Loss: 0.2701793909072876\n",
      "Epoch [1/3], Batch [2098/2500], Loss: 0.2933425009250641\n",
      "Epoch [1/3], Batch [2099/2500], Loss: 0.5805079340934753\n",
      "Epoch [1/3], Batch [2100/2500], Loss: 0.2555869221687317\n",
      "Epoch [1/3], Batch [2101/2500], Loss: 0.1077144518494606\n",
      "Epoch [1/3], Batch [2102/2500], Loss: 0.14513090252876282\n",
      "Epoch [1/3], Batch [2103/2500], Loss: 0.12107113748788834\n",
      "Epoch [1/3], Batch [2104/2500], Loss: 0.33644795417785645\n",
      "Epoch [1/3], Batch [2105/2500], Loss: 0.6311876773834229\n",
      "Epoch [1/3], Batch [2106/2500], Loss: 0.277850866317749\n",
      "Epoch [1/3], Batch [2107/2500], Loss: 0.18489523231983185\n",
      "Epoch [1/3], Batch [2108/2500], Loss: 0.09217965602874756\n",
      "Epoch [1/3], Batch [2109/2500], Loss: 0.1521913707256317\n",
      "Epoch [1/3], Batch [2110/2500], Loss: 0.12266413867473602\n",
      "Epoch [1/3], Batch [2111/2500], Loss: 0.37628787755966187\n",
      "Epoch [1/3], Batch [2112/2500], Loss: 0.11413205415010452\n",
      "Epoch [1/3], Batch [2113/2500], Loss: 0.13932985067367554\n",
      "Epoch [1/3], Batch [2114/2500], Loss: 0.3858039677143097\n",
      "Epoch [1/3], Batch [2115/2500], Loss: 0.19829559326171875\n",
      "Epoch [1/3], Batch [2116/2500], Loss: 0.23159277439117432\n",
      "Epoch [1/3], Batch [2117/2500], Loss: 0.4060513377189636\n",
      "Epoch [1/3], Batch [2118/2500], Loss: 0.14930154383182526\n",
      "Epoch [1/3], Batch [2119/2500], Loss: 0.1601995974779129\n",
      "Epoch [1/3], Batch [2120/2500], Loss: 0.3111840784549713\n",
      "Epoch [1/3], Batch [2121/2500], Loss: 0.1261555403470993\n",
      "Epoch [1/3], Batch [2122/2500], Loss: 0.2205134928226471\n",
      "Epoch [1/3], Batch [2123/2500], Loss: 0.1598433554172516\n",
      "Epoch [1/3], Batch [2124/2500], Loss: 0.6624154448509216\n",
      "Epoch [1/3], Batch [2125/2500], Loss: 0.1510479599237442\n",
      "Epoch [1/3], Batch [2126/2500], Loss: 0.12201827764511108\n",
      "Epoch [1/3], Batch [2127/2500], Loss: 0.1863299459218979\n",
      "Epoch [1/3], Batch [2128/2500], Loss: 0.10951333492994308\n",
      "Epoch [1/3], Batch [2129/2500], Loss: 0.5267864465713501\n",
      "Epoch [1/3], Batch [2130/2500], Loss: 0.29871681332588196\n",
      "Epoch [1/3], Batch [2131/2500], Loss: 0.331796258687973\n",
      "Epoch [1/3], Batch [2132/2500], Loss: 0.17808832228183746\n",
      "Epoch [1/3], Batch [2133/2500], Loss: 0.28902485966682434\n",
      "Epoch [1/3], Batch [2134/2500], Loss: 0.09867370873689651\n",
      "Epoch [1/3], Batch [2135/2500], Loss: 0.0755382776260376\n",
      "Epoch [1/3], Batch [2136/2500], Loss: 0.16892869770526886\n",
      "Epoch [1/3], Batch [2137/2500], Loss: 0.2405489981174469\n",
      "Epoch [1/3], Batch [2138/2500], Loss: 0.18629097938537598\n",
      "Epoch [1/3], Batch [2139/2500], Loss: 0.5164623260498047\n",
      "Epoch [1/3], Batch [2140/2500], Loss: 0.08052527159452438\n",
      "Epoch [1/3], Batch [2141/2500], Loss: 0.044392578303813934\n",
      "Epoch [1/3], Batch [2142/2500], Loss: 0.03667902946472168\n",
      "Epoch [1/3], Batch [2143/2500], Loss: 0.2169215977191925\n",
      "Epoch [1/3], Batch [2144/2500], Loss: 0.3501923382282257\n",
      "Epoch [1/3], Batch [2145/2500], Loss: 0.7016383409500122\n",
      "Epoch [1/3], Batch [2146/2500], Loss: 0.043868403881788254\n",
      "Epoch [1/3], Batch [2147/2500], Loss: 0.13463705778121948\n",
      "Epoch [1/3], Batch [2148/2500], Loss: 0.433640718460083\n",
      "Epoch [1/3], Batch [2149/2500], Loss: 0.16034512221813202\n",
      "Epoch [1/3], Batch [2150/2500], Loss: 0.22532419860363007\n",
      "Epoch [1/3], Batch [2151/2500], Loss: 0.22732889652252197\n",
      "Epoch [1/3], Batch [2152/2500], Loss: 0.0891384482383728\n",
      "Epoch [1/3], Batch [2153/2500], Loss: 0.23892197012901306\n",
      "Epoch [1/3], Batch [2154/2500], Loss: 0.33487337827682495\n",
      "Epoch [1/3], Batch [2155/2500], Loss: 0.2234925478696823\n",
      "Epoch [1/3], Batch [2156/2500], Loss: 0.24849410355091095\n",
      "Epoch [1/3], Batch [2157/2500], Loss: 0.2110781967639923\n",
      "Epoch [1/3], Batch [2158/2500], Loss: 0.25142112374305725\n",
      "Epoch [1/3], Batch [2159/2500], Loss: 0.4457263946533203\n",
      "Epoch [1/3], Batch [2160/2500], Loss: 0.2731326222419739\n",
      "Epoch [1/3], Batch [2161/2500], Loss: 0.09194056689739227\n",
      "Epoch [1/3], Batch [2162/2500], Loss: 0.30498915910720825\n",
      "Epoch [1/3], Batch [2163/2500], Loss: 0.25381866097450256\n",
      "Epoch [1/3], Batch [2164/2500], Loss: 0.08640863001346588\n",
      "Epoch [1/3], Batch [2165/2500], Loss: 0.09964438527822495\n",
      "Epoch [1/3], Batch [2166/2500], Loss: 0.18520519137382507\n",
      "Epoch [1/3], Batch [2167/2500], Loss: 0.11759217083454132\n",
      "Epoch [1/3], Batch [2168/2500], Loss: 0.11359840631484985\n",
      "Epoch [1/3], Batch [2169/2500], Loss: 0.27887552976608276\n",
      "Epoch [1/3], Batch [2170/2500], Loss: 0.44668903946876526\n",
      "Epoch [1/3], Batch [2171/2500], Loss: 0.09044834971427917\n",
      "Epoch [1/3], Batch [2172/2500], Loss: 0.10700640082359314\n",
      "Epoch [1/3], Batch [2173/2500], Loss: 0.2326342910528183\n",
      "Epoch [1/3], Batch [2174/2500], Loss: 0.12240790575742722\n",
      "Epoch [1/3], Batch [2175/2500], Loss: 0.5040911436080933\n",
      "Epoch [1/3], Batch [2176/2500], Loss: 0.138935849070549\n",
      "Epoch [1/3], Batch [2177/2500], Loss: 0.1403225064277649\n",
      "Epoch [1/3], Batch [2178/2500], Loss: 0.04272821545600891\n",
      "Epoch [1/3], Batch [2179/2500], Loss: 0.2840462923049927\n",
      "Epoch [1/3], Batch [2180/2500], Loss: 0.20174817740917206\n",
      "Epoch [1/3], Batch [2181/2500], Loss: 0.17514199018478394\n",
      "Epoch [1/3], Batch [2182/2500], Loss: 0.13877902925014496\n",
      "Epoch [1/3], Batch [2183/2500], Loss: 0.17891161143779755\n",
      "Epoch [1/3], Batch [2184/2500], Loss: 0.07247485220432281\n",
      "Epoch [1/3], Batch [2185/2500], Loss: 0.3706798553466797\n",
      "Epoch [1/3], Batch [2186/2500], Loss: 0.3240398168563843\n",
      "Epoch [1/3], Batch [2187/2500], Loss: 0.240122988820076\n",
      "Epoch [1/3], Batch [2188/2500], Loss: 0.07446711510419846\n",
      "Epoch [1/3], Batch [2189/2500], Loss: 0.06385845690965652\n",
      "Epoch [1/3], Batch [2190/2500], Loss: 0.3518545627593994\n",
      "Epoch [1/3], Batch [2191/2500], Loss: 0.3286897838115692\n",
      "Epoch [1/3], Batch [2192/2500], Loss: 0.32834190130233765\n",
      "Epoch [1/3], Batch [2193/2500], Loss: 0.12711288034915924\n",
      "Epoch [1/3], Batch [2194/2500], Loss: 0.15463389456272125\n",
      "Epoch [1/3], Batch [2195/2500], Loss: 0.20636238157749176\n",
      "Epoch [1/3], Batch [2196/2500], Loss: 0.3048071265220642\n",
      "Epoch [1/3], Batch [2197/2500], Loss: 0.3997121751308441\n",
      "Epoch [1/3], Batch [2198/2500], Loss: 0.2358154058456421\n",
      "Epoch [1/3], Batch [2199/2500], Loss: 0.11305602639913559\n",
      "Epoch [1/3], Batch [2200/2500], Loss: 0.07441188395023346\n",
      "Epoch [1/3], Batch [2201/2500], Loss: 0.16540168225765228\n",
      "Epoch [1/3], Batch [2202/2500], Loss: 0.49050432443618774\n",
      "Epoch [1/3], Batch [2203/2500], Loss: 0.08621925115585327\n",
      "Epoch [1/3], Batch [2204/2500], Loss: 0.08045946806669235\n",
      "Epoch [1/3], Batch [2205/2500], Loss: 0.26457810401916504\n",
      "Epoch [1/3], Batch [2206/2500], Loss: 0.30575448274612427\n",
      "Epoch [1/3], Batch [2207/2500], Loss: 0.0888276994228363\n",
      "Epoch [1/3], Batch [2208/2500], Loss: 0.07784697413444519\n",
      "Epoch [1/3], Batch [2209/2500], Loss: 0.2966405153274536\n",
      "Epoch [1/3], Batch [2210/2500], Loss: 0.07908676564693451\n",
      "Epoch [1/3], Batch [2211/2500], Loss: 0.2973126471042633\n",
      "Epoch [1/3], Batch [2212/2500], Loss: 0.11000306904315948\n",
      "Epoch [1/3], Batch [2213/2500], Loss: 0.10627444088459015\n",
      "Epoch [1/3], Batch [2214/2500], Loss: 0.08992695808410645\n",
      "Epoch [1/3], Batch [2215/2500], Loss: 0.19217108190059662\n",
      "Epoch [1/3], Batch [2216/2500], Loss: 0.16959595680236816\n",
      "Epoch [1/3], Batch [2217/2500], Loss: 0.13838984072208405\n",
      "Epoch [1/3], Batch [2218/2500], Loss: 0.05229989439249039\n",
      "Epoch [1/3], Batch [2219/2500], Loss: 0.23981142044067383\n",
      "Epoch [1/3], Batch [2220/2500], Loss: 0.6251844763755798\n",
      "Epoch [1/3], Batch [2221/2500], Loss: 0.03992108255624771\n",
      "Epoch [1/3], Batch [2222/2500], Loss: 0.4522639214992523\n",
      "Epoch [1/3], Batch [2223/2500], Loss: 0.3197002708911896\n",
      "Epoch [1/3], Batch [2224/2500], Loss: 0.034537479281425476\n",
      "Epoch [1/3], Batch [2225/2500], Loss: 0.05413835123181343\n",
      "Epoch [1/3], Batch [2226/2500], Loss: 0.22425110638141632\n",
      "Epoch [1/3], Batch [2227/2500], Loss: 0.03633899986743927\n",
      "Epoch [1/3], Batch [2228/2500], Loss: 0.4899139404296875\n",
      "Epoch [1/3], Batch [2229/2500], Loss: 0.39306896924972534\n",
      "Epoch [1/3], Batch [2230/2500], Loss: 0.15215395390987396\n",
      "Epoch [1/3], Batch [2231/2500], Loss: 0.10298115760087967\n",
      "Epoch [1/3], Batch [2232/2500], Loss: 0.35355308651924133\n",
      "Epoch [1/3], Batch [2233/2500], Loss: 0.2654194235801697\n",
      "Epoch [1/3], Batch [2234/2500], Loss: 0.5177096724510193\n",
      "Epoch [1/3], Batch [2235/2500], Loss: 0.19778186082839966\n",
      "Epoch [1/3], Batch [2236/2500], Loss: 0.2062356173992157\n",
      "Epoch [1/3], Batch [2237/2500], Loss: 0.4222368896007538\n",
      "Epoch [1/3], Batch [2238/2500], Loss: 0.14409999549388885\n",
      "Epoch [1/3], Batch [2239/2500], Loss: 0.314730167388916\n",
      "Epoch [1/3], Batch [2240/2500], Loss: 0.10289137065410614\n",
      "Epoch [1/3], Batch [2241/2500], Loss: 0.20085977017879486\n",
      "Epoch [1/3], Batch [2242/2500], Loss: 0.172666534781456\n",
      "Epoch [1/3], Batch [2243/2500], Loss: 0.31715577840805054\n",
      "Epoch [1/3], Batch [2244/2500], Loss: 0.36435896158218384\n",
      "Epoch [1/3], Batch [2245/2500], Loss: 0.06824690848588943\n",
      "Epoch [1/3], Batch [2246/2500], Loss: 0.24053682386875153\n",
      "Epoch [1/3], Batch [2247/2500], Loss: 0.3387164771556854\n",
      "Epoch [1/3], Batch [2248/2500], Loss: 0.11692467331886292\n",
      "Epoch [1/3], Batch [2249/2500], Loss: 0.36101096868515015\n",
      "Epoch [1/3], Batch [2250/2500], Loss: 0.3908860683441162\n",
      "Epoch [1/3], Batch [2251/2500], Loss: 0.34938645362854004\n",
      "Epoch [1/3], Batch [2252/2500], Loss: 0.24202710390090942\n",
      "Epoch [1/3], Batch [2253/2500], Loss: 0.13405218720436096\n",
      "Epoch [1/3], Batch [2254/2500], Loss: 0.4091866910457611\n",
      "Epoch [1/3], Batch [2255/2500], Loss: 0.17052602767944336\n",
      "Epoch [1/3], Batch [2256/2500], Loss: 0.031124811619520187\n",
      "Epoch [1/3], Batch [2257/2500], Loss: 0.06393270194530487\n",
      "Epoch [1/3], Batch [2258/2500], Loss: 0.4750315546989441\n",
      "Epoch [1/3], Batch [2259/2500], Loss: 0.17106854915618896\n",
      "Epoch [1/3], Batch [2260/2500], Loss: 0.360127717256546\n",
      "Epoch [1/3], Batch [2261/2500], Loss: 0.3058079183101654\n",
      "Epoch [1/3], Batch [2262/2500], Loss: 0.1251824051141739\n",
      "Epoch [1/3], Batch [2263/2500], Loss: 0.3944973349571228\n",
      "Epoch [1/3], Batch [2264/2500], Loss: 0.27291321754455566\n",
      "Epoch [1/3], Batch [2265/2500], Loss: 0.1252414435148239\n",
      "Epoch [1/3], Batch [2266/2500], Loss: 0.18690921366214752\n",
      "Epoch [1/3], Batch [2267/2500], Loss: 0.1022549420595169\n",
      "Epoch [1/3], Batch [2268/2500], Loss: 0.3317309617996216\n",
      "Epoch [1/3], Batch [2269/2500], Loss: 0.22964319586753845\n",
      "Epoch [1/3], Batch [2270/2500], Loss: 0.3570638597011566\n",
      "Epoch [1/3], Batch [2271/2500], Loss: 0.8863659501075745\n",
      "Epoch [1/3], Batch [2272/2500], Loss: 0.10213364660739899\n",
      "Epoch [1/3], Batch [2273/2500], Loss: 0.17823363840579987\n",
      "Epoch [1/3], Batch [2274/2500], Loss: 0.39716798067092896\n",
      "Epoch [1/3], Batch [2275/2500], Loss: 0.1231812909245491\n",
      "Epoch [1/3], Batch [2276/2500], Loss: 0.31928080320358276\n",
      "Epoch [1/3], Batch [2277/2500], Loss: 0.3640553057193756\n",
      "Epoch [1/3], Batch [2278/2500], Loss: 0.39473968744277954\n",
      "Epoch [1/3], Batch [2279/2500], Loss: 0.35826197266578674\n",
      "Epoch [1/3], Batch [2280/2500], Loss: 0.25411179661750793\n",
      "Epoch [1/3], Batch [2281/2500], Loss: 0.3297801911830902\n",
      "Epoch [1/3], Batch [2282/2500], Loss: 0.18229712545871735\n",
      "Epoch [1/3], Batch [2283/2500], Loss: 0.3068220317363739\n",
      "Epoch [1/3], Batch [2284/2500], Loss: 0.22151988744735718\n",
      "Epoch [1/3], Batch [2285/2500], Loss: 0.3174459636211395\n",
      "Epoch [1/3], Batch [2286/2500], Loss: 0.16691379249095917\n",
      "Epoch [1/3], Batch [2287/2500], Loss: 0.26583248376846313\n",
      "Epoch [1/3], Batch [2288/2500], Loss: 0.4596173167228699\n",
      "Epoch [1/3], Batch [2289/2500], Loss: 0.23371440172195435\n",
      "Epoch [1/3], Batch [2290/2500], Loss: 0.26107165217399597\n",
      "Epoch [1/3], Batch [2291/2500], Loss: 0.2530187964439392\n",
      "Epoch [1/3], Batch [2292/2500], Loss: 0.07599076628684998\n",
      "Epoch [1/3], Batch [2293/2500], Loss: 0.1670740246772766\n",
      "Epoch [1/3], Batch [2294/2500], Loss: 0.19935190677642822\n",
      "Epoch [1/3], Batch [2295/2500], Loss: 0.35927462577819824\n",
      "Epoch [1/3], Batch [2296/2500], Loss: 0.2553558349609375\n",
      "Epoch [1/3], Batch [2297/2500], Loss: 0.33758747577667236\n",
      "Epoch [1/3], Batch [2298/2500], Loss: 0.12839657068252563\n",
      "Epoch [1/3], Batch [2299/2500], Loss: 0.29868343472480774\n",
      "Epoch [1/3], Batch [2300/2500], Loss: 0.2195519059896469\n",
      "Epoch [1/3], Batch [2301/2500], Loss: 0.1526142656803131\n",
      "Epoch [1/3], Batch [2302/2500], Loss: 0.18194083869457245\n",
      "Epoch [1/3], Batch [2303/2500], Loss: 0.051780346781015396\n",
      "Epoch [1/3], Batch [2304/2500], Loss: 0.04962978884577751\n",
      "Epoch [1/3], Batch [2305/2500], Loss: 0.2536330223083496\n",
      "Epoch [1/3], Batch [2306/2500], Loss: 0.22166454792022705\n",
      "Epoch [1/3], Batch [2307/2500], Loss: 0.05554156005382538\n",
      "Epoch [1/3], Batch [2308/2500], Loss: 0.1724059283733368\n",
      "Epoch [1/3], Batch [2309/2500], Loss: 0.18885907530784607\n",
      "Epoch [1/3], Batch [2310/2500], Loss: 0.15129226446151733\n",
      "Epoch [1/3], Batch [2311/2500], Loss: 0.08505377918481827\n",
      "Epoch [1/3], Batch [2312/2500], Loss: 0.17177073657512665\n",
      "Epoch [1/3], Batch [2313/2500], Loss: 0.40809693932533264\n",
      "Epoch [1/3], Batch [2314/2500], Loss: 0.1565677672624588\n",
      "Epoch [1/3], Batch [2315/2500], Loss: 0.042605072259902954\n",
      "Epoch [1/3], Batch [2316/2500], Loss: 0.4196184575557709\n",
      "Epoch [1/3], Batch [2317/2500], Loss: 0.10608368366956711\n",
      "Epoch [1/3], Batch [2318/2500], Loss: 0.5289483666419983\n",
      "Epoch [1/3], Batch [2319/2500], Loss: 0.03952838107943535\n",
      "Epoch [1/3], Batch [2320/2500], Loss: 0.10327360779047012\n",
      "Epoch [1/3], Batch [2321/2500], Loss: 0.11046361178159714\n",
      "Epoch [1/3], Batch [2322/2500], Loss: 0.3223209083080292\n",
      "Epoch [1/3], Batch [2323/2500], Loss: 0.13360869884490967\n",
      "Epoch [1/3], Batch [2324/2500], Loss: 0.23072506487369537\n",
      "Epoch [1/3], Batch [2325/2500], Loss: 0.4798416495323181\n",
      "Epoch [1/3], Batch [2326/2500], Loss: 0.22085535526275635\n",
      "Epoch [1/3], Batch [2327/2500], Loss: 0.19249635934829712\n",
      "Epoch [1/3], Batch [2328/2500], Loss: 0.0581090934574604\n",
      "Epoch [1/3], Batch [2329/2500], Loss: 0.16306190192699432\n",
      "Epoch [1/3], Batch [2330/2500], Loss: 0.450084388256073\n",
      "Epoch [1/3], Batch [2331/2500], Loss: 0.06411422789096832\n",
      "Epoch [1/3], Batch [2332/2500], Loss: 0.3515550494194031\n",
      "Epoch [1/3], Batch [2333/2500], Loss: 0.20898938179016113\n",
      "Epoch [1/3], Batch [2334/2500], Loss: 0.414602130651474\n",
      "Epoch [1/3], Batch [2335/2500], Loss: 0.20297370851039886\n",
      "Epoch [1/3], Batch [2336/2500], Loss: 0.2254706472158432\n",
      "Epoch [1/3], Batch [2337/2500], Loss: 0.22547702491283417\n",
      "Epoch [1/3], Batch [2338/2500], Loss: 0.3129771649837494\n",
      "Epoch [1/3], Batch [2339/2500], Loss: 0.27959054708480835\n",
      "Epoch [1/3], Batch [2340/2500], Loss: 0.2492494434118271\n",
      "Epoch [1/3], Batch [2341/2500], Loss: 0.12101691216230392\n",
      "Epoch [1/3], Batch [2342/2500], Loss: 0.22388647496700287\n",
      "Epoch [1/3], Batch [2343/2500], Loss: 0.19255231320858002\n",
      "Epoch [1/3], Batch [2344/2500], Loss: 0.16076616942882538\n",
      "Epoch [1/3], Batch [2345/2500], Loss: 0.1291828602552414\n",
      "Epoch [1/3], Batch [2346/2500], Loss: 0.3379611372947693\n",
      "Epoch [1/3], Batch [2347/2500], Loss: 0.2231811136007309\n",
      "Epoch [1/3], Batch [2348/2500], Loss: 0.25564777851104736\n",
      "Epoch [1/3], Batch [2349/2500], Loss: 0.18975088000297546\n",
      "Epoch [1/3], Batch [2350/2500], Loss: 0.14102493226528168\n",
      "Epoch [1/3], Batch [2351/2500], Loss: 0.4324271082878113\n",
      "Epoch [1/3], Batch [2352/2500], Loss: 0.21517066657543182\n",
      "Epoch [1/3], Batch [2353/2500], Loss: 0.1536531150341034\n",
      "Epoch [1/3], Batch [2354/2500], Loss: 0.058307114988565445\n",
      "Epoch [1/3], Batch [2355/2500], Loss: 0.6706881523132324\n",
      "Epoch [1/3], Batch [2356/2500], Loss: 0.2839259207248688\n",
      "Epoch [1/3], Batch [2357/2500], Loss: 0.3353085219860077\n",
      "Epoch [1/3], Batch [2358/2500], Loss: 1.010419249534607\n",
      "Epoch [1/3], Batch [2359/2500], Loss: 0.4606984257698059\n",
      "Epoch [1/3], Batch [2360/2500], Loss: 0.1387583464384079\n",
      "Epoch [1/3], Batch [2361/2500], Loss: 0.27482205629348755\n",
      "Epoch [1/3], Batch [2362/2500], Loss: 0.14757037162780762\n",
      "Epoch [1/3], Batch [2363/2500], Loss: 0.11270847171545029\n",
      "Epoch [1/3], Batch [2364/2500], Loss: 0.105156809091568\n",
      "Epoch [1/3], Batch [2365/2500], Loss: 0.0931577980518341\n",
      "Epoch [1/3], Batch [2366/2500], Loss: 0.16291210055351257\n",
      "Epoch [1/3], Batch [2367/2500], Loss: 0.4715254008769989\n",
      "Epoch [1/3], Batch [2368/2500], Loss: 0.18417766690254211\n",
      "Epoch [1/3], Batch [2369/2500], Loss: 0.5477246642112732\n",
      "Epoch [1/3], Batch [2370/2500], Loss: 0.19437983632087708\n",
      "Epoch [1/3], Batch [2371/2500], Loss: 0.2867790758609772\n",
      "Epoch [1/3], Batch [2372/2500], Loss: 0.14034324884414673\n",
      "Epoch [1/3], Batch [2373/2500], Loss: 0.08512090146541595\n",
      "Epoch [1/3], Batch [2374/2500], Loss: 0.07229091227054596\n",
      "Epoch [1/3], Batch [2375/2500], Loss: 0.4507594406604767\n",
      "Epoch [1/3], Batch [2376/2500], Loss: 0.03691103309392929\n",
      "Epoch [1/3], Batch [2377/2500], Loss: 0.12004722654819489\n",
      "Epoch [1/3], Batch [2378/2500], Loss: 0.06955759972333908\n",
      "Epoch [1/3], Batch [2379/2500], Loss: 0.08697384595870972\n",
      "Epoch [1/3], Batch [2380/2500], Loss: 0.09746234863996506\n",
      "Epoch [1/3], Batch [2381/2500], Loss: 0.7704463005065918\n",
      "Epoch [1/3], Batch [2382/2500], Loss: 0.08302750438451767\n",
      "Epoch [1/3], Batch [2383/2500], Loss: 0.08815476298332214\n",
      "Epoch [1/3], Batch [2384/2500], Loss: 0.14408887922763824\n",
      "Epoch [1/3], Batch [2385/2500], Loss: 0.13338050246238708\n",
      "Epoch [1/3], Batch [2386/2500], Loss: 0.3895229697227478\n",
      "Epoch [1/3], Batch [2387/2500], Loss: 0.12084627151489258\n",
      "Epoch [1/3], Batch [2388/2500], Loss: 0.10785544663667679\n",
      "Epoch [1/3], Batch [2389/2500], Loss: 0.4153846204280853\n",
      "Epoch [1/3], Batch [2390/2500], Loss: 0.5037118196487427\n",
      "Epoch [1/3], Batch [2391/2500], Loss: 0.14246757328510284\n",
      "Epoch [1/3], Batch [2392/2500], Loss: 0.12464041262865067\n",
      "Epoch [1/3], Batch [2393/2500], Loss: 0.7513415813446045\n",
      "Epoch [1/3], Batch [2394/2500], Loss: 0.023065228015184402\n",
      "Epoch [1/3], Batch [2395/2500], Loss: 0.06317859888076782\n",
      "Epoch [1/3], Batch [2396/2500], Loss: 0.28686270117759705\n",
      "Epoch [1/3], Batch [2397/2500], Loss: 0.3660517632961273\n",
      "Epoch [1/3], Batch [2398/2500], Loss: 0.0935213640332222\n",
      "Epoch [1/3], Batch [2399/2500], Loss: 0.25454315543174744\n",
      "Epoch [1/3], Batch [2400/2500], Loss: 0.16252903640270233\n",
      "Epoch [1/3], Batch [2401/2500], Loss: 0.08873039484024048\n",
      "Epoch [1/3], Batch [2402/2500], Loss: 0.027445362880825996\n",
      "Epoch [1/3], Batch [2403/2500], Loss: 0.2249891459941864\n",
      "Epoch [1/3], Batch [2404/2500], Loss: 0.2336774617433548\n",
      "Epoch [1/3], Batch [2405/2500], Loss: 0.24909478425979614\n",
      "Epoch [1/3], Batch [2406/2500], Loss: 0.20086351037025452\n",
      "Epoch [1/3], Batch [2407/2500], Loss: 0.24406644701957703\n",
      "Epoch [1/3], Batch [2408/2500], Loss: 0.12635059654712677\n",
      "Epoch [1/3], Batch [2409/2500], Loss: 0.1268789917230606\n",
      "Epoch [1/3], Batch [2410/2500], Loss: 0.1956859678030014\n",
      "Epoch [1/3], Batch [2411/2500], Loss: 0.1614011973142624\n",
      "Epoch [1/3], Batch [2412/2500], Loss: 0.2654571235179901\n",
      "Epoch [1/3], Batch [2413/2500], Loss: 0.12892450392246246\n",
      "Epoch [1/3], Batch [2414/2500], Loss: 0.4801095128059387\n",
      "Epoch [1/3], Batch [2415/2500], Loss: 0.2109653502702713\n",
      "Epoch [1/3], Batch [2416/2500], Loss: 0.24843548238277435\n",
      "Epoch [1/3], Batch [2417/2500], Loss: 0.10246378183364868\n",
      "Epoch [1/3], Batch [2418/2500], Loss: 0.07971587032079697\n",
      "Epoch [1/3], Batch [2419/2500], Loss: 0.43233972787857056\n",
      "Epoch [1/3], Batch [2420/2500], Loss: 0.30698710680007935\n",
      "Epoch [1/3], Batch [2421/2500], Loss: 0.3016453981399536\n",
      "Epoch [1/3], Batch [2422/2500], Loss: 0.4795684516429901\n",
      "Epoch [1/3], Batch [2423/2500], Loss: 0.4443742632865906\n",
      "Epoch [1/3], Batch [2424/2500], Loss: 0.23338057100772858\n",
      "Epoch [1/3], Batch [2425/2500], Loss: 0.4407886564731598\n",
      "Epoch [1/3], Batch [2426/2500], Loss: 0.1922411471605301\n",
      "Epoch [1/3], Batch [2427/2500], Loss: 0.26096609234809875\n",
      "Epoch [1/3], Batch [2428/2500], Loss: 0.12209849059581757\n",
      "Epoch [1/3], Batch [2429/2500], Loss: 0.13721778988838196\n",
      "Epoch [1/3], Batch [2430/2500], Loss: 0.3073011338710785\n",
      "Epoch [1/3], Batch [2431/2500], Loss: 0.026825914159417152\n",
      "Epoch [1/3], Batch [2432/2500], Loss: 0.09067654609680176\n",
      "Epoch [1/3], Batch [2433/2500], Loss: 0.17372733354568481\n",
      "Epoch [1/3], Batch [2434/2500], Loss: 0.25613337755203247\n",
      "Epoch [1/3], Batch [2435/2500], Loss: 0.5350469350814819\n",
      "Epoch [1/3], Batch [2436/2500], Loss: 0.110623799264431\n",
      "Epoch [1/3], Batch [2437/2500], Loss: 0.5002295970916748\n",
      "Epoch [1/3], Batch [2438/2500], Loss: 0.1794223040342331\n",
      "Epoch [1/3], Batch [2439/2500], Loss: 0.3789327144622803\n",
      "Epoch [1/3], Batch [2440/2500], Loss: 0.602169930934906\n",
      "Epoch [1/3], Batch [2441/2500], Loss: 0.050352778285741806\n",
      "Epoch [1/3], Batch [2442/2500], Loss: 0.5139288902282715\n",
      "Epoch [1/3], Batch [2443/2500], Loss: 0.3341517150402069\n",
      "Epoch [1/3], Batch [2444/2500], Loss: 0.12341029196977615\n",
      "Epoch [1/3], Batch [2445/2500], Loss: 0.03680024668574333\n",
      "Epoch [1/3], Batch [2446/2500], Loss: 0.34890615940093994\n",
      "Epoch [1/3], Batch [2447/2500], Loss: 0.43334469199180603\n",
      "Epoch [1/3], Batch [2448/2500], Loss: 0.155264213681221\n",
      "Epoch [1/3], Batch [2449/2500], Loss: 0.08755519241094589\n",
      "Epoch [1/3], Batch [2450/2500], Loss: 0.3999670743942261\n",
      "Epoch [1/3], Batch [2451/2500], Loss: 0.12262807786464691\n",
      "Epoch [1/3], Batch [2452/2500], Loss: 0.23340198397636414\n",
      "Epoch [1/3], Batch [2453/2500], Loss: 0.32334277033805847\n",
      "Epoch [1/3], Batch [2454/2500], Loss: 0.3866084814071655\n",
      "Epoch [1/3], Batch [2455/2500], Loss: 0.3626355528831482\n",
      "Epoch [1/3], Batch [2456/2500], Loss: 0.24992728233337402\n",
      "Epoch [1/3], Batch [2457/2500], Loss: 0.14724482595920563\n",
      "Epoch [1/3], Batch [2458/2500], Loss: 0.3136468529701233\n",
      "Epoch [1/3], Batch [2459/2500], Loss: 0.21297790110111237\n",
      "Epoch [1/3], Batch [2460/2500], Loss: 0.3974243402481079\n",
      "Epoch [1/3], Batch [2461/2500], Loss: 0.1506507843732834\n",
      "Epoch [1/3], Batch [2462/2500], Loss: 0.21776124835014343\n",
      "Epoch [1/3], Batch [2463/2500], Loss: 0.2919841706752777\n",
      "Epoch [1/3], Batch [2464/2500], Loss: 0.1639522910118103\n",
      "Epoch [1/3], Batch [2465/2500], Loss: 0.25937631726264954\n",
      "Epoch [1/3], Batch [2466/2500], Loss: 0.19200284779071808\n",
      "Epoch [1/3], Batch [2467/2500], Loss: 0.2730964124202728\n",
      "Epoch [1/3], Batch [2468/2500], Loss: 0.040258366614580154\n",
      "Epoch [1/3], Batch [2469/2500], Loss: 0.15505537390708923\n",
      "Epoch [1/3], Batch [2470/2500], Loss: 0.08090055733919144\n",
      "Epoch [1/3], Batch [2471/2500], Loss: 0.14793828129768372\n",
      "Epoch [1/3], Batch [2472/2500], Loss: 0.4508291482925415\n",
      "Epoch [1/3], Batch [2473/2500], Loss: 0.32980862259864807\n",
      "Epoch [1/3], Batch [2474/2500], Loss: 0.1203598827123642\n",
      "Epoch [1/3], Batch [2475/2500], Loss: 0.3096354305744171\n",
      "Epoch [1/3], Batch [2476/2500], Loss: 0.17074419558048248\n",
      "Epoch [1/3], Batch [2477/2500], Loss: 0.1791740357875824\n",
      "Epoch [1/3], Batch [2478/2500], Loss: 0.7999908328056335\n",
      "Epoch [1/3], Batch [2479/2500], Loss: 0.22226735949516296\n",
      "Epoch [1/3], Batch [2480/2500], Loss: 0.15433436632156372\n",
      "Epoch [1/3], Batch [2481/2500], Loss: 0.2422594130039215\n",
      "Epoch [1/3], Batch [2482/2500], Loss: 0.13959957659244537\n",
      "Epoch [1/3], Batch [2483/2500], Loss: 0.3072811961174011\n",
      "Epoch [1/3], Batch [2484/2500], Loss: 0.2239079773426056\n",
      "Epoch [1/3], Batch [2485/2500], Loss: 0.55781090259552\n",
      "Epoch [1/3], Batch [2486/2500], Loss: 0.2804638743400574\n",
      "Epoch [1/3], Batch [2487/2500], Loss: 0.33316758275032043\n",
      "Epoch [1/3], Batch [2488/2500], Loss: 0.2889277935028076\n",
      "Epoch [1/3], Batch [2489/2500], Loss: 0.3263036608695984\n",
      "Epoch [1/3], Batch [2490/2500], Loss: 0.11521445214748383\n",
      "Epoch [1/3], Batch [2491/2500], Loss: 0.5108917951583862\n",
      "Epoch [1/3], Batch [2492/2500], Loss: 0.37832504510879517\n",
      "Epoch [1/3], Batch [2493/2500], Loss: 0.2598869204521179\n",
      "Epoch [1/3], Batch [2494/2500], Loss: 0.17536292970180511\n",
      "Epoch [1/3], Batch [2495/2500], Loss: 0.13080576062202454\n",
      "Epoch [1/3], Batch [2496/2500], Loss: 0.20007802546024323\n",
      "Epoch [1/3], Batch [2497/2500], Loss: 0.24358320236206055\n",
      "Epoch [1/3], Batch [2498/2500], Loss: 0.21969416737556458\n",
      "Epoch [1/3], Batch [2499/2500], Loss: 0.11261821538209915\n",
      "Epoch [1/3], Batch [2500/2500], Loss: 0.2514783442020416\n",
      "Epoch [1/3] Average Loss: 0.35747247423231604\n",
      "Epoch 2/3\n",
      "Epoch [2/3], Batch [1/2500], Loss: 0.2461404800415039\n",
      "Epoch [2/3], Batch [2/2500], Loss: 0.12222713232040405\n",
      "Epoch [2/3], Batch [3/2500], Loss: 0.38885682821273804\n",
      "Epoch [2/3], Batch [4/2500], Loss: 0.17990736663341522\n",
      "Epoch [2/3], Batch [5/2500], Loss: 0.4647974669933319\n",
      "Epoch [2/3], Batch [6/2500], Loss: 0.3052227795124054\n",
      "Epoch [2/3], Batch [7/2500], Loss: 0.3389432728290558\n",
      "Epoch [2/3], Batch [8/2500], Loss: 0.14459063112735748\n",
      "Epoch [2/3], Batch [9/2500], Loss: 0.47070252895355225\n",
      "Epoch [2/3], Batch [10/2500], Loss: 0.2545132339000702\n",
      "Epoch [2/3], Batch [11/2500], Loss: 0.12512096762657166\n",
      "Epoch [2/3], Batch [12/2500], Loss: 0.5348629951477051\n",
      "Epoch [2/3], Batch [13/2500], Loss: 0.140694722533226\n",
      "Epoch [2/3], Batch [14/2500], Loss: 0.22399094700813293\n",
      "Epoch [2/3], Batch [15/2500], Loss: 0.08240202069282532\n",
      "Epoch [2/3], Batch [16/2500], Loss: 0.09533311426639557\n",
      "Epoch [2/3], Batch [17/2500], Loss: 0.20503051578998566\n",
      "Epoch [2/3], Batch [18/2500], Loss: 0.21371948719024658\n",
      "Epoch [2/3], Batch [19/2500], Loss: 0.4445507228374481\n",
      "Epoch [2/3], Batch [20/2500], Loss: 0.21124060451984406\n",
      "Epoch [2/3], Batch [21/2500], Loss: 0.17749354243278503\n",
      "Epoch [2/3], Batch [22/2500], Loss: 0.38620397448539734\n",
      "Epoch [2/3], Batch [23/2500], Loss: 0.13335078954696655\n",
      "Epoch [2/3], Batch [24/2500], Loss: 0.3680671155452728\n",
      "Epoch [2/3], Batch [25/2500], Loss: 0.36769333481788635\n",
      "Epoch [2/3], Batch [26/2500], Loss: 0.1984608918428421\n",
      "Epoch [2/3], Batch [27/2500], Loss: 0.13628381490707397\n",
      "Epoch [2/3], Batch [28/2500], Loss: 0.117799311876297\n",
      "Epoch [2/3], Batch [29/2500], Loss: 0.12817883491516113\n",
      "Epoch [2/3], Batch [30/2500], Loss: 0.12091934680938721\n",
      "Epoch [2/3], Batch [31/2500], Loss: 0.19579924643039703\n",
      "Epoch [2/3], Batch [32/2500], Loss: 0.2877439260482788\n",
      "Epoch [2/3], Batch [33/2500], Loss: 0.11903178691864014\n",
      "Epoch [2/3], Batch [34/2500], Loss: 0.29834601283073425\n",
      "Epoch [2/3], Batch [35/2500], Loss: 0.11968626081943512\n",
      "Epoch [2/3], Batch [36/2500], Loss: 0.04524398595094681\n",
      "Epoch [2/3], Batch [37/2500], Loss: 0.1255008727312088\n",
      "Epoch [2/3], Batch [38/2500], Loss: 0.1120385229587555\n",
      "Epoch [2/3], Batch [39/2500], Loss: 0.6910315752029419\n",
      "Epoch [2/3], Batch [40/2500], Loss: 0.13952550292015076\n",
      "Epoch [2/3], Batch [41/2500], Loss: 0.07590799033641815\n",
      "Epoch [2/3], Batch [42/2500], Loss: 0.24131149053573608\n",
      "Epoch [2/3], Batch [43/2500], Loss: 0.3980153501033783\n",
      "Epoch [2/3], Batch [44/2500], Loss: 0.5005248188972473\n",
      "Epoch [2/3], Batch [45/2500], Loss: 0.28511732816696167\n",
      "Epoch [2/3], Batch [46/2500], Loss: 0.1689959317445755\n",
      "Epoch [2/3], Batch [47/2500], Loss: 0.44147980213165283\n",
      "Epoch [2/3], Batch [48/2500], Loss: 0.386330246925354\n",
      "Epoch [2/3], Batch [49/2500], Loss: 0.07180719822645187\n",
      "Epoch [2/3], Batch [50/2500], Loss: 0.18766659498214722\n",
      "Epoch [2/3], Batch [51/2500], Loss: 0.2778506875038147\n",
      "Epoch [2/3], Batch [52/2500], Loss: 0.22447510063648224\n",
      "Epoch [2/3], Batch [53/2500], Loss: 0.2730616331100464\n",
      "Epoch [2/3], Batch [54/2500], Loss: 0.15187561511993408\n",
      "Epoch [2/3], Batch [55/2500], Loss: 0.21845397353172302\n",
      "Epoch [2/3], Batch [56/2500], Loss: 0.13060133159160614\n",
      "Epoch [2/3], Batch [57/2500], Loss: 0.06921112537384033\n",
      "Epoch [2/3], Batch [58/2500], Loss: 0.24639892578125\n",
      "Epoch [2/3], Batch [59/2500], Loss: 0.03233043849468231\n",
      "Epoch [2/3], Batch [60/2500], Loss: 0.2128036767244339\n",
      "Epoch [2/3], Batch [61/2500], Loss: 0.2814072370529175\n",
      "Epoch [2/3], Batch [62/2500], Loss: 0.18498116731643677\n",
      "Epoch [2/3], Batch [63/2500], Loss: 0.214575856924057\n",
      "Epoch [2/3], Batch [64/2500], Loss: 0.08247892558574677\n",
      "Epoch [2/3], Batch [65/2500], Loss: 0.07284630089998245\n",
      "Epoch [2/3], Batch [66/2500], Loss: 0.13989245891571045\n",
      "Epoch [2/3], Batch [67/2500], Loss: 0.24368466436862946\n",
      "Epoch [2/3], Batch [68/2500], Loss: 0.1432364583015442\n",
      "Epoch [2/3], Batch [69/2500], Loss: 0.15681731700897217\n",
      "Epoch [2/3], Batch [70/2500], Loss: 0.3729395270347595\n",
      "Epoch [2/3], Batch [71/2500], Loss: 0.08010096102952957\n",
      "Epoch [2/3], Batch [72/2500], Loss: 0.2239827960729599\n",
      "Epoch [2/3], Batch [73/2500], Loss: 0.40359723567962646\n",
      "Epoch [2/3], Batch [74/2500], Loss: 0.061964355409145355\n",
      "Epoch [2/3], Batch [75/2500], Loss: 0.3088858723640442\n",
      "Epoch [2/3], Batch [76/2500], Loss: 0.2937043011188507\n",
      "Epoch [2/3], Batch [77/2500], Loss: 0.1608748435974121\n",
      "Epoch [2/3], Batch [78/2500], Loss: 0.4104960560798645\n",
      "Epoch [2/3], Batch [79/2500], Loss: 0.1251225471496582\n",
      "Epoch [2/3], Batch [80/2500], Loss: 0.16711345314979553\n",
      "Epoch [2/3], Batch [81/2500], Loss: 0.13289625942707062\n",
      "Epoch [2/3], Batch [82/2500], Loss: 0.2683362662792206\n",
      "Epoch [2/3], Batch [83/2500], Loss: 0.22583216428756714\n",
      "Epoch [2/3], Batch [84/2500], Loss: 0.2414056360721588\n",
      "Epoch [2/3], Batch [85/2500], Loss: 0.0821642056107521\n",
      "Epoch [2/3], Batch [86/2500], Loss: 0.07553569227457047\n",
      "Epoch [2/3], Batch [87/2500], Loss: 0.07958555221557617\n",
      "Epoch [2/3], Batch [88/2500], Loss: 0.38268205523490906\n",
      "Epoch [2/3], Batch [89/2500], Loss: 0.23869404196739197\n",
      "Epoch [2/3], Batch [90/2500], Loss: 0.21546511352062225\n",
      "Epoch [2/3], Batch [91/2500], Loss: 0.1836276799440384\n",
      "Epoch [2/3], Batch [92/2500], Loss: 0.05521129071712494\n",
      "Epoch [2/3], Batch [93/2500], Loss: 0.14156420528888702\n",
      "Epoch [2/3], Batch [94/2500], Loss: 0.2746477723121643\n",
      "Epoch [2/3], Batch [95/2500], Loss: 0.18150055408477783\n",
      "Epoch [2/3], Batch [96/2500], Loss: 0.19145892560482025\n",
      "Epoch [2/3], Batch [97/2500], Loss: 0.43512916564941406\n",
      "Epoch [2/3], Batch [98/2500], Loss: 0.15546870231628418\n",
      "Epoch [2/3], Batch [99/2500], Loss: 0.3703339397907257\n",
      "Epoch [2/3], Batch [100/2500], Loss: 0.1306440532207489\n",
      "Epoch [2/3], Batch [101/2500], Loss: 0.32883965969085693\n",
      "Epoch [2/3], Batch [102/2500], Loss: 0.2401941865682602\n",
      "Epoch [2/3], Batch [103/2500], Loss: 0.09510275721549988\n",
      "Epoch [2/3], Batch [104/2500], Loss: 0.20122814178466797\n",
      "Epoch [2/3], Batch [105/2500], Loss: 0.3685099184513092\n",
      "Epoch [2/3], Batch [106/2500], Loss: 0.6888467073440552\n",
      "Epoch [2/3], Batch [107/2500], Loss: 0.058390069752931595\n",
      "Epoch [2/3], Batch [108/2500], Loss: 0.1480594277381897\n",
      "Epoch [2/3], Batch [109/2500], Loss: 0.5500413179397583\n",
      "Epoch [2/3], Batch [110/2500], Loss: 0.20668311417102814\n",
      "Epoch [2/3], Batch [111/2500], Loss: 0.21622325479984283\n",
      "Epoch [2/3], Batch [112/2500], Loss: 0.41095760464668274\n",
      "Epoch [2/3], Batch [113/2500], Loss: 0.24720391631126404\n",
      "Epoch [2/3], Batch [114/2500], Loss: 0.31887882947921753\n",
      "Epoch [2/3], Batch [115/2500], Loss: 0.24346408247947693\n",
      "Epoch [2/3], Batch [116/2500], Loss: 0.10837116092443466\n",
      "Epoch [2/3], Batch [117/2500], Loss: 0.13086923956871033\n",
      "Epoch [2/3], Batch [118/2500], Loss: 0.3304048776626587\n",
      "Epoch [2/3], Batch [119/2500], Loss: 0.06058383733034134\n",
      "Epoch [2/3], Batch [120/2500], Loss: 0.2314658910036087\n",
      "Epoch [2/3], Batch [121/2500], Loss: 0.29801371693611145\n",
      "Epoch [2/3], Batch [122/2500], Loss: 0.12459678947925568\n",
      "Epoch [2/3], Batch [123/2500], Loss: 0.30932316184043884\n",
      "Epoch [2/3], Batch [124/2500], Loss: 0.10981713980436325\n",
      "Epoch [2/3], Batch [125/2500], Loss: 0.26542288064956665\n",
      "Epoch [2/3], Batch [126/2500], Loss: 0.13164721429347992\n",
      "Epoch [2/3], Batch [127/2500], Loss: 0.07446582615375519\n",
      "Epoch [2/3], Batch [128/2500], Loss: 0.3480951189994812\n",
      "Epoch [2/3], Batch [129/2500], Loss: 0.27123358845710754\n",
      "Epoch [2/3], Batch [130/2500], Loss: 0.43611037731170654\n",
      "Epoch [2/3], Batch [131/2500], Loss: 0.12835188210010529\n",
      "Epoch [2/3], Batch [132/2500], Loss: 0.2210835963487625\n",
      "Epoch [2/3], Batch [133/2500], Loss: 0.07895752042531967\n",
      "Epoch [2/3], Batch [134/2500], Loss: 0.1090320497751236\n",
      "Epoch [2/3], Batch [135/2500], Loss: 0.12554818391799927\n",
      "Epoch [2/3], Batch [136/2500], Loss: 0.23962345719337463\n",
      "Epoch [2/3], Batch [137/2500], Loss: 0.39421725273132324\n",
      "Epoch [2/3], Batch [138/2500], Loss: 0.1851697713136673\n",
      "Epoch [2/3], Batch [139/2500], Loss: 0.35075128078460693\n",
      "Epoch [2/3], Batch [140/2500], Loss: 0.20852909982204437\n",
      "Epoch [2/3], Batch [141/2500], Loss: 0.21765024960041046\n",
      "Epoch [2/3], Batch [142/2500], Loss: 0.2145613431930542\n",
      "Epoch [2/3], Batch [143/2500], Loss: 0.2044820487499237\n",
      "Epoch [2/3], Batch [144/2500], Loss: 0.21416528522968292\n",
      "Epoch [2/3], Batch [145/2500], Loss: 0.1254735291004181\n",
      "Epoch [2/3], Batch [146/2500], Loss: 0.2415326088666916\n",
      "Epoch [2/3], Batch [147/2500], Loss: 0.18253539502620697\n",
      "Epoch [2/3], Batch [148/2500], Loss: 0.1545054018497467\n",
      "Epoch [2/3], Batch [149/2500], Loss: 0.21316564083099365\n",
      "Epoch [2/3], Batch [150/2500], Loss: 0.47480976581573486\n",
      "Epoch [2/3], Batch [151/2500], Loss: 0.17338429391384125\n",
      "Epoch [2/3], Batch [152/2500], Loss: 0.031954918056726456\n",
      "Epoch [2/3], Batch [153/2500], Loss: 0.07653754204511642\n",
      "Epoch [2/3], Batch [154/2500], Loss: 0.15389156341552734\n",
      "Epoch [2/3], Batch [155/2500], Loss: 0.1603260487318039\n",
      "Epoch [2/3], Batch [156/2500], Loss: 0.08881161361932755\n",
      "Epoch [2/3], Batch [157/2500], Loss: 0.1278121918439865\n",
      "Epoch [2/3], Batch [158/2500], Loss: 0.3464280366897583\n",
      "Epoch [2/3], Batch [159/2500], Loss: 0.05762657895684242\n",
      "Epoch [2/3], Batch [160/2500], Loss: 0.2951697111129761\n",
      "Epoch [2/3], Batch [161/2500], Loss: 0.20885536074638367\n",
      "Epoch [2/3], Batch [162/2500], Loss: 0.3278929591178894\n",
      "Epoch [2/3], Batch [163/2500], Loss: 0.2590126693248749\n",
      "Epoch [2/3], Batch [164/2500], Loss: 0.44187113642692566\n",
      "Epoch [2/3], Batch [165/2500], Loss: 0.04285559803247452\n",
      "Epoch [2/3], Batch [166/2500], Loss: 0.06360231339931488\n",
      "Epoch [2/3], Batch [167/2500], Loss: 0.17320996522903442\n",
      "Epoch [2/3], Batch [168/2500], Loss: 0.4241912066936493\n",
      "Epoch [2/3], Batch [169/2500], Loss: 0.5166705250740051\n",
      "Epoch [2/3], Batch [170/2500], Loss: 0.06870173662900925\n",
      "Epoch [2/3], Batch [171/2500], Loss: 0.4732409715652466\n",
      "Epoch [2/3], Batch [172/2500], Loss: 0.2788541615009308\n",
      "Epoch [2/3], Batch [173/2500], Loss: 0.2615560293197632\n",
      "Epoch [2/3], Batch [174/2500], Loss: 0.10102663934230804\n",
      "Epoch [2/3], Batch [175/2500], Loss: 0.19111037254333496\n",
      "Epoch [2/3], Batch [176/2500], Loss: 0.21324047446250916\n",
      "Epoch [2/3], Batch [177/2500], Loss: 0.056511908769607544\n",
      "Epoch [2/3], Batch [178/2500], Loss: 0.3354218304157257\n",
      "Epoch [2/3], Batch [179/2500], Loss: 0.22578972578048706\n",
      "Epoch [2/3], Batch [180/2500], Loss: 0.06816384196281433\n",
      "Epoch [2/3], Batch [181/2500], Loss: 0.12368016690015793\n",
      "Epoch [2/3], Batch [182/2500], Loss: 0.10828990489244461\n",
      "Epoch [2/3], Batch [183/2500], Loss: 0.2995434105396271\n",
      "Epoch [2/3], Batch [184/2500], Loss: 0.18036162853240967\n",
      "Epoch [2/3], Batch [185/2500], Loss: 0.04336788132786751\n",
      "Epoch [2/3], Batch [186/2500], Loss: 0.25257450342178345\n",
      "Epoch [2/3], Batch [187/2500], Loss: 0.3434488773345947\n",
      "Epoch [2/3], Batch [188/2500], Loss: 0.1333387792110443\n",
      "Epoch [2/3], Batch [189/2500], Loss: 0.27397361397743225\n",
      "Epoch [2/3], Batch [190/2500], Loss: 0.1703081876039505\n",
      "Epoch [2/3], Batch [191/2500], Loss: 0.17114195227622986\n",
      "Epoch [2/3], Batch [192/2500], Loss: 0.1757689118385315\n",
      "Epoch [2/3], Batch [193/2500], Loss: 0.08469544351100922\n",
      "Epoch [2/3], Batch [194/2500], Loss: 0.23656129837036133\n",
      "Epoch [2/3], Batch [195/2500], Loss: 0.3599940836429596\n",
      "Epoch [2/3], Batch [196/2500], Loss: 0.2950764298439026\n",
      "Epoch [2/3], Batch [197/2500], Loss: 0.3374417722225189\n",
      "Epoch [2/3], Batch [198/2500], Loss: 0.2414267510175705\n",
      "Epoch [2/3], Batch [199/2500], Loss: 0.053297996520996094\n",
      "Epoch [2/3], Batch [200/2500], Loss: 0.34149426221847534\n",
      "Epoch [2/3], Batch [201/2500], Loss: 0.3015938699245453\n",
      "Epoch [2/3], Batch [202/2500], Loss: 0.49963822960853577\n",
      "Epoch [2/3], Batch [203/2500], Loss: 0.21828581392765045\n",
      "Epoch [2/3], Batch [204/2500], Loss: 0.06907366961240768\n",
      "Epoch [2/3], Batch [205/2500], Loss: 0.2218431830406189\n",
      "Epoch [2/3], Batch [206/2500], Loss: 0.06506738066673279\n",
      "Epoch [2/3], Batch [207/2500], Loss: 0.11950136721134186\n",
      "Epoch [2/3], Batch [208/2500], Loss: 0.12962372601032257\n",
      "Epoch [2/3], Batch [209/2500], Loss: 0.03906800597906113\n",
      "Epoch [2/3], Batch [210/2500], Loss: 0.26538434624671936\n",
      "Epoch [2/3], Batch [211/2500], Loss: 0.0999983549118042\n",
      "Epoch [2/3], Batch [212/2500], Loss: 0.3608528971672058\n",
      "Epoch [2/3], Batch [213/2500], Loss: 0.05026901513338089\n",
      "Epoch [2/3], Batch [214/2500], Loss: 0.0421137697994709\n",
      "Epoch [2/3], Batch [215/2500], Loss: 0.1459023803472519\n",
      "Epoch [2/3], Batch [216/2500], Loss: 0.19557112455368042\n",
      "Epoch [2/3], Batch [217/2500], Loss: 0.6206534504890442\n",
      "Epoch [2/3], Batch [218/2500], Loss: 0.17989785969257355\n",
      "Epoch [2/3], Batch [219/2500], Loss: 0.10209882259368896\n",
      "Epoch [2/3], Batch [220/2500], Loss: 0.21481671929359436\n",
      "Epoch [2/3], Batch [221/2500], Loss: 0.2769978940486908\n",
      "Epoch [2/3], Batch [222/2500], Loss: 0.30180010199546814\n",
      "Epoch [2/3], Batch [223/2500], Loss: 0.09198349714279175\n",
      "Epoch [2/3], Batch [224/2500], Loss: 0.23609912395477295\n",
      "Epoch [2/3], Batch [225/2500], Loss: 0.09083335846662521\n",
      "Epoch [2/3], Batch [226/2500], Loss: 0.36562228202819824\n",
      "Epoch [2/3], Batch [227/2500], Loss: 0.06467904895544052\n",
      "Epoch [2/3], Batch [228/2500], Loss: 0.06585852801799774\n",
      "Epoch [2/3], Batch [229/2500], Loss: 0.2287096381187439\n",
      "Epoch [2/3], Batch [230/2500], Loss: 0.033910222351551056\n",
      "Epoch [2/3], Batch [231/2500], Loss: 0.04773035645484924\n",
      "Epoch [2/3], Batch [232/2500], Loss: 0.03170515596866608\n",
      "Epoch [2/3], Batch [233/2500], Loss: 0.20887523889541626\n",
      "Epoch [2/3], Batch [234/2500], Loss: 0.11349339783191681\n",
      "Epoch [2/3], Batch [235/2500], Loss: 0.15588080883026123\n",
      "Epoch [2/3], Batch [236/2500], Loss: 0.23475919663906097\n",
      "Epoch [2/3], Batch [237/2500], Loss: 0.1396351009607315\n",
      "Epoch [2/3], Batch [238/2500], Loss: 0.3380274474620819\n",
      "Epoch [2/3], Batch [239/2500], Loss: 0.02507099136710167\n",
      "Epoch [2/3], Batch [240/2500], Loss: 0.3701432943344116\n",
      "Epoch [2/3], Batch [241/2500], Loss: 0.03622636944055557\n",
      "Epoch [2/3], Batch [242/2500], Loss: 0.12189347296953201\n",
      "Epoch [2/3], Batch [243/2500], Loss: 0.3508397936820984\n",
      "Epoch [2/3], Batch [244/2500], Loss: 0.6905863285064697\n",
      "Epoch [2/3], Batch [245/2500], Loss: 0.15319140255451202\n",
      "Epoch [2/3], Batch [246/2500], Loss: 0.33208274841308594\n",
      "Epoch [2/3], Batch [247/2500], Loss: 0.37352272868156433\n",
      "Epoch [2/3], Batch [248/2500], Loss: 0.24882908165454865\n",
      "Epoch [2/3], Batch [249/2500], Loss: 0.17612817883491516\n",
      "Epoch [2/3], Batch [250/2500], Loss: 0.11022315919399261\n",
      "Epoch [2/3], Batch [251/2500], Loss: 0.24401438236236572\n",
      "Epoch [2/3], Batch [252/2500], Loss: 0.11848752200603485\n",
      "Epoch [2/3], Batch [253/2500], Loss: 0.195848748087883\n",
      "Epoch [2/3], Batch [254/2500], Loss: 0.3538905680179596\n",
      "Epoch [2/3], Batch [255/2500], Loss: 0.12022872269153595\n",
      "Epoch [2/3], Batch [256/2500], Loss: 0.12110434472560883\n",
      "Epoch [2/3], Batch [257/2500], Loss: 0.4562554359436035\n",
      "Epoch [2/3], Batch [258/2500], Loss: 0.22986532747745514\n",
      "Epoch [2/3], Batch [259/2500], Loss: 0.26734229922294617\n",
      "Epoch [2/3], Batch [260/2500], Loss: 0.14074184000492096\n",
      "Epoch [2/3], Batch [261/2500], Loss: 0.20492985844612122\n",
      "Epoch [2/3], Batch [262/2500], Loss: 0.33034202456474304\n",
      "Epoch [2/3], Batch [263/2500], Loss: 0.06742291152477264\n",
      "Epoch [2/3], Batch [264/2500], Loss: 0.03167598694562912\n",
      "Epoch [2/3], Batch [265/2500], Loss: 0.4769982695579529\n",
      "Epoch [2/3], Batch [266/2500], Loss: 0.26501888036727905\n",
      "Epoch [2/3], Batch [267/2500], Loss: 0.047349713742733\n",
      "Epoch [2/3], Batch [268/2500], Loss: 0.23731081187725067\n",
      "Epoch [2/3], Batch [269/2500], Loss: 0.2600817382335663\n",
      "Epoch [2/3], Batch [270/2500], Loss: 0.38178980350494385\n",
      "Epoch [2/3], Batch [271/2500], Loss: 0.22450940310955048\n",
      "Epoch [2/3], Batch [272/2500], Loss: 0.1577291637659073\n",
      "Epoch [2/3], Batch [273/2500], Loss: 0.5844401121139526\n",
      "Epoch [2/3], Batch [274/2500], Loss: 0.13552512228488922\n",
      "Epoch [2/3], Batch [275/2500], Loss: 0.18434888124465942\n",
      "Epoch [2/3], Batch [276/2500], Loss: 0.18450649082660675\n",
      "Epoch [2/3], Batch [277/2500], Loss: 0.07919232547283173\n",
      "Epoch [2/3], Batch [278/2500], Loss: 0.13033047318458557\n",
      "Epoch [2/3], Batch [279/2500], Loss: 0.5843155384063721\n",
      "Epoch [2/3], Batch [280/2500], Loss: 0.23081743717193604\n",
      "Epoch [2/3], Batch [281/2500], Loss: 0.056899961084127426\n",
      "Epoch [2/3], Batch [282/2500], Loss: 0.30363646149635315\n",
      "Epoch [2/3], Batch [283/2500], Loss: 0.1283426433801651\n",
      "Epoch [2/3], Batch [284/2500], Loss: 0.3378759026527405\n",
      "Epoch [2/3], Batch [285/2500], Loss: 0.2266736775636673\n",
      "Epoch [2/3], Batch [286/2500], Loss: 0.10045001655817032\n",
      "Epoch [2/3], Batch [287/2500], Loss: 0.1482589989900589\n",
      "Epoch [2/3], Batch [288/2500], Loss: 0.27607741951942444\n",
      "Epoch [2/3], Batch [289/2500], Loss: 0.13492831587791443\n",
      "Epoch [2/3], Batch [290/2500], Loss: 0.16940779983997345\n",
      "Epoch [2/3], Batch [291/2500], Loss: 0.3136883080005646\n",
      "Epoch [2/3], Batch [292/2500], Loss: 0.12197410315275192\n",
      "Epoch [2/3], Batch [293/2500], Loss: 0.31663060188293457\n",
      "Epoch [2/3], Batch [294/2500], Loss: 0.16386529803276062\n",
      "Epoch [2/3], Batch [295/2500], Loss: 0.09592418372631073\n",
      "Epoch [2/3], Batch [296/2500], Loss: 0.40475180745124817\n",
      "Epoch [2/3], Batch [297/2500], Loss: 0.07920090109109879\n",
      "Epoch [2/3], Batch [298/2500], Loss: 0.3342643976211548\n",
      "Epoch [2/3], Batch [299/2500], Loss: 0.11062124371528625\n",
      "Epoch [2/3], Batch [300/2500], Loss: 0.2742997109889984\n",
      "Epoch [2/3], Batch [301/2500], Loss: 0.23216916620731354\n",
      "Epoch [2/3], Batch [302/2500], Loss: 0.39942601323127747\n",
      "Epoch [2/3], Batch [303/2500], Loss: 0.18471087515354156\n",
      "Epoch [2/3], Batch [304/2500], Loss: 0.17803624272346497\n",
      "Epoch [2/3], Batch [305/2500], Loss: 0.21188612282276154\n",
      "Epoch [2/3], Batch [306/2500], Loss: 0.3406096398830414\n",
      "Epoch [2/3], Batch [307/2500], Loss: 0.12583862245082855\n",
      "Epoch [2/3], Batch [308/2500], Loss: 0.33850547671318054\n",
      "Epoch [2/3], Batch [309/2500], Loss: 0.1064695194363594\n",
      "Epoch [2/3], Batch [310/2500], Loss: 0.37352505326271057\n",
      "Epoch [2/3], Batch [311/2500], Loss: 0.2000766545534134\n",
      "Epoch [2/3], Batch [312/2500], Loss: 0.05593591555953026\n",
      "Epoch [2/3], Batch [313/2500], Loss: 0.18717899918556213\n",
      "Epoch [2/3], Batch [314/2500], Loss: 0.2655492424964905\n",
      "Epoch [2/3], Batch [315/2500], Loss: 0.14730454981327057\n",
      "Epoch [2/3], Batch [316/2500], Loss: 0.4092978239059448\n",
      "Epoch [2/3], Batch [317/2500], Loss: 0.15292365849018097\n",
      "Epoch [2/3], Batch [318/2500], Loss: 0.20587453246116638\n",
      "Epoch [2/3], Batch [319/2500], Loss: 0.28462347388267517\n",
      "Epoch [2/3], Batch [320/2500], Loss: 0.3953431248664856\n",
      "Epoch [2/3], Batch [321/2500], Loss: 0.3026962876319885\n",
      "Epoch [2/3], Batch [322/2500], Loss: 0.05351314693689346\n",
      "Epoch [2/3], Batch [323/2500], Loss: 0.25076237320899963\n",
      "Epoch [2/3], Batch [324/2500], Loss: 0.07260936498641968\n",
      "Epoch [2/3], Batch [325/2500], Loss: 0.27598971128463745\n",
      "Epoch [2/3], Batch [326/2500], Loss: 0.07089950889348984\n",
      "Epoch [2/3], Batch [327/2500], Loss: 0.18056243658065796\n",
      "Epoch [2/3], Batch [328/2500], Loss: 0.08361998200416565\n",
      "Epoch [2/3], Batch [329/2500], Loss: 0.1399664580821991\n",
      "Epoch [2/3], Batch [330/2500], Loss: 0.06468908488750458\n",
      "Epoch [2/3], Batch [331/2500], Loss: 0.15262827277183533\n",
      "Epoch [2/3], Batch [332/2500], Loss: 0.25197911262512207\n",
      "Epoch [2/3], Batch [333/2500], Loss: 0.24684037268161774\n",
      "Epoch [2/3], Batch [334/2500], Loss: 0.6255800127983093\n",
      "Epoch [2/3], Batch [335/2500], Loss: 0.5964180827140808\n",
      "Epoch [2/3], Batch [336/2500], Loss: 0.21188147366046906\n",
      "Epoch [2/3], Batch [337/2500], Loss: 0.22786518931388855\n",
      "Epoch [2/3], Batch [338/2500], Loss: 0.1038978323340416\n",
      "Epoch [2/3], Batch [339/2500], Loss: 0.2723903954029083\n",
      "Epoch [2/3], Batch [340/2500], Loss: 0.37978240847587585\n",
      "Epoch [2/3], Batch [341/2500], Loss: 0.34586837887763977\n",
      "Epoch [2/3], Batch [342/2500], Loss: 0.13962507247924805\n",
      "Epoch [2/3], Batch [343/2500], Loss: 0.20961898565292358\n",
      "Epoch [2/3], Batch [344/2500], Loss: 0.03070259839296341\n",
      "Epoch [2/3], Batch [345/2500], Loss: 0.25149333477020264\n",
      "Epoch [2/3], Batch [346/2500], Loss: 0.2689856290817261\n",
      "Epoch [2/3], Batch [347/2500], Loss: 0.34316131472587585\n",
      "Epoch [2/3], Batch [348/2500], Loss: 0.12941914796829224\n",
      "Epoch [2/3], Batch [349/2500], Loss: 0.07910393923521042\n",
      "Epoch [2/3], Batch [350/2500], Loss: 0.17287643253803253\n",
      "Epoch [2/3], Batch [351/2500], Loss: 0.15059460699558258\n",
      "Epoch [2/3], Batch [352/2500], Loss: 0.3464256227016449\n",
      "Epoch [2/3], Batch [353/2500], Loss: 0.4994763135910034\n",
      "Epoch [2/3], Batch [354/2500], Loss: 0.12316791713237762\n",
      "Epoch [2/3], Batch [355/2500], Loss: 0.3071567714214325\n",
      "Epoch [2/3], Batch [356/2500], Loss: 0.04827342927455902\n",
      "Epoch [2/3], Batch [357/2500], Loss: 0.10788774490356445\n",
      "Epoch [2/3], Batch [358/2500], Loss: 0.052678126841783524\n",
      "Epoch [2/3], Batch [359/2500], Loss: 0.06284969300031662\n",
      "Epoch [2/3], Batch [360/2500], Loss: 0.13498824834823608\n",
      "Epoch [2/3], Batch [361/2500], Loss: 0.0322534516453743\n",
      "Epoch [2/3], Batch [362/2500], Loss: 0.6348891258239746\n",
      "Epoch [2/3], Batch [363/2500], Loss: 0.2116910219192505\n",
      "Epoch [2/3], Batch [364/2500], Loss: 0.21346928179264069\n",
      "Epoch [2/3], Batch [365/2500], Loss: 0.3054201304912567\n",
      "Epoch [2/3], Batch [366/2500], Loss: 0.12420162558555603\n",
      "Epoch [2/3], Batch [367/2500], Loss: 0.13592389225959778\n",
      "Epoch [2/3], Batch [368/2500], Loss: 0.2702951729297638\n",
      "Epoch [2/3], Batch [369/2500], Loss: 0.1915913224220276\n",
      "Epoch [2/3], Batch [370/2500], Loss: 0.10970550030469894\n",
      "Epoch [2/3], Batch [371/2500], Loss: 0.2817538380622864\n",
      "Epoch [2/3], Batch [372/2500], Loss: 0.26447683572769165\n",
      "Epoch [2/3], Batch [373/2500], Loss: 0.26697710156440735\n",
      "Epoch [2/3], Batch [374/2500], Loss: 0.03512343019247055\n",
      "Epoch [2/3], Batch [375/2500], Loss: 0.24430404603481293\n",
      "Epoch [2/3], Batch [376/2500], Loss: 0.4044243097305298\n",
      "Epoch [2/3], Batch [377/2500], Loss: 0.12229684740304947\n",
      "Epoch [2/3], Batch [378/2500], Loss: 0.5382389426231384\n",
      "Epoch [2/3], Batch [379/2500], Loss: 0.2683984339237213\n",
      "Epoch [2/3], Batch [380/2500], Loss: 0.05101406201720238\n",
      "Epoch [2/3], Batch [381/2500], Loss: 0.2454610913991928\n",
      "Epoch [2/3], Batch [382/2500], Loss: 0.3066217005252838\n",
      "Epoch [2/3], Batch [383/2500], Loss: 0.052647218108177185\n",
      "Epoch [2/3], Batch [384/2500], Loss: 0.1440536230802536\n",
      "Epoch [2/3], Batch [385/2500], Loss: 0.3069741427898407\n",
      "Epoch [2/3], Batch [386/2500], Loss: 0.16121579706668854\n",
      "Epoch [2/3], Batch [387/2500], Loss: 0.1901162713766098\n",
      "Epoch [2/3], Batch [388/2500], Loss: 0.25163236260414124\n",
      "Epoch [2/3], Batch [389/2500], Loss: 0.05928266793489456\n",
      "Epoch [2/3], Batch [390/2500], Loss: 0.26046323776245117\n",
      "Epoch [2/3], Batch [391/2500], Loss: 0.3362818956375122\n",
      "Epoch [2/3], Batch [392/2500], Loss: 0.21550363302230835\n",
      "Epoch [2/3], Batch [393/2500], Loss: 0.22963181138038635\n",
      "Epoch [2/3], Batch [394/2500], Loss: 0.21249429881572723\n",
      "Epoch [2/3], Batch [395/2500], Loss: 0.25001728534698486\n",
      "Epoch [2/3], Batch [396/2500], Loss: 0.07808905839920044\n",
      "Epoch [2/3], Batch [397/2500], Loss: 0.2937678396701813\n",
      "Epoch [2/3], Batch [398/2500], Loss: 0.2420627623796463\n",
      "Epoch [2/3], Batch [399/2500], Loss: 0.4291728734970093\n",
      "Epoch [2/3], Batch [400/2500], Loss: 0.20395328104496002\n",
      "Epoch [2/3], Batch [401/2500], Loss: 0.1663268506526947\n",
      "Epoch [2/3], Batch [402/2500], Loss: 0.5468529462814331\n",
      "Epoch [2/3], Batch [403/2500], Loss: 0.1931927353143692\n",
      "Epoch [2/3], Batch [404/2500], Loss: 0.343375563621521\n",
      "Epoch [2/3], Batch [405/2500], Loss: 0.034490782767534256\n",
      "Epoch [2/3], Batch [406/2500], Loss: 0.25953641533851624\n",
      "Epoch [2/3], Batch [407/2500], Loss: 0.39168182015419006\n",
      "Epoch [2/3], Batch [408/2500], Loss: 0.21924634277820587\n",
      "Epoch [2/3], Batch [409/2500], Loss: 0.13878753781318665\n",
      "Epoch [2/3], Batch [410/2500], Loss: 0.03879270702600479\n",
      "Epoch [2/3], Batch [411/2500], Loss: 0.3017721474170685\n",
      "Epoch [2/3], Batch [412/2500], Loss: 0.16809898614883423\n",
      "Epoch [2/3], Batch [413/2500], Loss: 0.12847238779067993\n",
      "Epoch [2/3], Batch [414/2500], Loss: 0.058855555951595306\n",
      "Epoch [2/3], Batch [415/2500], Loss: 0.2941504418849945\n",
      "Epoch [2/3], Batch [416/2500], Loss: 0.1483139842748642\n",
      "Epoch [2/3], Batch [417/2500], Loss: 0.30937278270721436\n",
      "Epoch [2/3], Batch [418/2500], Loss: 0.3803306221961975\n",
      "Epoch [2/3], Batch [419/2500], Loss: 0.2884787917137146\n",
      "Epoch [2/3], Batch [420/2500], Loss: 0.17454105615615845\n",
      "Epoch [2/3], Batch [421/2500], Loss: 0.17466479539871216\n",
      "Epoch [2/3], Batch [422/2500], Loss: 0.5518268942832947\n",
      "Epoch [2/3], Batch [423/2500], Loss: 0.3039288818836212\n",
      "Epoch [2/3], Batch [424/2500], Loss: 0.05984265357255936\n",
      "Epoch [2/3], Batch [425/2500], Loss: 0.0935087725520134\n",
      "Epoch [2/3], Batch [426/2500], Loss: 0.20661203563213348\n",
      "Epoch [2/3], Batch [427/2500], Loss: 0.10693223029375076\n",
      "Epoch [2/3], Batch [428/2500], Loss: 0.07681867480278015\n",
      "Epoch [2/3], Batch [429/2500], Loss: 0.28461986780166626\n",
      "Epoch [2/3], Batch [430/2500], Loss: 0.4335438013076782\n",
      "Epoch [2/3], Batch [431/2500], Loss: 0.35385656356811523\n",
      "Epoch [2/3], Batch [432/2500], Loss: 0.05641145259141922\n",
      "Epoch [2/3], Batch [433/2500], Loss: 0.04087162762880325\n",
      "Epoch [2/3], Batch [434/2500], Loss: 0.20978637039661407\n",
      "Epoch [2/3], Batch [435/2500], Loss: 0.2976667582988739\n",
      "Epoch [2/3], Batch [436/2500], Loss: 0.14541828632354736\n",
      "Epoch [2/3], Batch [437/2500], Loss: 0.3527902662754059\n",
      "Epoch [2/3], Batch [438/2500], Loss: 0.051644466817379\n",
      "Epoch [2/3], Batch [439/2500], Loss: 0.6385211944580078\n",
      "Epoch [2/3], Batch [440/2500], Loss: 0.2782234847545624\n",
      "Epoch [2/3], Batch [441/2500], Loss: 0.3297399878501892\n",
      "Epoch [2/3], Batch [442/2500], Loss: 0.12763650715351105\n",
      "Epoch [2/3], Batch [443/2500], Loss: 0.10171448439359665\n",
      "Epoch [2/3], Batch [444/2500], Loss: 0.1879551112651825\n",
      "Epoch [2/3], Batch [445/2500], Loss: 0.08802304416894913\n",
      "Epoch [2/3], Batch [446/2500], Loss: 0.16892458498477936\n",
      "Epoch [2/3], Batch [447/2500], Loss: 0.19476203620433807\n",
      "Epoch [2/3], Batch [448/2500], Loss: 0.5453936457633972\n",
      "Epoch [2/3], Batch [449/2500], Loss: 0.3930765688419342\n",
      "Epoch [2/3], Batch [450/2500], Loss: 0.17061352729797363\n",
      "Epoch [2/3], Batch [451/2500], Loss: 0.18065907061100006\n",
      "Epoch [2/3], Batch [452/2500], Loss: 0.22729869186878204\n",
      "Epoch [2/3], Batch [453/2500], Loss: 0.32391026616096497\n",
      "Epoch [2/3], Batch [454/2500], Loss: 0.10496747493743896\n",
      "Epoch [2/3], Batch [455/2500], Loss: 0.3031182885169983\n",
      "Epoch [2/3], Batch [456/2500], Loss: 0.38568034768104553\n",
      "Epoch [2/3], Batch [457/2500], Loss: 0.3921675682067871\n",
      "Epoch [2/3], Batch [458/2500], Loss: 0.25280240178108215\n",
      "Epoch [2/3], Batch [459/2500], Loss: 0.08718894422054291\n",
      "Epoch [2/3], Batch [460/2500], Loss: 0.34456685185432434\n",
      "Epoch [2/3], Batch [461/2500], Loss: 0.22433951497077942\n",
      "Epoch [2/3], Batch [462/2500], Loss: 0.10706153512001038\n",
      "Epoch [2/3], Batch [463/2500], Loss: 0.2720409631729126\n",
      "Epoch [2/3], Batch [464/2500], Loss: 0.16245076060295105\n",
      "Epoch [2/3], Batch [465/2500], Loss: 0.20556437969207764\n",
      "Epoch [2/3], Batch [466/2500], Loss: 0.2584645450115204\n",
      "Epoch [2/3], Batch [467/2500], Loss: 0.5946635007858276\n",
      "Epoch [2/3], Batch [468/2500], Loss: 0.13607805967330933\n",
      "Epoch [2/3], Batch [469/2500], Loss: 0.22604763507843018\n",
      "Epoch [2/3], Batch [470/2500], Loss: 0.2029390186071396\n",
      "Epoch [2/3], Batch [471/2500], Loss: 0.2381170243024826\n",
      "Epoch [2/3], Batch [472/2500], Loss: 0.14842835068702698\n",
      "Epoch [2/3], Batch [473/2500], Loss: 0.33161476254463196\n",
      "Epoch [2/3], Batch [474/2500], Loss: 0.14288927614688873\n",
      "Epoch [2/3], Batch [475/2500], Loss: 0.1990901380777359\n",
      "Epoch [2/3], Batch [476/2500], Loss: 0.37038901448249817\n",
      "Epoch [2/3], Batch [477/2500], Loss: 0.07818832248449326\n",
      "Epoch [2/3], Batch [478/2500], Loss: 0.21511584520339966\n",
      "Epoch [2/3], Batch [479/2500], Loss: 0.195718452334404\n",
      "Epoch [2/3], Batch [480/2500], Loss: 0.3776284158229828\n",
      "Epoch [2/3], Batch [481/2500], Loss: 0.34058457612991333\n",
      "Epoch [2/3], Batch [482/2500], Loss: 0.1722768098115921\n",
      "Epoch [2/3], Batch [483/2500], Loss: 0.16482718288898468\n",
      "Epoch [2/3], Batch [484/2500], Loss: 0.435119092464447\n",
      "Epoch [2/3], Batch [485/2500], Loss: 0.14047059416770935\n",
      "Epoch [2/3], Batch [486/2500], Loss: 0.36708134412765503\n",
      "Epoch [2/3], Batch [487/2500], Loss: 0.14484423398971558\n",
      "Epoch [2/3], Batch [488/2500], Loss: 0.2021336704492569\n",
      "Epoch [2/3], Batch [489/2500], Loss: 0.1782260537147522\n",
      "Epoch [2/3], Batch [490/2500], Loss: 0.15685534477233887\n",
      "Epoch [2/3], Batch [491/2500], Loss: 0.1968354731798172\n",
      "Epoch [2/3], Batch [492/2500], Loss: 0.20802496373653412\n",
      "Epoch [2/3], Batch [493/2500], Loss: 0.1334356963634491\n",
      "Epoch [2/3], Batch [494/2500], Loss: 0.37218770384788513\n",
      "Epoch [2/3], Batch [495/2500], Loss: 0.35127735137939453\n",
      "Epoch [2/3], Batch [496/2500], Loss: 0.30014538764953613\n",
      "Epoch [2/3], Batch [497/2500], Loss: 0.1337997317314148\n",
      "Epoch [2/3], Batch [498/2500], Loss: 0.3052625060081482\n",
      "Epoch [2/3], Batch [499/2500], Loss: 0.01924811862409115\n",
      "Epoch [2/3], Batch [500/2500], Loss: 0.543715238571167\n",
      "Epoch [2/3], Batch [501/2500], Loss: 0.26222890615463257\n",
      "Epoch [2/3], Batch [502/2500], Loss: 0.15829607844352722\n",
      "Epoch [2/3], Batch [503/2500], Loss: 0.13846255838871002\n",
      "Epoch [2/3], Batch [504/2500], Loss: 0.12901510298252106\n",
      "Epoch [2/3], Batch [505/2500], Loss: 0.17551198601722717\n",
      "Epoch [2/3], Batch [506/2500], Loss: 0.41554006934165955\n",
      "Epoch [2/3], Batch [507/2500], Loss: 0.20230992138385773\n",
      "Epoch [2/3], Batch [508/2500], Loss: 0.07411077618598938\n",
      "Epoch [2/3], Batch [509/2500], Loss: 0.27178409695625305\n",
      "Epoch [2/3], Batch [510/2500], Loss: 0.14462028443813324\n",
      "Epoch [2/3], Batch [511/2500], Loss: 0.11624010652303696\n",
      "Epoch [2/3], Batch [512/2500], Loss: 0.11507528275251389\n",
      "Epoch [2/3], Batch [513/2500], Loss: 0.3477672040462494\n",
      "Epoch [2/3], Batch [514/2500], Loss: 0.08205004781484604\n",
      "Epoch [2/3], Batch [515/2500], Loss: 0.32099980115890503\n",
      "Epoch [2/3], Batch [516/2500], Loss: 0.24537043273448944\n",
      "Epoch [2/3], Batch [517/2500], Loss: 0.7219192981719971\n",
      "Epoch [2/3], Batch [518/2500], Loss: 0.18671010434627533\n",
      "Epoch [2/3], Batch [519/2500], Loss: 0.40589210391044617\n",
      "Epoch [2/3], Batch [520/2500], Loss: 0.09241293370723724\n",
      "Epoch [2/3], Batch [521/2500], Loss: 0.1141475960612297\n",
      "Epoch [2/3], Batch [522/2500], Loss: 0.09490323066711426\n",
      "Epoch [2/3], Batch [523/2500], Loss: 0.14159931242465973\n",
      "Epoch [2/3], Batch [524/2500], Loss: 0.12464013695716858\n",
      "Epoch [2/3], Batch [525/2500], Loss: 0.45150819420814514\n",
      "Epoch [2/3], Batch [526/2500], Loss: 0.12858738005161285\n",
      "Epoch [2/3], Batch [527/2500], Loss: 0.2390126883983612\n",
      "Epoch [2/3], Batch [528/2500], Loss: 0.24087148904800415\n",
      "Epoch [2/3], Batch [529/2500], Loss: 0.21573039889335632\n",
      "Epoch [2/3], Batch [530/2500], Loss: 0.36516016721725464\n",
      "Epoch [2/3], Batch [531/2500], Loss: 0.1895718276500702\n",
      "Epoch [2/3], Batch [532/2500], Loss: 0.14489354193210602\n",
      "Epoch [2/3], Batch [533/2500], Loss: 0.10242888331413269\n",
      "Epoch [2/3], Batch [534/2500], Loss: 0.25447651743888855\n",
      "Epoch [2/3], Batch [535/2500], Loss: 0.12416265904903412\n",
      "Epoch [2/3], Batch [536/2500], Loss: 0.026343073695898056\n",
      "Epoch [2/3], Batch [537/2500], Loss: 0.20558100938796997\n",
      "Epoch [2/3], Batch [538/2500], Loss: 0.19561561942100525\n",
      "Epoch [2/3], Batch [539/2500], Loss: 0.08949899673461914\n",
      "Epoch [2/3], Batch [540/2500], Loss: 0.2807868421077728\n",
      "Epoch [2/3], Batch [541/2500], Loss: 0.08630629628896713\n",
      "Epoch [2/3], Batch [542/2500], Loss: 0.37565454840660095\n",
      "Epoch [2/3], Batch [543/2500], Loss: 0.0497608445584774\n",
      "Epoch [2/3], Batch [544/2500], Loss: 0.17210645973682404\n",
      "Epoch [2/3], Batch [545/2500], Loss: 0.12504775822162628\n",
      "Epoch [2/3], Batch [546/2500], Loss: 0.23659135401248932\n",
      "Epoch [2/3], Batch [547/2500], Loss: 0.03967271000146866\n",
      "Epoch [2/3], Batch [548/2500], Loss: 0.7773002982139587\n",
      "Epoch [2/3], Batch [549/2500], Loss: 0.09619021415710449\n",
      "Epoch [2/3], Batch [550/2500], Loss: 0.0655849426984787\n",
      "Epoch [2/3], Batch [551/2500], Loss: 0.21022731065750122\n",
      "Epoch [2/3], Batch [552/2500], Loss: 0.2372218519449234\n",
      "Epoch [2/3], Batch [553/2500], Loss: 0.25156140327453613\n",
      "Epoch [2/3], Batch [554/2500], Loss: 0.27429476380348206\n",
      "Epoch [2/3], Batch [555/2500], Loss: 0.18008247017860413\n",
      "Epoch [2/3], Batch [556/2500], Loss: 0.0996323674917221\n",
      "Epoch [2/3], Batch [557/2500], Loss: 0.05963565409183502\n",
      "Epoch [2/3], Batch [558/2500], Loss: 0.17754243314266205\n",
      "Epoch [2/3], Batch [559/2500], Loss: 0.318882554769516\n",
      "Epoch [2/3], Batch [560/2500], Loss: 0.053755346685647964\n",
      "Epoch [2/3], Batch [561/2500], Loss: 0.14765001833438873\n",
      "Epoch [2/3], Batch [562/2500], Loss: 0.09249772876501083\n",
      "Epoch [2/3], Batch [563/2500], Loss: 0.141543909907341\n",
      "Epoch [2/3], Batch [564/2500], Loss: 0.21908602118492126\n",
      "Epoch [2/3], Batch [565/2500], Loss: 0.12223184108734131\n",
      "Epoch [2/3], Batch [566/2500], Loss: 0.31807518005371094\n",
      "Epoch [2/3], Batch [567/2500], Loss: 0.6405307054519653\n",
      "Epoch [2/3], Batch [568/2500], Loss: 0.08359069377183914\n",
      "Epoch [2/3], Batch [569/2500], Loss: 0.04619181901216507\n",
      "Epoch [2/3], Batch [570/2500], Loss: 0.2118808925151825\n",
      "Epoch [2/3], Batch [571/2500], Loss: 0.04264712333679199\n",
      "Epoch [2/3], Batch [572/2500], Loss: 0.0348556824028492\n",
      "Epoch [2/3], Batch [573/2500], Loss: 0.5204886794090271\n",
      "Epoch [2/3], Batch [574/2500], Loss: 0.16777345538139343\n",
      "Epoch [2/3], Batch [575/2500], Loss: 0.14862820506095886\n",
      "Epoch [2/3], Batch [576/2500], Loss: 0.05433020740747452\n",
      "Epoch [2/3], Batch [577/2500], Loss: 0.16951946914196014\n",
      "Epoch [2/3], Batch [578/2500], Loss: 0.17674192786216736\n",
      "Epoch [2/3], Batch [579/2500], Loss: 0.09274415671825409\n",
      "Epoch [2/3], Batch [580/2500], Loss: 0.2793879508972168\n",
      "Epoch [2/3], Batch [581/2500], Loss: 0.5488730072975159\n",
      "Epoch [2/3], Batch [582/2500], Loss: 0.3817557394504547\n",
      "Epoch [2/3], Batch [583/2500], Loss: 0.3041321039199829\n",
      "Epoch [2/3], Batch [584/2500], Loss: 0.2076088935136795\n",
      "Epoch [2/3], Batch [585/2500], Loss: 0.03543742373585701\n",
      "Epoch [2/3], Batch [586/2500], Loss: 0.6969140768051147\n",
      "Epoch [2/3], Batch [587/2500], Loss: 0.26905083656311035\n",
      "Epoch [2/3], Batch [588/2500], Loss: 0.0324883908033371\n",
      "Epoch [2/3], Batch [589/2500], Loss: 0.11251500993967056\n",
      "Epoch [2/3], Batch [590/2500], Loss: 0.04572407156229019\n",
      "Epoch [2/3], Batch [591/2500], Loss: 0.8298260569572449\n",
      "Epoch [2/3], Batch [592/2500], Loss: 0.23891451954841614\n",
      "Epoch [2/3], Batch [593/2500], Loss: 0.0874556452035904\n",
      "Epoch [2/3], Batch [594/2500], Loss: 0.4353366494178772\n",
      "Epoch [2/3], Batch [595/2500], Loss: 0.08441546559333801\n",
      "Epoch [2/3], Batch [596/2500], Loss: 0.05459924042224884\n",
      "Epoch [2/3], Batch [597/2500], Loss: 0.05120770260691643\n",
      "Epoch [2/3], Batch [598/2500], Loss: 0.22708311676979065\n",
      "Epoch [2/3], Batch [599/2500], Loss: 0.0627535879611969\n",
      "Epoch [2/3], Batch [600/2500], Loss: 0.13385795056819916\n",
      "Epoch [2/3], Batch [601/2500], Loss: 0.35878345370292664\n",
      "Epoch [2/3], Batch [602/2500], Loss: 0.408031165599823\n",
      "Epoch [2/3], Batch [603/2500], Loss: 0.23133742809295654\n",
      "Epoch [2/3], Batch [604/2500], Loss: 0.0973629504442215\n",
      "Epoch [2/3], Batch [605/2500], Loss: 0.13819780945777893\n",
      "Epoch [2/3], Batch [606/2500], Loss: 0.03058949112892151\n",
      "Epoch [2/3], Batch [607/2500], Loss: 0.2515715956687927\n",
      "Epoch [2/3], Batch [608/2500], Loss: 0.09856389462947845\n",
      "Epoch [2/3], Batch [609/2500], Loss: 0.07876162976026535\n",
      "Epoch [2/3], Batch [610/2500], Loss: 0.3762395679950714\n",
      "Epoch [2/3], Batch [611/2500], Loss: 0.14765363931655884\n",
      "Epoch [2/3], Batch [612/2500], Loss: 0.2119722217321396\n",
      "Epoch [2/3], Batch [613/2500], Loss: 0.04904510825872421\n",
      "Epoch [2/3], Batch [614/2500], Loss: 0.09032705426216125\n",
      "Epoch [2/3], Batch [615/2500], Loss: 0.05565900355577469\n",
      "Epoch [2/3], Batch [616/2500], Loss: 0.44318991899490356\n",
      "Epoch [2/3], Batch [617/2500], Loss: 0.11488256603479385\n",
      "Epoch [2/3], Batch [618/2500], Loss: 0.06496742367744446\n",
      "Epoch [2/3], Batch [619/2500], Loss: 0.08347991108894348\n",
      "Epoch [2/3], Batch [620/2500], Loss: 0.25450143218040466\n",
      "Epoch [2/3], Batch [621/2500], Loss: 0.35136955976486206\n",
      "Epoch [2/3], Batch [622/2500], Loss: 0.06935109198093414\n",
      "Epoch [2/3], Batch [623/2500], Loss: 0.3144906163215637\n",
      "Epoch [2/3], Batch [624/2500], Loss: 0.07914084941148758\n",
      "Epoch [2/3], Batch [625/2500], Loss: 0.44528335332870483\n",
      "Epoch [2/3], Batch [626/2500], Loss: 0.09078051894903183\n",
      "Epoch [2/3], Batch [627/2500], Loss: 0.08279404789209366\n",
      "Epoch [2/3], Batch [628/2500], Loss: 0.31142762303352356\n",
      "Epoch [2/3], Batch [629/2500], Loss: 0.13938164710998535\n",
      "Epoch [2/3], Batch [630/2500], Loss: 0.13696055114269257\n",
      "Epoch [2/3], Batch [631/2500], Loss: 0.43087711930274963\n",
      "Epoch [2/3], Batch [632/2500], Loss: 0.08835761249065399\n",
      "Epoch [2/3], Batch [633/2500], Loss: 0.15988346934318542\n",
      "Epoch [2/3], Batch [634/2500], Loss: 0.3584147095680237\n",
      "Epoch [2/3], Batch [635/2500], Loss: 0.20984329283237457\n",
      "Epoch [2/3], Batch [636/2500], Loss: 0.19123037159442902\n",
      "Epoch [2/3], Batch [637/2500], Loss: 0.3056239187717438\n",
      "Epoch [2/3], Batch [638/2500], Loss: 0.1353415697813034\n",
      "Epoch [2/3], Batch [639/2500], Loss: 0.08082590997219086\n",
      "Epoch [2/3], Batch [640/2500], Loss: 0.2986571192741394\n",
      "Epoch [2/3], Batch [641/2500], Loss: 0.4297301769256592\n",
      "Epoch [2/3], Batch [642/2500], Loss: 0.0694260448217392\n",
      "Epoch [2/3], Batch [643/2500], Loss: 0.2843957245349884\n",
      "Epoch [2/3], Batch [644/2500], Loss: 0.2833944857120514\n",
      "Epoch [2/3], Batch [645/2500], Loss: 0.2689899206161499\n",
      "Epoch [2/3], Batch [646/2500], Loss: 0.0660933181643486\n",
      "Epoch [2/3], Batch [647/2500], Loss: 0.3785591125488281\n",
      "Epoch [2/3], Batch [648/2500], Loss: 0.09870228916406631\n",
      "Epoch [2/3], Batch [649/2500], Loss: 0.5985809564590454\n",
      "Epoch [2/3], Batch [650/2500], Loss: 0.22181075811386108\n",
      "Epoch [2/3], Batch [651/2500], Loss: 0.2538456618785858\n",
      "Epoch [2/3], Batch [652/2500], Loss: 0.10069940984249115\n",
      "Epoch [2/3], Batch [653/2500], Loss: 0.14572113752365112\n",
      "Epoch [2/3], Batch [654/2500], Loss: 0.21450644731521606\n",
      "Epoch [2/3], Batch [655/2500], Loss: 0.26910829544067383\n",
      "Epoch [2/3], Batch [656/2500], Loss: 0.3314158618450165\n",
      "Epoch [2/3], Batch [657/2500], Loss: 0.31734853982925415\n",
      "Epoch [2/3], Batch [658/2500], Loss: 0.2360781729221344\n",
      "Epoch [2/3], Batch [659/2500], Loss: 0.1222781166434288\n",
      "Epoch [2/3], Batch [660/2500], Loss: 0.17217537760734558\n",
      "Epoch [2/3], Batch [661/2500], Loss: 0.09029717743396759\n",
      "Epoch [2/3], Batch [662/2500], Loss: 0.12196024507284164\n",
      "Epoch [2/3], Batch [663/2500], Loss: 0.15929585695266724\n",
      "Epoch [2/3], Batch [664/2500], Loss: 0.6829787492752075\n",
      "Epoch [2/3], Batch [665/2500], Loss: 0.7232258319854736\n",
      "Epoch [2/3], Batch [666/2500], Loss: 0.2802560031414032\n",
      "Epoch [2/3], Batch [667/2500], Loss: 0.2669772803783417\n",
      "Epoch [2/3], Batch [668/2500], Loss: 0.24287371337413788\n",
      "Epoch [2/3], Batch [669/2500], Loss: 0.15266729891300201\n",
      "Epoch [2/3], Batch [670/2500], Loss: 0.08005043864250183\n",
      "Epoch [2/3], Batch [671/2500], Loss: 0.14408960938453674\n",
      "Epoch [2/3], Batch [672/2500], Loss: 0.16092295944690704\n",
      "Epoch [2/3], Batch [673/2500], Loss: 0.37587183713912964\n",
      "Epoch [2/3], Batch [674/2500], Loss: 0.1590431034564972\n",
      "Epoch [2/3], Batch [675/2500], Loss: 0.1582743525505066\n",
      "Epoch [2/3], Batch [676/2500], Loss: 0.09992881864309311\n",
      "Epoch [2/3], Batch [677/2500], Loss: 0.20449835062026978\n",
      "Epoch [2/3], Batch [678/2500], Loss: 0.34837234020233154\n",
      "Epoch [2/3], Batch [679/2500], Loss: 0.2618536651134491\n",
      "Epoch [2/3], Batch [680/2500], Loss: 0.24491673707962036\n",
      "Epoch [2/3], Batch [681/2500], Loss: 0.37799352407455444\n",
      "Epoch [2/3], Batch [682/2500], Loss: 0.09926727414131165\n",
      "Epoch [2/3], Batch [683/2500], Loss: 0.32000532746315\n",
      "Epoch [2/3], Batch [684/2500], Loss: 0.28619909286499023\n",
      "Epoch [2/3], Batch [685/2500], Loss: 0.41076165437698364\n",
      "Epoch [2/3], Batch [686/2500], Loss: 0.20953667163848877\n",
      "Epoch [2/3], Batch [687/2500], Loss: 0.2690490484237671\n",
      "Epoch [2/3], Batch [688/2500], Loss: 0.19410324096679688\n",
      "Epoch [2/3], Batch [689/2500], Loss: 0.22219054400920868\n",
      "Epoch [2/3], Batch [690/2500], Loss: 0.2628697454929352\n",
      "Epoch [2/3], Batch [691/2500], Loss: 0.546779453754425\n",
      "Epoch [2/3], Batch [692/2500], Loss: 0.3159617781639099\n",
      "Epoch [2/3], Batch [693/2500], Loss: 0.13857655227184296\n",
      "Epoch [2/3], Batch [694/2500], Loss: 0.46969136595726013\n",
      "Epoch [2/3], Batch [695/2500], Loss: 0.2856329679489136\n",
      "Epoch [2/3], Batch [696/2500], Loss: 0.1200808510184288\n",
      "Epoch [2/3], Batch [697/2500], Loss: 0.25252848863601685\n",
      "Epoch [2/3], Batch [698/2500], Loss: 0.2686697840690613\n",
      "Epoch [2/3], Batch [699/2500], Loss: 0.071941077709198\n",
      "Epoch [2/3], Batch [700/2500], Loss: 0.0846722200512886\n",
      "Epoch [2/3], Batch [701/2500], Loss: 0.129776269197464\n",
      "Epoch [2/3], Batch [702/2500], Loss: 0.680141031742096\n",
      "Epoch [2/3], Batch [703/2500], Loss: 0.12771067023277283\n",
      "Epoch [2/3], Batch [704/2500], Loss: 0.20890696346759796\n",
      "Epoch [2/3], Batch [705/2500], Loss: 0.23678891360759735\n",
      "Epoch [2/3], Batch [706/2500], Loss: 0.19270962476730347\n",
      "Epoch [2/3], Batch [707/2500], Loss: 0.1579737663269043\n",
      "Epoch [2/3], Batch [708/2500], Loss: 0.07475785911083221\n",
      "Epoch [2/3], Batch [709/2500], Loss: 0.39588281512260437\n",
      "Epoch [2/3], Batch [710/2500], Loss: 0.036165352910757065\n",
      "Epoch [2/3], Batch [711/2500], Loss: 0.1789667010307312\n",
      "Epoch [2/3], Batch [712/2500], Loss: 0.26261743903160095\n",
      "Epoch [2/3], Batch [713/2500], Loss: 0.27082860469818115\n",
      "Epoch [2/3], Batch [714/2500], Loss: 0.3679310381412506\n",
      "Epoch [2/3], Batch [715/2500], Loss: 0.3094944953918457\n",
      "Epoch [2/3], Batch [716/2500], Loss: 0.18034708499908447\n",
      "Epoch [2/3], Batch [717/2500], Loss: 0.26166319847106934\n",
      "Epoch [2/3], Batch [718/2500], Loss: 0.14268112182617188\n",
      "Epoch [2/3], Batch [719/2500], Loss: 0.07130175083875656\n",
      "Epoch [2/3], Batch [720/2500], Loss: 0.1297251284122467\n",
      "Epoch [2/3], Batch [721/2500], Loss: 0.21621714532375336\n",
      "Epoch [2/3], Batch [722/2500], Loss: 0.19592203199863434\n",
      "Epoch [2/3], Batch [723/2500], Loss: 0.24461615085601807\n",
      "Epoch [2/3], Batch [724/2500], Loss: 0.21759498119354248\n",
      "Epoch [2/3], Batch [725/2500], Loss: 0.16839177906513214\n",
      "Epoch [2/3], Batch [726/2500], Loss: 0.14867709577083588\n",
      "Epoch [2/3], Batch [727/2500], Loss: 0.10074589401483536\n",
      "Epoch [2/3], Batch [728/2500], Loss: 0.11697883158922195\n",
      "Epoch [2/3], Batch [729/2500], Loss: 0.06163759529590607\n",
      "Epoch [2/3], Batch [730/2500], Loss: 0.06520340591669083\n",
      "Epoch [2/3], Batch [731/2500], Loss: 0.21482132375240326\n",
      "Epoch [2/3], Batch [732/2500], Loss: 0.05812196806073189\n",
      "Epoch [2/3], Batch [733/2500], Loss: 0.2126033455133438\n",
      "Epoch [2/3], Batch [734/2500], Loss: 0.1608884632587433\n",
      "Epoch [2/3], Batch [735/2500], Loss: 0.04939243942499161\n",
      "Epoch [2/3], Batch [736/2500], Loss: 0.16481924057006836\n",
      "Epoch [2/3], Batch [737/2500], Loss: 0.2703574597835541\n",
      "Epoch [2/3], Batch [738/2500], Loss: 0.11047138273715973\n",
      "Epoch [2/3], Batch [739/2500], Loss: 0.04027692973613739\n",
      "Epoch [2/3], Batch [740/2500], Loss: 0.09746121615171432\n",
      "Epoch [2/3], Batch [741/2500], Loss: 0.24414025247097015\n",
      "Epoch [2/3], Batch [742/2500], Loss: 0.08026693016290665\n",
      "Epoch [2/3], Batch [743/2500], Loss: 0.6312731504440308\n",
      "Epoch [2/3], Batch [744/2500], Loss: 0.2003660798072815\n",
      "Epoch [2/3], Batch [745/2500], Loss: 0.06620966643095016\n",
      "Epoch [2/3], Batch [746/2500], Loss: 0.03782359138131142\n",
      "Epoch [2/3], Batch [747/2500], Loss: 0.15039022266864777\n",
      "Epoch [2/3], Batch [748/2500], Loss: 0.24633924663066864\n",
      "Epoch [2/3], Batch [749/2500], Loss: 0.017849143594503403\n",
      "Epoch [2/3], Batch [750/2500], Loss: 0.25696200132369995\n",
      "Epoch [2/3], Batch [751/2500], Loss: 0.07447401434183121\n",
      "Epoch [2/3], Batch [752/2500], Loss: 0.1509695202112198\n",
      "Epoch [2/3], Batch [753/2500], Loss: 0.04760298877954483\n",
      "Epoch [2/3], Batch [754/2500], Loss: 0.07308580726385117\n",
      "Epoch [2/3], Batch [755/2500], Loss: 0.1336449682712555\n",
      "Epoch [2/3], Batch [756/2500], Loss: 0.5497480630874634\n",
      "Epoch [2/3], Batch [757/2500], Loss: 0.16257068514823914\n",
      "Epoch [2/3], Batch [758/2500], Loss: 0.017181679606437683\n",
      "Epoch [2/3], Batch [759/2500], Loss: 0.07258926331996918\n",
      "Epoch [2/3], Batch [760/2500], Loss: 0.2088087499141693\n",
      "Epoch [2/3], Batch [761/2500], Loss: 0.1770387440919876\n",
      "Epoch [2/3], Batch [762/2500], Loss: 0.1418657749891281\n",
      "Epoch [2/3], Batch [763/2500], Loss: 0.295612096786499\n",
      "Epoch [2/3], Batch [764/2500], Loss: 0.03368836268782616\n",
      "Epoch [2/3], Batch [765/2500], Loss: 0.043329909443855286\n",
      "Epoch [2/3], Batch [766/2500], Loss: 0.07234687358140945\n",
      "Epoch [2/3], Batch [767/2500], Loss: 0.2653791308403015\n",
      "Epoch [2/3], Batch [768/2500], Loss: 0.28724369406700134\n",
      "Epoch [2/3], Batch [769/2500], Loss: 0.15409868955612183\n",
      "Epoch [2/3], Batch [770/2500], Loss: 0.3181925415992737\n",
      "Epoch [2/3], Batch [771/2500], Loss: 0.04623725265264511\n",
      "Epoch [2/3], Batch [772/2500], Loss: 0.06655104458332062\n",
      "Epoch [2/3], Batch [773/2500], Loss: 0.08951602131128311\n",
      "Epoch [2/3], Batch [774/2500], Loss: 0.4983813762664795\n",
      "Epoch [2/3], Batch [775/2500], Loss: 0.18907591700553894\n",
      "Epoch [2/3], Batch [776/2500], Loss: 0.04210607707500458\n",
      "Epoch [2/3], Batch [777/2500], Loss: 0.2166256308555603\n",
      "Epoch [2/3], Batch [778/2500], Loss: 0.054659947752952576\n",
      "Epoch [2/3], Batch [779/2500], Loss: 0.20853465795516968\n",
      "Epoch [2/3], Batch [780/2500], Loss: 0.10316231101751328\n",
      "Epoch [2/3], Batch [781/2500], Loss: 0.064136803150177\n",
      "Epoch [2/3], Batch [782/2500], Loss: 0.4032147228717804\n",
      "Epoch [2/3], Batch [783/2500], Loss: 0.08007853478193283\n",
      "Epoch [2/3], Batch [784/2500], Loss: 0.19646474719047546\n",
      "Epoch [2/3], Batch [785/2500], Loss: 0.25983408093452454\n",
      "Epoch [2/3], Batch [786/2500], Loss: 0.2041059285402298\n",
      "Epoch [2/3], Batch [787/2500], Loss: 0.1373969167470932\n",
      "Epoch [2/3], Batch [788/2500], Loss: 0.07759948819875717\n",
      "Epoch [2/3], Batch [789/2500], Loss: 0.08378776162862778\n",
      "Epoch [2/3], Batch [790/2500], Loss: 0.47236719727516174\n",
      "Epoch [2/3], Batch [791/2500], Loss: 0.31866392493247986\n",
      "Epoch [2/3], Batch [792/2500], Loss: 0.2530795633792877\n",
      "Epoch [2/3], Batch [793/2500], Loss: 0.36688801646232605\n",
      "Epoch [2/3], Batch [794/2500], Loss: 0.18006347119808197\n",
      "Epoch [2/3], Batch [795/2500], Loss: 0.5130952000617981\n",
      "Epoch [2/3], Batch [796/2500], Loss: 0.01965140923857689\n",
      "Epoch [2/3], Batch [797/2500], Loss: 0.42745521664619446\n",
      "Epoch [2/3], Batch [798/2500], Loss: 0.06798510253429413\n",
      "Epoch [2/3], Batch [799/2500], Loss: 0.27956825494766235\n",
      "Epoch [2/3], Batch [800/2500], Loss: 0.10621222108602524\n",
      "Epoch [2/3], Batch [801/2500], Loss: 0.13347682356834412\n",
      "Epoch [2/3], Batch [802/2500], Loss: 0.48165425658226013\n",
      "Epoch [2/3], Batch [803/2500], Loss: 0.34928232431411743\n",
      "Epoch [2/3], Batch [804/2500], Loss: 0.22806602716445923\n",
      "Epoch [2/3], Batch [805/2500], Loss: 0.38928884267807007\n",
      "Epoch [2/3], Batch [806/2500], Loss: 0.21601685881614685\n",
      "Epoch [2/3], Batch [807/2500], Loss: 0.08484745770692825\n",
      "Epoch [2/3], Batch [808/2500], Loss: 0.062488019466400146\n",
      "Epoch [2/3], Batch [809/2500], Loss: 0.342339426279068\n",
      "Epoch [2/3], Batch [810/2500], Loss: 0.26673296093940735\n",
      "Epoch [2/3], Batch [811/2500], Loss: 0.4752156734466553\n",
      "Epoch [2/3], Batch [812/2500], Loss: 0.38961225748062134\n",
      "Epoch [2/3], Batch [813/2500], Loss: 0.237190842628479\n",
      "Epoch [2/3], Batch [814/2500], Loss: 0.22663156688213348\n",
      "Epoch [2/3], Batch [815/2500], Loss: 0.08031291514635086\n",
      "Epoch [2/3], Batch [816/2500], Loss: 0.08760020136833191\n",
      "Epoch [2/3], Batch [817/2500], Loss: 0.09701834619045258\n",
      "Epoch [2/3], Batch [818/2500], Loss: 0.07857368886470795\n",
      "Epoch [2/3], Batch [819/2500], Loss: 0.1640239953994751\n",
      "Epoch [2/3], Batch [820/2500], Loss: 0.21851646900177002\n",
      "Epoch [2/3], Batch [821/2500], Loss: 0.30080053210258484\n",
      "Epoch [2/3], Batch [822/2500], Loss: 0.10899141430854797\n",
      "Epoch [2/3], Batch [823/2500], Loss: 0.42084941267967224\n",
      "Epoch [2/3], Batch [824/2500], Loss: 0.12148231267929077\n",
      "Epoch [2/3], Batch [825/2500], Loss: 0.06398850679397583\n",
      "Epoch [2/3], Batch [826/2500], Loss: 0.07945595681667328\n",
      "Epoch [2/3], Batch [827/2500], Loss: 0.12339464575052261\n",
      "Epoch [2/3], Batch [828/2500], Loss: 0.22732192277908325\n",
      "Epoch [2/3], Batch [829/2500], Loss: 0.23244145512580872\n",
      "Epoch [2/3], Batch [830/2500], Loss: 0.20452868938446045\n",
      "Epoch [2/3], Batch [831/2500], Loss: 0.14837683737277985\n",
      "Epoch [2/3], Batch [832/2500], Loss: 0.13939201831817627\n",
      "Epoch [2/3], Batch [833/2500], Loss: 0.2388552874326706\n",
      "Epoch [2/3], Batch [834/2500], Loss: 0.2662033140659332\n",
      "Epoch [2/3], Batch [835/2500], Loss: 0.18140871822834015\n",
      "Epoch [2/3], Batch [836/2500], Loss: 0.11254420131444931\n",
      "Epoch [2/3], Batch [837/2500], Loss: 0.2526777386665344\n",
      "Epoch [2/3], Batch [838/2500], Loss: 0.14609239995479584\n",
      "Epoch [2/3], Batch [839/2500], Loss: 0.6147958636283875\n",
      "Epoch [2/3], Batch [840/2500], Loss: 0.04894840344786644\n",
      "Epoch [2/3], Batch [841/2500], Loss: 0.16650699079036713\n",
      "Epoch [2/3], Batch [842/2500], Loss: 0.15324519574642181\n",
      "Epoch [2/3], Batch [843/2500], Loss: 0.2558716833591461\n",
      "Epoch [2/3], Batch [844/2500], Loss: 0.11992019414901733\n",
      "Epoch [2/3], Batch [845/2500], Loss: 0.28367674350738525\n",
      "Epoch [2/3], Batch [846/2500], Loss: 0.05602826178073883\n",
      "Epoch [2/3], Batch [847/2500], Loss: 0.33598485589027405\n",
      "Epoch [2/3], Batch [848/2500], Loss: 0.25658825039863586\n",
      "Epoch [2/3], Batch [849/2500], Loss: 0.11165143549442291\n",
      "Epoch [2/3], Batch [850/2500], Loss: 0.16489630937576294\n",
      "Epoch [2/3], Batch [851/2500], Loss: 0.15460672974586487\n",
      "Epoch [2/3], Batch [852/2500], Loss: 0.26850876212120056\n",
      "Epoch [2/3], Batch [853/2500], Loss: 0.27692711353302\n",
      "Epoch [2/3], Batch [854/2500], Loss: 0.23343421518802643\n",
      "Epoch [2/3], Batch [855/2500], Loss: 0.1479494422674179\n",
      "Epoch [2/3], Batch [856/2500], Loss: 0.11569372564554214\n",
      "Epoch [2/3], Batch [857/2500], Loss: 0.17586617171764374\n",
      "Epoch [2/3], Batch [858/2500], Loss: 0.0615115649998188\n",
      "Epoch [2/3], Batch [859/2500], Loss: 0.23310643434524536\n",
      "Epoch [2/3], Batch [860/2500], Loss: 0.11681932210922241\n",
      "Epoch [2/3], Batch [861/2500], Loss: 0.20865881443023682\n",
      "Epoch [2/3], Batch [862/2500], Loss: 0.21488556265830994\n",
      "Epoch [2/3], Batch [863/2500], Loss: 0.2610298991203308\n",
      "Epoch [2/3], Batch [864/2500], Loss: 0.06319928914308548\n",
      "Epoch [2/3], Batch [865/2500], Loss: 0.22272208333015442\n",
      "Epoch [2/3], Batch [866/2500], Loss: 0.09633903950452805\n",
      "Epoch [2/3], Batch [867/2500], Loss: 0.02098865620791912\n",
      "Epoch [2/3], Batch [868/2500], Loss: 0.1757952719926834\n",
      "Epoch [2/3], Batch [869/2500], Loss: 0.185524120926857\n",
      "Epoch [2/3], Batch [870/2500], Loss: 0.2585245668888092\n",
      "Epoch [2/3], Batch [871/2500], Loss: 0.022001711651682854\n",
      "Epoch [2/3], Batch [872/2500], Loss: 0.08154428750276566\n",
      "Epoch [2/3], Batch [873/2500], Loss: 0.14340321719646454\n",
      "Epoch [2/3], Batch [874/2500], Loss: 0.08271529525518417\n",
      "Epoch [2/3], Batch [875/2500], Loss: 0.13237538933753967\n",
      "Epoch [2/3], Batch [876/2500], Loss: 0.28874850273132324\n",
      "Epoch [2/3], Batch [877/2500], Loss: 0.21568739414215088\n",
      "Epoch [2/3], Batch [878/2500], Loss: 0.4820949137210846\n",
      "Epoch [2/3], Batch [879/2500], Loss: 0.16464705765247345\n",
      "Epoch [2/3], Batch [880/2500], Loss: 0.0788760632276535\n",
      "Epoch [2/3], Batch [881/2500], Loss: 0.0520794652402401\n",
      "Epoch [2/3], Batch [882/2500], Loss: 0.4591258764266968\n",
      "Epoch [2/3], Batch [883/2500], Loss: 0.22350279986858368\n",
      "Epoch [2/3], Batch [884/2500], Loss: 0.14853151142597198\n",
      "Epoch [2/3], Batch [885/2500], Loss: 0.13053449988365173\n",
      "Epoch [2/3], Batch [886/2500], Loss: 0.07182632386684418\n",
      "Epoch [2/3], Batch [887/2500], Loss: 0.0943458303809166\n",
      "Epoch [2/3], Batch [888/2500], Loss: 0.09063060581684113\n",
      "Epoch [2/3], Batch [889/2500], Loss: 0.08203587681055069\n",
      "Epoch [2/3], Batch [890/2500], Loss: 0.20191128551959991\n",
      "Epoch [2/3], Batch [891/2500], Loss: 0.22347156703472137\n",
      "Epoch [2/3], Batch [892/2500], Loss: 0.05102323368191719\n",
      "Epoch [2/3], Batch [893/2500], Loss: 0.282955527305603\n",
      "Epoch [2/3], Batch [894/2500], Loss: 0.06801183521747589\n",
      "Epoch [2/3], Batch [895/2500], Loss: 0.09014097601175308\n",
      "Epoch [2/3], Batch [896/2500], Loss: 0.13828244805335999\n",
      "Epoch [2/3], Batch [897/2500], Loss: 0.0548115149140358\n",
      "Epoch [2/3], Batch [898/2500], Loss: 0.3577420115470886\n",
      "Epoch [2/3], Batch [899/2500], Loss: 0.07670766860246658\n",
      "Epoch [2/3], Batch [900/2500], Loss: 0.07958726584911346\n",
      "Epoch [2/3], Batch [901/2500], Loss: 0.29574769735336304\n",
      "Epoch [2/3], Batch [902/2500], Loss: 0.1138642206788063\n",
      "Epoch [2/3], Batch [903/2500], Loss: 0.21338997781276703\n",
      "Epoch [2/3], Batch [904/2500], Loss: 0.2628631889820099\n",
      "Epoch [2/3], Batch [905/2500], Loss: 0.23642206192016602\n",
      "Epoch [2/3], Batch [906/2500], Loss: 0.20280195772647858\n",
      "Epoch [2/3], Batch [907/2500], Loss: 0.08118751645088196\n",
      "Epoch [2/3], Batch [908/2500], Loss: 0.1275200992822647\n",
      "Epoch [2/3], Batch [909/2500], Loss: 0.022534463554620743\n",
      "Epoch [2/3], Batch [910/2500], Loss: 0.08534994721412659\n",
      "Epoch [2/3], Batch [911/2500], Loss: 0.12705129384994507\n",
      "Epoch [2/3], Batch [912/2500], Loss: 0.05218528211116791\n",
      "Epoch [2/3], Batch [913/2500], Loss: 0.05622728541493416\n",
      "Epoch [2/3], Batch [914/2500], Loss: 0.19204817712306976\n",
      "Epoch [2/3], Batch [915/2500], Loss: 0.09172341227531433\n",
      "Epoch [2/3], Batch [916/2500], Loss: 0.015598269179463387\n",
      "Epoch [2/3], Batch [917/2500], Loss: 0.115964874625206\n",
      "Epoch [2/3], Batch [918/2500], Loss: 0.2504335343837738\n",
      "Epoch [2/3], Batch [919/2500], Loss: 0.03920804709196091\n",
      "Epoch [2/3], Batch [920/2500], Loss: 0.05034962669014931\n",
      "Epoch [2/3], Batch [921/2500], Loss: 0.06016920134425163\n",
      "Epoch [2/3], Batch [922/2500], Loss: 0.2898005247116089\n",
      "Epoch [2/3], Batch [923/2500], Loss: 0.08391772955656052\n",
      "Epoch [2/3], Batch [924/2500], Loss: 0.5172529816627502\n",
      "Epoch [2/3], Batch [925/2500], Loss: 0.013804063200950623\n",
      "Epoch [2/3], Batch [926/2500], Loss: 0.08109903335571289\n",
      "Epoch [2/3], Batch [927/2500], Loss: 0.11580610275268555\n",
      "Epoch [2/3], Batch [928/2500], Loss: 0.037011682987213135\n",
      "Epoch [2/3], Batch [929/2500], Loss: 0.06513860821723938\n",
      "Epoch [2/3], Batch [930/2500], Loss: 0.03370499610900879\n",
      "Epoch [2/3], Batch [931/2500], Loss: 0.226379856467247\n",
      "Epoch [2/3], Batch [932/2500], Loss: 0.05546579882502556\n",
      "Epoch [2/3], Batch [933/2500], Loss: 0.045971740037202835\n",
      "Epoch [2/3], Batch [934/2500], Loss: 0.0647282674908638\n",
      "Epoch [2/3], Batch [935/2500], Loss: 0.17719222605228424\n",
      "Epoch [2/3], Batch [936/2500], Loss: 0.056513696908950806\n",
      "Epoch [2/3], Batch [937/2500], Loss: 0.07567062228918076\n",
      "Epoch [2/3], Batch [938/2500], Loss: 0.05095453932881355\n",
      "Epoch [2/3], Batch [939/2500], Loss: 0.17490868270397186\n",
      "Epoch [2/3], Batch [940/2500], Loss: 0.35148492455482483\n",
      "Epoch [2/3], Batch [941/2500], Loss: 0.24799703061580658\n",
      "Epoch [2/3], Batch [942/2500], Loss: 0.06860435754060745\n",
      "Epoch [2/3], Batch [943/2500], Loss: 0.4328637421131134\n",
      "Epoch [2/3], Batch [944/2500], Loss: 0.3326551020145416\n",
      "Epoch [2/3], Batch [945/2500], Loss: 0.18760094046592712\n",
      "Epoch [2/3], Batch [946/2500], Loss: 0.5297291278839111\n",
      "Epoch [2/3], Batch [947/2500], Loss: 0.6869220733642578\n",
      "Epoch [2/3], Batch [948/2500], Loss: 0.02314859814941883\n",
      "Epoch [2/3], Batch [949/2500], Loss: 0.021924175322055817\n",
      "Epoch [2/3], Batch [950/2500], Loss: 0.27439987659454346\n",
      "Epoch [2/3], Batch [951/2500], Loss: 0.050674114376306534\n",
      "Epoch [2/3], Batch [952/2500], Loss: 0.03836028650403023\n",
      "Epoch [2/3], Batch [953/2500], Loss: 0.17566095292568207\n",
      "Epoch [2/3], Batch [954/2500], Loss: 0.31551629304885864\n",
      "Epoch [2/3], Batch [955/2500], Loss: 0.05429773032665253\n",
      "Epoch [2/3], Batch [956/2500], Loss: 0.22592924535274506\n",
      "Epoch [2/3], Batch [957/2500], Loss: 0.03324646130204201\n",
      "Epoch [2/3], Batch [958/2500], Loss: 0.4039539098739624\n",
      "Epoch [2/3], Batch [959/2500], Loss: 0.04477722942829132\n",
      "Epoch [2/3], Batch [960/2500], Loss: 0.16070391237735748\n",
      "Epoch [2/3], Batch [961/2500], Loss: 0.06897160410881042\n",
      "Epoch [2/3], Batch [962/2500], Loss: 0.1890915036201477\n",
      "Epoch [2/3], Batch [963/2500], Loss: 0.21668291091918945\n",
      "Epoch [2/3], Batch [964/2500], Loss: 0.2165820151567459\n",
      "Epoch [2/3], Batch [965/2500], Loss: 0.24973921477794647\n",
      "Epoch [2/3], Batch [966/2500], Loss: 0.2161220908164978\n",
      "Epoch [2/3], Batch [967/2500], Loss: 0.07758109271526337\n",
      "Epoch [2/3], Batch [968/2500], Loss: 0.029172208160161972\n",
      "Epoch [2/3], Batch [969/2500], Loss: 0.1299603432416916\n",
      "Epoch [2/3], Batch [970/2500], Loss: 0.10795701295137405\n",
      "Epoch [2/3], Batch [971/2500], Loss: 0.12917523086071014\n",
      "Epoch [2/3], Batch [972/2500], Loss: 0.0855809822678566\n",
      "Epoch [2/3], Batch [973/2500], Loss: 0.13754615187644958\n",
      "Epoch [2/3], Batch [974/2500], Loss: 0.08693189173936844\n",
      "Epoch [2/3], Batch [975/2500], Loss: 0.0674540176987648\n",
      "Epoch [2/3], Batch [976/2500], Loss: 0.07474002242088318\n",
      "Epoch [2/3], Batch [977/2500], Loss: 0.18692989647388458\n",
      "Epoch [2/3], Batch [978/2500], Loss: 0.04165259748697281\n",
      "Epoch [2/3], Batch [979/2500], Loss: 0.0749761164188385\n",
      "Epoch [2/3], Batch [980/2500], Loss: 0.12081090360879898\n",
      "Epoch [2/3], Batch [981/2500], Loss: 0.04496634751558304\n",
      "Epoch [2/3], Batch [982/2500], Loss: 0.04142754152417183\n",
      "Epoch [2/3], Batch [983/2500], Loss: 0.08496531844139099\n",
      "Epoch [2/3], Batch [984/2500], Loss: 0.08550316095352173\n",
      "Epoch [2/3], Batch [985/2500], Loss: 0.11727572232484818\n",
      "Epoch [2/3], Batch [986/2500], Loss: 0.11233418434858322\n",
      "Epoch [2/3], Batch [987/2500], Loss: 0.09786152839660645\n",
      "Epoch [2/3], Batch [988/2500], Loss: 0.27053382992744446\n",
      "Epoch [2/3], Batch [989/2500], Loss: 0.05692402273416519\n",
      "Epoch [2/3], Batch [990/2500], Loss: 0.05442620813846588\n",
      "Epoch [2/3], Batch [991/2500], Loss: 0.04083789139986038\n",
      "Epoch [2/3], Batch [992/2500], Loss: 0.1967836320400238\n",
      "Epoch [2/3], Batch [993/2500], Loss: 0.03977134823799133\n",
      "Epoch [2/3], Batch [994/2500], Loss: 0.049503177404403687\n",
      "Epoch [2/3], Batch [995/2500], Loss: 0.051714375615119934\n",
      "Epoch [2/3], Batch [996/2500], Loss: 0.042014218866825104\n",
      "Epoch [2/3], Batch [997/2500], Loss: 0.03152995556592941\n",
      "Epoch [2/3], Batch [998/2500], Loss: 0.24094583094120026\n",
      "Epoch [2/3], Batch [999/2500], Loss: 0.06428651511669159\n",
      "Epoch [2/3], Batch [1000/2500], Loss: 0.08988992124795914\n",
      "Epoch [2/3], Batch [1001/2500], Loss: 0.3273489475250244\n",
      "Epoch [2/3], Batch [1002/2500], Loss: 0.06329275667667389\n",
      "Epoch [2/3], Batch [1003/2500], Loss: 0.07141707092523575\n",
      "Epoch [2/3], Batch [1004/2500], Loss: 0.21897821128368378\n",
      "Epoch [2/3], Batch [1005/2500], Loss: 0.04375578463077545\n",
      "Epoch [2/3], Batch [1006/2500], Loss: 0.11681664735078812\n",
      "Epoch [2/3], Batch [1007/2500], Loss: 0.011353998444974422\n",
      "Epoch [2/3], Batch [1008/2500], Loss: 0.28635820746421814\n",
      "Epoch [2/3], Batch [1009/2500], Loss: 0.09452486038208008\n",
      "Epoch [2/3], Batch [1010/2500], Loss: 0.2707936763763428\n",
      "Epoch [2/3], Batch [1011/2500], Loss: 0.04036237671971321\n",
      "Epoch [2/3], Batch [1012/2500], Loss: 0.5096343755722046\n",
      "Epoch [2/3], Batch [1013/2500], Loss: 0.26294898986816406\n",
      "Epoch [2/3], Batch [1014/2500], Loss: 0.1840328872203827\n",
      "Epoch [2/3], Batch [1015/2500], Loss: 0.11722919344902039\n",
      "Epoch [2/3], Batch [1016/2500], Loss: 0.32233482599258423\n",
      "Epoch [2/3], Batch [1017/2500], Loss: 0.5150309801101685\n",
      "Epoch [2/3], Batch [1018/2500], Loss: 0.4651181101799011\n",
      "Epoch [2/3], Batch [1019/2500], Loss: 0.07933256030082703\n",
      "Epoch [2/3], Batch [1020/2500], Loss: 0.19217756390571594\n",
      "Epoch [2/3], Batch [1021/2500], Loss: 0.1682211309671402\n",
      "Epoch [2/3], Batch [1022/2500], Loss: 0.0481841005384922\n",
      "Epoch [2/3], Batch [1023/2500], Loss: 0.15825292468070984\n",
      "Epoch [2/3], Batch [1024/2500], Loss: 0.024126991629600525\n",
      "Epoch [2/3], Batch [1025/2500], Loss: 0.03031882643699646\n",
      "Epoch [2/3], Batch [1026/2500], Loss: 0.25263679027557373\n",
      "Epoch [2/3], Batch [1027/2500], Loss: 0.08892177790403366\n",
      "Epoch [2/3], Batch [1028/2500], Loss: 0.18363116681575775\n",
      "Epoch [2/3], Batch [1029/2500], Loss: 0.21775615215301514\n",
      "Epoch [2/3], Batch [1030/2500], Loss: 0.3904930353164673\n",
      "Epoch [2/3], Batch [1031/2500], Loss: 0.401309609413147\n",
      "Epoch [2/3], Batch [1032/2500], Loss: 0.12356720864772797\n",
      "Epoch [2/3], Batch [1033/2500], Loss: 0.4547913670539856\n",
      "Epoch [2/3], Batch [1034/2500], Loss: 0.11885085701942444\n",
      "Epoch [2/3], Batch [1035/2500], Loss: 0.33437591791152954\n",
      "Epoch [2/3], Batch [1036/2500], Loss: 0.2250262051820755\n",
      "Epoch [2/3], Batch [1037/2500], Loss: 0.16716958582401276\n",
      "Epoch [2/3], Batch [1038/2500], Loss: 0.03761768341064453\n",
      "Epoch [2/3], Batch [1039/2500], Loss: 0.2160302847623825\n",
      "Epoch [2/3], Batch [1040/2500], Loss: 0.06973687559366226\n",
      "Epoch [2/3], Batch [1041/2500], Loss: 0.41252800822257996\n",
      "Epoch [2/3], Batch [1042/2500], Loss: 0.18538109958171844\n",
      "Epoch [2/3], Batch [1043/2500], Loss: 0.23232458531856537\n",
      "Epoch [2/3], Batch [1044/2500], Loss: 0.07666114717721939\n",
      "Epoch [2/3], Batch [1045/2500], Loss: 0.056543733924627304\n",
      "Epoch [2/3], Batch [1046/2500], Loss: 0.15866543352603912\n",
      "Epoch [2/3], Batch [1047/2500], Loss: 0.26612529158592224\n",
      "Epoch [2/3], Batch [1048/2500], Loss: 0.3452562987804413\n",
      "Epoch [2/3], Batch [1049/2500], Loss: 0.11988440901041031\n",
      "Epoch [2/3], Batch [1050/2500], Loss: 0.10050356388092041\n",
      "Epoch [2/3], Batch [1051/2500], Loss: 0.054859694093465805\n",
      "Epoch [2/3], Batch [1052/2500], Loss: 0.07375095784664154\n",
      "Epoch [2/3], Batch [1053/2500], Loss: 0.12534941732883453\n",
      "Epoch [2/3], Batch [1054/2500], Loss: 0.13133464753627777\n",
      "Epoch [2/3], Batch [1055/2500], Loss: 0.029236529022455215\n",
      "Epoch [2/3], Batch [1056/2500], Loss: 0.07956212013959885\n",
      "Epoch [2/3], Batch [1057/2500], Loss: 0.020386453717947006\n",
      "Epoch [2/3], Batch [1058/2500], Loss: 0.05939462035894394\n",
      "Epoch [2/3], Batch [1059/2500], Loss: 0.14367316663265228\n",
      "Epoch [2/3], Batch [1060/2500], Loss: 0.025549914687871933\n",
      "Epoch [2/3], Batch [1061/2500], Loss: 0.11664766073226929\n",
      "Epoch [2/3], Batch [1062/2500], Loss: 0.20523133873939514\n",
      "Epoch [2/3], Batch [1063/2500], Loss: 0.06808783113956451\n",
      "Epoch [2/3], Batch [1064/2500], Loss: 0.1880028247833252\n",
      "Epoch [2/3], Batch [1065/2500], Loss: 0.29179203510284424\n",
      "Epoch [2/3], Batch [1066/2500], Loss: 0.10502222180366516\n",
      "Epoch [2/3], Batch [1067/2500], Loss: 0.06674458086490631\n",
      "Epoch [2/3], Batch [1068/2500], Loss: 0.2923983037471771\n",
      "Epoch [2/3], Batch [1069/2500], Loss: 0.20018205046653748\n",
      "Epoch [2/3], Batch [1070/2500], Loss: 0.12457691878080368\n",
      "Epoch [2/3], Batch [1071/2500], Loss: 0.11809613555669785\n",
      "Epoch [2/3], Batch [1072/2500], Loss: 0.3358246088027954\n",
      "Epoch [2/3], Batch [1073/2500], Loss: 0.02679136022925377\n",
      "Epoch [2/3], Batch [1074/2500], Loss: 0.15647993981838226\n",
      "Epoch [2/3], Batch [1075/2500], Loss: 0.06254228204488754\n",
      "Epoch [2/3], Batch [1076/2500], Loss: 0.040626537054777145\n",
      "Epoch [2/3], Batch [1077/2500], Loss: 0.23014748096466064\n",
      "Epoch [2/3], Batch [1078/2500], Loss: 0.17219024896621704\n",
      "Epoch [2/3], Batch [1079/2500], Loss: 0.038202352821826935\n",
      "Epoch [2/3], Batch [1080/2500], Loss: 0.14600808918476105\n",
      "Epoch [2/3], Batch [1081/2500], Loss: 0.22870932519435883\n",
      "Epoch [2/3], Batch [1082/2500], Loss: 0.0838063657283783\n",
      "Epoch [2/3], Batch [1083/2500], Loss: 0.13283519446849823\n",
      "Epoch [2/3], Batch [1084/2500], Loss: 0.05130234360694885\n",
      "Epoch [2/3], Batch [1085/2500], Loss: 0.030771635472774506\n",
      "Epoch [2/3], Batch [1086/2500], Loss: 0.30806270241737366\n",
      "Epoch [2/3], Batch [1087/2500], Loss: 0.13740073144435883\n",
      "Epoch [2/3], Batch [1088/2500], Loss: 0.05074148252606392\n",
      "Epoch [2/3], Batch [1089/2500], Loss: 0.24677759408950806\n",
      "Epoch [2/3], Batch [1090/2500], Loss: 0.3880877196788788\n",
      "Epoch [2/3], Batch [1091/2500], Loss: 0.014944418333470821\n",
      "Epoch [2/3], Batch [1092/2500], Loss: 0.0330335907638073\n",
      "Epoch [2/3], Batch [1093/2500], Loss: 0.13199426233768463\n",
      "Epoch [2/3], Batch [1094/2500], Loss: 0.17105405032634735\n",
      "Epoch [2/3], Batch [1095/2500], Loss: 0.18606002628803253\n",
      "Epoch [2/3], Batch [1096/2500], Loss: 0.1482711136341095\n",
      "Epoch [2/3], Batch [1097/2500], Loss: 0.3236474394798279\n",
      "Epoch [2/3], Batch [1098/2500], Loss: 0.06207584589719772\n",
      "Epoch [2/3], Batch [1099/2500], Loss: 0.14877882599830627\n",
      "Epoch [2/3], Batch [1100/2500], Loss: 0.056869324296712875\n",
      "Epoch [2/3], Batch [1101/2500], Loss: 0.08886316418647766\n",
      "Epoch [2/3], Batch [1102/2500], Loss: 0.2627134919166565\n",
      "Epoch [2/3], Batch [1103/2500], Loss: 0.10610942542552948\n",
      "Epoch [2/3], Batch [1104/2500], Loss: 0.039388108998537064\n",
      "Epoch [2/3], Batch [1105/2500], Loss: 0.01609618403017521\n",
      "Epoch [2/3], Batch [1106/2500], Loss: 0.15213759243488312\n",
      "Epoch [2/3], Batch [1107/2500], Loss: 0.049119606614112854\n",
      "Epoch [2/3], Batch [1108/2500], Loss: 0.015742411836981773\n",
      "Epoch [2/3], Batch [1109/2500], Loss: 0.0647098645567894\n",
      "Epoch [2/3], Batch [1110/2500], Loss: 0.024852711707353592\n",
      "Epoch [2/3], Batch [1111/2500], Loss: 0.05617757886648178\n",
      "Epoch [2/3], Batch [1112/2500], Loss: 0.602871835231781\n",
      "Epoch [2/3], Batch [1113/2500], Loss: 0.037297848612070084\n",
      "Epoch [2/3], Batch [1114/2500], Loss: 0.28264230489730835\n",
      "Epoch [2/3], Batch [1115/2500], Loss: 0.43624347448349\n",
      "Epoch [2/3], Batch [1116/2500], Loss: 0.2803342938423157\n",
      "Epoch [2/3], Batch [1117/2500], Loss: 0.06633487343788147\n",
      "Epoch [2/3], Batch [1118/2500], Loss: 0.2322470098733902\n",
      "Epoch [2/3], Batch [1119/2500], Loss: 0.16397130489349365\n",
      "Epoch [2/3], Batch [1120/2500], Loss: 0.24093228578567505\n",
      "Epoch [2/3], Batch [1121/2500], Loss: 0.07488221675157547\n",
      "Epoch [2/3], Batch [1122/2500], Loss: 0.055959101766347885\n",
      "Epoch [2/3], Batch [1123/2500], Loss: 0.5046778917312622\n",
      "Epoch [2/3], Batch [1124/2500], Loss: 0.5113726854324341\n",
      "Epoch [2/3], Batch [1125/2500], Loss: 0.1485622674226761\n",
      "Epoch [2/3], Batch [1126/2500], Loss: 0.05573480576276779\n",
      "Epoch [2/3], Batch [1127/2500], Loss: 0.12027700245380402\n",
      "Epoch [2/3], Batch [1128/2500], Loss: 0.5296685695648193\n",
      "Epoch [2/3], Batch [1129/2500], Loss: 0.04548201709985733\n",
      "Epoch [2/3], Batch [1130/2500], Loss: 0.2278432846069336\n",
      "Epoch [2/3], Batch [1131/2500], Loss: 0.1954030692577362\n",
      "Epoch [2/3], Batch [1132/2500], Loss: 0.1282038688659668\n",
      "Epoch [2/3], Batch [1133/2500], Loss: 0.12861268222332\n",
      "Epoch [2/3], Batch [1134/2500], Loss: 0.16696982085704803\n",
      "Epoch [2/3], Batch [1135/2500], Loss: 0.06895838677883148\n",
      "Epoch [2/3], Batch [1136/2500], Loss: 0.32544970512390137\n",
      "Epoch [2/3], Batch [1137/2500], Loss: 0.7166244387626648\n",
      "Epoch [2/3], Batch [1138/2500], Loss: 0.2719714641571045\n",
      "Epoch [2/3], Batch [1139/2500], Loss: 0.15000838041305542\n",
      "Epoch [2/3], Batch [1140/2500], Loss: 0.08945506811141968\n",
      "Epoch [2/3], Batch [1141/2500], Loss: 0.08639252185821533\n",
      "Epoch [2/3], Batch [1142/2500], Loss: 0.07512140274047852\n",
      "Epoch [2/3], Batch [1143/2500], Loss: 0.07244633138179779\n",
      "Epoch [2/3], Batch [1144/2500], Loss: 0.09325135499238968\n",
      "Epoch [2/3], Batch [1145/2500], Loss: 0.21130062639713287\n",
      "Epoch [2/3], Batch [1146/2500], Loss: 0.022538375109434128\n",
      "Epoch [2/3], Batch [1147/2500], Loss: 0.09380315244197845\n",
      "Epoch [2/3], Batch [1148/2500], Loss: 0.01319518405944109\n",
      "Epoch [2/3], Batch [1149/2500], Loss: 0.2166069746017456\n",
      "Epoch [2/3], Batch [1150/2500], Loss: 0.22236387431621552\n",
      "Epoch [2/3], Batch [1151/2500], Loss: 0.17182454466819763\n",
      "Epoch [2/3], Batch [1152/2500], Loss: 0.09439802914857864\n",
      "Epoch [2/3], Batch [1153/2500], Loss: 0.29091519117355347\n",
      "Epoch [2/3], Batch [1154/2500], Loss: 0.6576895713806152\n",
      "Epoch [2/3], Batch [1155/2500], Loss: 0.09526755660772324\n",
      "Epoch [2/3], Batch [1156/2500], Loss: 0.8479392528533936\n",
      "Epoch [2/3], Batch [1157/2500], Loss: 0.22522936761379242\n",
      "Epoch [2/3], Batch [1158/2500], Loss: 0.14575961232185364\n",
      "Epoch [2/3], Batch [1159/2500], Loss: 0.0503542385995388\n",
      "Epoch [2/3], Batch [1160/2500], Loss: 0.23896107077598572\n",
      "Epoch [2/3], Batch [1161/2500], Loss: 0.0404481440782547\n",
      "Epoch [2/3], Batch [1162/2500], Loss: 0.22053079307079315\n",
      "Epoch [2/3], Batch [1163/2500], Loss: 0.16762754321098328\n",
      "Epoch [2/3], Batch [1164/2500], Loss: 0.13574013113975525\n",
      "Epoch [2/3], Batch [1165/2500], Loss: 0.1716068536043167\n",
      "Epoch [2/3], Batch [1166/2500], Loss: 0.328542023897171\n",
      "Epoch [2/3], Batch [1167/2500], Loss: 0.02922651171684265\n",
      "Epoch [2/3], Batch [1168/2500], Loss: 0.16195745766162872\n",
      "Epoch [2/3], Batch [1169/2500], Loss: 0.18331530690193176\n",
      "Epoch [2/3], Batch [1170/2500], Loss: 0.1492774486541748\n",
      "Epoch [2/3], Batch [1171/2500], Loss: 0.22187529504299164\n",
      "Epoch [2/3], Batch [1172/2500], Loss: 0.04420904070138931\n",
      "Epoch [2/3], Batch [1173/2500], Loss: 0.33729836344718933\n",
      "Epoch [2/3], Batch [1174/2500], Loss: 0.12884126603603363\n",
      "Epoch [2/3], Batch [1175/2500], Loss: 0.15766750276088715\n",
      "Epoch [2/3], Batch [1176/2500], Loss: 0.2341804951429367\n",
      "Epoch [2/3], Batch [1177/2500], Loss: 0.3237849175930023\n",
      "Epoch [2/3], Batch [1178/2500], Loss: 0.3044600188732147\n",
      "Epoch [2/3], Batch [1179/2500], Loss: 0.23241646587848663\n",
      "Epoch [2/3], Batch [1180/2500], Loss: 0.10004774481058121\n",
      "Epoch [2/3], Batch [1181/2500], Loss: 0.4402795135974884\n",
      "Epoch [2/3], Batch [1182/2500], Loss: 0.10258863121271133\n",
      "Epoch [2/3], Batch [1183/2500], Loss: 0.13187028467655182\n",
      "Epoch [2/3], Batch [1184/2500], Loss: 0.1885565221309662\n",
      "Epoch [2/3], Batch [1185/2500], Loss: 0.09321045875549316\n",
      "Epoch [2/3], Batch [1186/2500], Loss: 0.20000457763671875\n",
      "Epoch [2/3], Batch [1187/2500], Loss: 0.08390738070011139\n",
      "Epoch [2/3], Batch [1188/2500], Loss: 0.22160810232162476\n",
      "Epoch [2/3], Batch [1189/2500], Loss: 0.09315843880176544\n",
      "Epoch [2/3], Batch [1190/2500], Loss: 0.13784123957157135\n",
      "Epoch [2/3], Batch [1191/2500], Loss: 0.2724568247795105\n",
      "Epoch [2/3], Batch [1192/2500], Loss: 0.21122007071971893\n",
      "Epoch [2/3], Batch [1193/2500], Loss: 0.16034460067749023\n",
      "Epoch [2/3], Batch [1194/2500], Loss: 0.25060078501701355\n",
      "Epoch [2/3], Batch [1195/2500], Loss: 0.14798273146152496\n",
      "Epoch [2/3], Batch [1196/2500], Loss: 0.1842615306377411\n",
      "Epoch [2/3], Batch [1197/2500], Loss: 0.17015749216079712\n",
      "Epoch [2/3], Batch [1198/2500], Loss: 0.25345706939697266\n",
      "Epoch [2/3], Batch [1199/2500], Loss: 0.12806788086891174\n",
      "Epoch [2/3], Batch [1200/2500], Loss: 0.1293521672487259\n",
      "Epoch [2/3], Batch [1201/2500], Loss: 0.07207071036100388\n",
      "Epoch [2/3], Batch [1202/2500], Loss: 0.1523868292570114\n",
      "Epoch [2/3], Batch [1203/2500], Loss: 0.10335157811641693\n",
      "Epoch [2/3], Batch [1204/2500], Loss: 0.2563582956790924\n",
      "Epoch [2/3], Batch [1205/2500], Loss: 0.5092715620994568\n",
      "Epoch [2/3], Batch [1206/2500], Loss: 0.3087747097015381\n",
      "Epoch [2/3], Batch [1207/2500], Loss: 0.18060776591300964\n",
      "Epoch [2/3], Batch [1208/2500], Loss: 0.05315408483147621\n",
      "Epoch [2/3], Batch [1209/2500], Loss: 0.13407139480113983\n",
      "Epoch [2/3], Batch [1210/2500], Loss: 0.2137567698955536\n",
      "Epoch [2/3], Batch [1211/2500], Loss: 0.05430585518479347\n",
      "Epoch [2/3], Batch [1212/2500], Loss: 0.13700158894062042\n",
      "Epoch [2/3], Batch [1213/2500], Loss: 0.3110138475894928\n",
      "Epoch [2/3], Batch [1214/2500], Loss: 0.2006102353334427\n",
      "Epoch [2/3], Batch [1215/2500], Loss: 0.08768589794635773\n",
      "Epoch [2/3], Batch [1216/2500], Loss: 0.3369259536266327\n",
      "Epoch [2/3], Batch [1217/2500], Loss: 0.07368931174278259\n",
      "Epoch [2/3], Batch [1218/2500], Loss: 0.05398326367139816\n",
      "Epoch [2/3], Batch [1219/2500], Loss: 0.07853911817073822\n",
      "Epoch [2/3], Batch [1220/2500], Loss: 0.10552974045276642\n",
      "Epoch [2/3], Batch [1221/2500], Loss: 0.39730414748191833\n",
      "Epoch [2/3], Batch [1222/2500], Loss: 0.07042817026376724\n",
      "Epoch [2/3], Batch [1223/2500], Loss: 0.26530027389526367\n",
      "Epoch [2/3], Batch [1224/2500], Loss: 0.10480134189128876\n",
      "Epoch [2/3], Batch [1225/2500], Loss: 0.15981261432170868\n",
      "Epoch [2/3], Batch [1226/2500], Loss: 0.2617447078227997\n",
      "Epoch [2/3], Batch [1227/2500], Loss: 0.1483970284461975\n",
      "Epoch [2/3], Batch [1228/2500], Loss: 0.16173206269741058\n",
      "Epoch [2/3], Batch [1229/2500], Loss: 0.3128175139427185\n",
      "Epoch [2/3], Batch [1230/2500], Loss: 0.3346373438835144\n",
      "Epoch [2/3], Batch [1231/2500], Loss: 0.5086749196052551\n",
      "Epoch [2/3], Batch [1232/2500], Loss: 0.4109101891517639\n",
      "Epoch [2/3], Batch [1233/2500], Loss: 0.07130278646945953\n",
      "Epoch [2/3], Batch [1234/2500], Loss: 0.22382190823554993\n",
      "Epoch [2/3], Batch [1235/2500], Loss: 0.13216657936573029\n",
      "Epoch [2/3], Batch [1236/2500], Loss: 0.1033446192741394\n",
      "Epoch [2/3], Batch [1237/2500], Loss: 0.4942884147167206\n",
      "Epoch [2/3], Batch [1238/2500], Loss: 0.10456782579421997\n",
      "Epoch [2/3], Batch [1239/2500], Loss: 0.20923659205436707\n",
      "Epoch [2/3], Batch [1240/2500], Loss: 0.0733756422996521\n",
      "Epoch [2/3], Batch [1241/2500], Loss: 0.07442190498113632\n",
      "Epoch [2/3], Batch [1242/2500], Loss: 0.16345061361789703\n",
      "Epoch [2/3], Batch [1243/2500], Loss: 0.036364126950502396\n",
      "Epoch [2/3], Batch [1244/2500], Loss: 0.08860469609498978\n",
      "Epoch [2/3], Batch [1245/2500], Loss: 0.19627760350704193\n",
      "Epoch [2/3], Batch [1246/2500], Loss: 0.08092028647661209\n",
      "Epoch [2/3], Batch [1247/2500], Loss: 0.16915485262870789\n",
      "Epoch [2/3], Batch [1248/2500], Loss: 0.12288391590118408\n",
      "Epoch [2/3], Batch [1249/2500], Loss: 0.07645769417285919\n",
      "Epoch [2/3], Batch [1250/2500], Loss: 0.07487829774618149\n",
      "Epoch [2/3], Batch [1251/2500], Loss: 0.1294979602098465\n",
      "Epoch [2/3], Batch [1252/2500], Loss: 0.19383540749549866\n",
      "Epoch [2/3], Batch [1253/2500], Loss: 0.20825357735157013\n",
      "Epoch [2/3], Batch [1254/2500], Loss: 0.04927278682589531\n",
      "Epoch [2/3], Batch [1255/2500], Loss: 0.20841790735721588\n",
      "Epoch [2/3], Batch [1256/2500], Loss: 0.14758969843387604\n",
      "Epoch [2/3], Batch [1257/2500], Loss: 0.041418321430683136\n",
      "Epoch [2/3], Batch [1258/2500], Loss: 0.11449144035577774\n",
      "Epoch [2/3], Batch [1259/2500], Loss: 0.042967136949300766\n",
      "Epoch [2/3], Batch [1260/2500], Loss: 0.42583945393562317\n",
      "Epoch [2/3], Batch [1261/2500], Loss: 0.2811734974384308\n",
      "Epoch [2/3], Batch [1262/2500], Loss: 0.02178499475121498\n",
      "Epoch [2/3], Batch [1263/2500], Loss: 0.20600366592407227\n",
      "Epoch [2/3], Batch [1264/2500], Loss: 0.026126127690076828\n",
      "Epoch [2/3], Batch [1265/2500], Loss: 0.17675162851810455\n",
      "Epoch [2/3], Batch [1266/2500], Loss: 0.13689467310905457\n",
      "Epoch [2/3], Batch [1267/2500], Loss: 0.0469609834253788\n",
      "Epoch [2/3], Batch [1268/2500], Loss: 0.19301365315914154\n",
      "Epoch [2/3], Batch [1269/2500], Loss: 0.21150167286396027\n",
      "Epoch [2/3], Batch [1270/2500], Loss: 0.337986558675766\n",
      "Epoch [2/3], Batch [1271/2500], Loss: 0.12503688037395477\n",
      "Epoch [2/3], Batch [1272/2500], Loss: 0.35912543535232544\n",
      "Epoch [2/3], Batch [1273/2500], Loss: 0.14536680281162262\n",
      "Epoch [2/3], Batch [1274/2500], Loss: 0.0141672994941473\n",
      "Epoch [2/3], Batch [1275/2500], Loss: 0.145932137966156\n",
      "Epoch [2/3], Batch [1276/2500], Loss: 0.7030813694000244\n",
      "Epoch [2/3], Batch [1277/2500], Loss: 0.039652496576309204\n",
      "Epoch [2/3], Batch [1278/2500], Loss: 0.3839986324310303\n",
      "Epoch [2/3], Batch [1279/2500], Loss: 0.04990252107381821\n",
      "Epoch [2/3], Batch [1280/2500], Loss: 0.0692746564745903\n",
      "Epoch [2/3], Batch [1281/2500], Loss: 0.07533831149339676\n",
      "Epoch [2/3], Batch [1282/2500], Loss: 0.05008309334516525\n",
      "Epoch [2/3], Batch [1283/2500], Loss: 0.19556836783885956\n",
      "Epoch [2/3], Batch [1284/2500], Loss: 0.12221438437700272\n",
      "Epoch [2/3], Batch [1285/2500], Loss: 0.402634859085083\n",
      "Epoch [2/3], Batch [1286/2500], Loss: 0.10678243637084961\n",
      "Epoch [2/3], Batch [1287/2500], Loss: 0.06972295790910721\n",
      "Epoch [2/3], Batch [1288/2500], Loss: 0.18740466237068176\n",
      "Epoch [2/3], Batch [1289/2500], Loss: 0.13815101981163025\n",
      "Epoch [2/3], Batch [1290/2500], Loss: 0.21116158366203308\n",
      "Epoch [2/3], Batch [1291/2500], Loss: 0.29956117272377014\n",
      "Epoch [2/3], Batch [1292/2500], Loss: 0.05526156350970268\n",
      "Epoch [2/3], Batch [1293/2500], Loss: 0.2774467170238495\n",
      "Epoch [2/3], Batch [1294/2500], Loss: 0.056613773107528687\n",
      "Epoch [2/3], Batch [1295/2500], Loss: 0.49916955828666687\n",
      "Epoch [2/3], Batch [1296/2500], Loss: 0.10104212164878845\n",
      "Epoch [2/3], Batch [1297/2500], Loss: 0.6573708653450012\n",
      "Epoch [2/3], Batch [1298/2500], Loss: 0.043354347348213196\n",
      "Epoch [2/3], Batch [1299/2500], Loss: 0.08850829303264618\n",
      "Epoch [2/3], Batch [1300/2500], Loss: 0.05160330608487129\n",
      "Epoch [2/3], Batch [1301/2500], Loss: 0.597936749458313\n",
      "Epoch [2/3], Batch [1302/2500], Loss: 0.09193815290927887\n",
      "Epoch [2/3], Batch [1303/2500], Loss: 0.07474008202552795\n",
      "Epoch [2/3], Batch [1304/2500], Loss: 0.02762102521955967\n",
      "Epoch [2/3], Batch [1305/2500], Loss: 0.05541039630770683\n",
      "Epoch [2/3], Batch [1306/2500], Loss: 0.16299551725387573\n",
      "Epoch [2/3], Batch [1307/2500], Loss: 0.20361071825027466\n",
      "Epoch [2/3], Batch [1308/2500], Loss: 0.1277652382850647\n",
      "Epoch [2/3], Batch [1309/2500], Loss: 0.05041355639696121\n",
      "Epoch [2/3], Batch [1310/2500], Loss: 0.08416889607906342\n",
      "Epoch [2/3], Batch [1311/2500], Loss: 0.20581462979316711\n",
      "Epoch [2/3], Batch [1312/2500], Loss: 0.08523602783679962\n",
      "Epoch [2/3], Batch [1313/2500], Loss: 0.8278130888938904\n",
      "Epoch [2/3], Batch [1314/2500], Loss: 0.16042546927928925\n",
      "Epoch [2/3], Batch [1315/2500], Loss: 0.09985648095607758\n",
      "Epoch [2/3], Batch [1316/2500], Loss: 0.02044813521206379\n",
      "Epoch [2/3], Batch [1317/2500], Loss: 0.3653433322906494\n",
      "Epoch [2/3], Batch [1318/2500], Loss: 0.024112459272146225\n",
      "Epoch [2/3], Batch [1319/2500], Loss: 0.11265496164560318\n",
      "Epoch [2/3], Batch [1320/2500], Loss: 0.21610423922538757\n",
      "Epoch [2/3], Batch [1321/2500], Loss: 0.07952956855297089\n",
      "Epoch [2/3], Batch [1322/2500], Loss: 0.06909488141536713\n",
      "Epoch [2/3], Batch [1323/2500], Loss: 0.3930266499519348\n",
      "Epoch [2/3], Batch [1324/2500], Loss: 0.11606660485267639\n",
      "Epoch [2/3], Batch [1325/2500], Loss: 0.07960912585258484\n",
      "Epoch [2/3], Batch [1326/2500], Loss: 0.09442514181137085\n",
      "Epoch [2/3], Batch [1327/2500], Loss: 0.4538997411727905\n",
      "Epoch [2/3], Batch [1328/2500], Loss: 0.0835229903459549\n",
      "Epoch [2/3], Batch [1329/2500], Loss: 0.11940672248601913\n",
      "Epoch [2/3], Batch [1330/2500], Loss: 0.26910966634750366\n",
      "Epoch [2/3], Batch [1331/2500], Loss: 0.06040465459227562\n",
      "Epoch [2/3], Batch [1332/2500], Loss: 0.1689431071281433\n",
      "Epoch [2/3], Batch [1333/2500], Loss: 0.1451149433851242\n",
      "Epoch [2/3], Batch [1334/2500], Loss: 0.232386514544487\n",
      "Epoch [2/3], Batch [1335/2500], Loss: 0.028868447989225388\n",
      "Epoch [2/3], Batch [1336/2500], Loss: 0.27226686477661133\n",
      "Epoch [2/3], Batch [1337/2500], Loss: 0.3245979845523834\n",
      "Epoch [2/3], Batch [1338/2500], Loss: 0.03952055424451828\n",
      "Epoch [2/3], Batch [1339/2500], Loss: 0.33207911252975464\n",
      "Epoch [2/3], Batch [1340/2500], Loss: 0.36867383122444153\n",
      "Epoch [2/3], Batch [1341/2500], Loss: 0.04899714142084122\n",
      "Epoch [2/3], Batch [1342/2500], Loss: 0.04444490000605583\n",
      "Epoch [2/3], Batch [1343/2500], Loss: 0.06711821258068085\n",
      "Epoch [2/3], Batch [1344/2500], Loss: 0.4505457878112793\n",
      "Epoch [2/3], Batch [1345/2500], Loss: 0.3084273636341095\n",
      "Epoch [2/3], Batch [1346/2500], Loss: 0.19512099027633667\n",
      "Epoch [2/3], Batch [1347/2500], Loss: 0.07388681918382645\n",
      "Epoch [2/3], Batch [1348/2500], Loss: 0.1575966328382492\n",
      "Epoch [2/3], Batch [1349/2500], Loss: 0.14135316014289856\n",
      "Epoch [2/3], Batch [1350/2500], Loss: 0.0418538823723793\n",
      "Epoch [2/3], Batch [1351/2500], Loss: 0.018300391733646393\n",
      "Epoch [2/3], Batch [1352/2500], Loss: 0.06729152798652649\n",
      "Epoch [2/3], Batch [1353/2500], Loss: 0.3153606057167053\n",
      "Epoch [2/3], Batch [1354/2500], Loss: 0.15876653790473938\n",
      "Epoch [2/3], Batch [1355/2500], Loss: 0.624778151512146\n",
      "Epoch [2/3], Batch [1356/2500], Loss: 0.3184530436992645\n",
      "Epoch [2/3], Batch [1357/2500], Loss: 0.1104506179690361\n",
      "Epoch [2/3], Batch [1358/2500], Loss: 0.10636657476425171\n",
      "Epoch [2/3], Batch [1359/2500], Loss: 0.05666109547019005\n",
      "Epoch [2/3], Batch [1360/2500], Loss: 0.055723898112773895\n",
      "Epoch [2/3], Batch [1361/2500], Loss: 0.7382898330688477\n",
      "Epoch [2/3], Batch [1362/2500], Loss: 0.06195887550711632\n",
      "Epoch [2/3], Batch [1363/2500], Loss: 0.20598691701889038\n",
      "Epoch [2/3], Batch [1364/2500], Loss: 0.29282045364379883\n",
      "Epoch [2/3], Batch [1365/2500], Loss: 0.14172311127185822\n",
      "Epoch [2/3], Batch [1366/2500], Loss: 0.12600202858448029\n",
      "Epoch [2/3], Batch [1367/2500], Loss: 0.43832695484161377\n",
      "Epoch [2/3], Batch [1368/2500], Loss: 0.3580806255340576\n",
      "Epoch [2/3], Batch [1369/2500], Loss: 0.3101295828819275\n",
      "Epoch [2/3], Batch [1370/2500], Loss: 0.05558967962861061\n",
      "Epoch [2/3], Batch [1371/2500], Loss: 0.21796530485153198\n",
      "Epoch [2/3], Batch [1372/2500], Loss: 0.03303062543272972\n",
      "Epoch [2/3], Batch [1373/2500], Loss: 0.2589874863624573\n",
      "Epoch [2/3], Batch [1374/2500], Loss: 0.3137282729148865\n",
      "Epoch [2/3], Batch [1375/2500], Loss: 0.2956313192844391\n",
      "Epoch [2/3], Batch [1376/2500], Loss: 0.11793183535337448\n",
      "Epoch [2/3], Batch [1377/2500], Loss: 0.1953868269920349\n",
      "Epoch [2/3], Batch [1378/2500], Loss: 0.18868407607078552\n",
      "Epoch [2/3], Batch [1379/2500], Loss: 0.1299469769001007\n",
      "Epoch [2/3], Batch [1380/2500], Loss: 0.3745853900909424\n",
      "Epoch [2/3], Batch [1381/2500], Loss: 0.17381379008293152\n",
      "Epoch [2/3], Batch [1382/2500], Loss: 0.24191433191299438\n",
      "Epoch [2/3], Batch [1383/2500], Loss: 0.30993399024009705\n",
      "Epoch [2/3], Batch [1384/2500], Loss: 0.2003278136253357\n",
      "Epoch [2/3], Batch [1385/2500], Loss: 0.5068360567092896\n",
      "Epoch [2/3], Batch [1386/2500], Loss: 0.08564808964729309\n",
      "Epoch [2/3], Batch [1387/2500], Loss: 0.09341593831777573\n",
      "Epoch [2/3], Batch [1388/2500], Loss: 0.30721619725227356\n",
      "Epoch [2/3], Batch [1389/2500], Loss: 0.11498847603797913\n",
      "Epoch [2/3], Batch [1390/2500], Loss: 0.030994759872555733\n",
      "Epoch [2/3], Batch [1391/2500], Loss: 0.0851326733827591\n",
      "Epoch [2/3], Batch [1392/2500], Loss: 0.2183510810136795\n",
      "Epoch [2/3], Batch [1393/2500], Loss: 0.32881802320480347\n",
      "Epoch [2/3], Batch [1394/2500], Loss: 0.2398572713136673\n",
      "Epoch [2/3], Batch [1395/2500], Loss: 0.16811531782150269\n",
      "Epoch [2/3], Batch [1396/2500], Loss: 0.23704893887043\n",
      "Epoch [2/3], Batch [1397/2500], Loss: 0.1433502435684204\n",
      "Epoch [2/3], Batch [1398/2500], Loss: 0.20206424593925476\n",
      "Epoch [2/3], Batch [1399/2500], Loss: 0.13916659355163574\n",
      "Epoch [2/3], Batch [1400/2500], Loss: 0.11897704750299454\n",
      "Epoch [2/3], Batch [1401/2500], Loss: 0.36916324496269226\n",
      "Epoch [2/3], Batch [1402/2500], Loss: 0.09013082087039948\n",
      "Epoch [2/3], Batch [1403/2500], Loss: 0.21218998730182648\n",
      "Epoch [2/3], Batch [1404/2500], Loss: 0.14575296640396118\n",
      "Epoch [2/3], Batch [1405/2500], Loss: 0.2728680968284607\n",
      "Epoch [2/3], Batch [1406/2500], Loss: 0.10973084717988968\n",
      "Epoch [2/3], Batch [1407/2500], Loss: 0.37375035881996155\n",
      "Epoch [2/3], Batch [1408/2500], Loss: 0.3246852159500122\n",
      "Epoch [2/3], Batch [1409/2500], Loss: 0.6229078769683838\n",
      "Epoch [2/3], Batch [1410/2500], Loss: 0.3733125925064087\n",
      "Epoch [2/3], Batch [1411/2500], Loss: 0.20807313919067383\n",
      "Epoch [2/3], Batch [1412/2500], Loss: 0.06309611350297928\n",
      "Epoch [2/3], Batch [1413/2500], Loss: 0.022157132625579834\n",
      "Epoch [2/3], Batch [1414/2500], Loss: 0.41080689430236816\n",
      "Epoch [2/3], Batch [1415/2500], Loss: 0.18072348833084106\n",
      "Epoch [2/3], Batch [1416/2500], Loss: 0.2698400616645813\n",
      "Epoch [2/3], Batch [1417/2500], Loss: 0.1218976154923439\n",
      "Epoch [2/3], Batch [1418/2500], Loss: 0.2743879556655884\n",
      "Epoch [2/3], Batch [1419/2500], Loss: 0.21094049513339996\n",
      "Epoch [2/3], Batch [1420/2500], Loss: 0.39456960558891296\n",
      "Epoch [2/3], Batch [1421/2500], Loss: 0.05326687544584274\n",
      "Epoch [2/3], Batch [1422/2500], Loss: 0.17263220250606537\n",
      "Epoch [2/3], Batch [1423/2500], Loss: 0.15247300267219543\n",
      "Epoch [2/3], Batch [1424/2500], Loss: 0.6073722839355469\n",
      "Epoch [2/3], Batch [1425/2500], Loss: 0.10917150974273682\n",
      "Epoch [2/3], Batch [1426/2500], Loss: 0.0643550306558609\n",
      "Epoch [2/3], Batch [1427/2500], Loss: 0.08995632827281952\n",
      "Epoch [2/3], Batch [1428/2500], Loss: 0.10506169497966766\n",
      "Epoch [2/3], Batch [1429/2500], Loss: 0.5336032509803772\n",
      "Epoch [2/3], Batch [1430/2500], Loss: 0.1984609216451645\n",
      "Epoch [2/3], Batch [1431/2500], Loss: 0.12074130028486252\n",
      "Epoch [2/3], Batch [1432/2500], Loss: 0.10144538432359695\n",
      "Epoch [2/3], Batch [1433/2500], Loss: 0.02663654461503029\n",
      "Epoch [2/3], Batch [1434/2500], Loss: 0.048425011336803436\n",
      "Epoch [2/3], Batch [1435/2500], Loss: 0.22132053971290588\n",
      "Epoch [2/3], Batch [1436/2500], Loss: 0.48090147972106934\n",
      "Epoch [2/3], Batch [1437/2500], Loss: 0.059944771230220795\n",
      "Epoch [2/3], Batch [1438/2500], Loss: 0.24806463718414307\n",
      "Epoch [2/3], Batch [1439/2500], Loss: 0.10324607044458389\n",
      "Epoch [2/3], Batch [1440/2500], Loss: 0.05961588770151138\n",
      "Epoch [2/3], Batch [1441/2500], Loss: 0.1535952389240265\n",
      "Epoch [2/3], Batch [1442/2500], Loss: 0.10193496942520142\n",
      "Epoch [2/3], Batch [1443/2500], Loss: 0.2108706831932068\n",
      "Epoch [2/3], Batch [1444/2500], Loss: 0.1097080409526825\n",
      "Epoch [2/3], Batch [1445/2500], Loss: 0.1471123993396759\n",
      "Epoch [2/3], Batch [1446/2500], Loss: 0.23496891558170319\n",
      "Epoch [2/3], Batch [1447/2500], Loss: 0.12874437868595123\n",
      "Epoch [2/3], Batch [1448/2500], Loss: 0.15240538120269775\n",
      "Epoch [2/3], Batch [1449/2500], Loss: 0.36878877878189087\n",
      "Epoch [2/3], Batch [1450/2500], Loss: 0.35827624797821045\n",
      "Epoch [2/3], Batch [1451/2500], Loss: 0.35361379384994507\n",
      "Epoch [2/3], Batch [1452/2500], Loss: 0.07679300755262375\n",
      "Epoch [2/3], Batch [1453/2500], Loss: 0.21892118453979492\n",
      "Epoch [2/3], Batch [1454/2500], Loss: 0.3215544819831848\n",
      "Epoch [2/3], Batch [1455/2500], Loss: 0.22609174251556396\n",
      "Epoch [2/3], Batch [1456/2500], Loss: 0.31682348251342773\n",
      "Epoch [2/3], Batch [1457/2500], Loss: 0.34495994448661804\n",
      "Epoch [2/3], Batch [1458/2500], Loss: 0.071990966796875\n",
      "Epoch [2/3], Batch [1459/2500], Loss: 0.1305655539035797\n",
      "Epoch [2/3], Batch [1460/2500], Loss: 0.30741384625434875\n",
      "Epoch [2/3], Batch [1461/2500], Loss: 0.14345911145210266\n",
      "Epoch [2/3], Batch [1462/2500], Loss: 0.07403573393821716\n",
      "Epoch [2/3], Batch [1463/2500], Loss: 0.30125945806503296\n",
      "Epoch [2/3], Batch [1464/2500], Loss: 0.12239044904708862\n",
      "Epoch [2/3], Batch [1465/2500], Loss: 0.06821123510599136\n",
      "Epoch [2/3], Batch [1466/2500], Loss: 0.38980478048324585\n",
      "Epoch [2/3], Batch [1467/2500], Loss: 0.24640609323978424\n",
      "Epoch [2/3], Batch [1468/2500], Loss: 0.23528362810611725\n",
      "Epoch [2/3], Batch [1469/2500], Loss: 0.1596715897321701\n",
      "Epoch [2/3], Batch [1470/2500], Loss: 0.09672928601503372\n",
      "Epoch [2/3], Batch [1471/2500], Loss: 0.12128473818302155\n",
      "Epoch [2/3], Batch [1472/2500], Loss: 0.0704331323504448\n",
      "Epoch [2/3], Batch [1473/2500], Loss: 0.14735513925552368\n",
      "Epoch [2/3], Batch [1474/2500], Loss: 0.02143288403749466\n",
      "Epoch [2/3], Batch [1475/2500], Loss: 0.01593947969377041\n",
      "Epoch [2/3], Batch [1476/2500], Loss: 0.14261622726917267\n",
      "Epoch [2/3], Batch [1477/2500], Loss: 0.26707908511161804\n",
      "Epoch [2/3], Batch [1478/2500], Loss: 0.07753415405750275\n",
      "Epoch [2/3], Batch [1479/2500], Loss: 0.19307303428649902\n",
      "Epoch [2/3], Batch [1480/2500], Loss: 0.2887088656425476\n",
      "Epoch [2/3], Batch [1481/2500], Loss: 0.10080762207508087\n",
      "Epoch [2/3], Batch [1482/2500], Loss: 0.3341386318206787\n",
      "Epoch [2/3], Batch [1483/2500], Loss: 0.48936769366264343\n",
      "Epoch [2/3], Batch [1484/2500], Loss: 0.06995144486427307\n",
      "Epoch [2/3], Batch [1485/2500], Loss: 0.0895482525229454\n",
      "Epoch [2/3], Batch [1486/2500], Loss: 0.01702731102705002\n",
      "Epoch [2/3], Batch [1487/2500], Loss: 0.0179494246840477\n",
      "Epoch [2/3], Batch [1488/2500], Loss: 0.08078941702842712\n",
      "Epoch [2/3], Batch [1489/2500], Loss: 0.06976183503866196\n",
      "Epoch [2/3], Batch [1490/2500], Loss: 0.018042296171188354\n",
      "Epoch [2/3], Batch [1491/2500], Loss: 0.18445082008838654\n",
      "Epoch [2/3], Batch [1492/2500], Loss: 0.17407062649726868\n",
      "Epoch [2/3], Batch [1493/2500], Loss: 0.31848353147506714\n",
      "Epoch [2/3], Batch [1494/2500], Loss: 0.07636144757270813\n",
      "Epoch [2/3], Batch [1495/2500], Loss: 0.060961753129959106\n",
      "Epoch [2/3], Batch [1496/2500], Loss: 0.10563583672046661\n",
      "Epoch [2/3], Batch [1497/2500], Loss: 0.10483622550964355\n",
      "Epoch [2/3], Batch [1498/2500], Loss: 0.20172849297523499\n",
      "Epoch [2/3], Batch [1499/2500], Loss: 0.09523249417543411\n",
      "Epoch [2/3], Batch [1500/2500], Loss: 0.03964041545987129\n",
      "Epoch [2/3], Batch [1501/2500], Loss: 0.2353128045797348\n",
      "Epoch [2/3], Batch [1502/2500], Loss: 0.056249748915433884\n",
      "Epoch [2/3], Batch [1503/2500], Loss: 0.11158350855112076\n",
      "Epoch [2/3], Batch [1504/2500], Loss: 0.11659352481365204\n",
      "Epoch [2/3], Batch [1505/2500], Loss: 0.0194726400077343\n",
      "Epoch [2/3], Batch [1506/2500], Loss: 0.09990723431110382\n",
      "Epoch [2/3], Batch [1507/2500], Loss: 0.18315733969211578\n",
      "Epoch [2/3], Batch [1508/2500], Loss: 0.16365623474121094\n",
      "Epoch [2/3], Batch [1509/2500], Loss: 0.10169138759374619\n",
      "Epoch [2/3], Batch [1510/2500], Loss: 0.3335869610309601\n",
      "Epoch [2/3], Batch [1511/2500], Loss: 0.08883346617221832\n",
      "Epoch [2/3], Batch [1512/2500], Loss: 0.07499542087316513\n",
      "Epoch [2/3], Batch [1513/2500], Loss: 0.07085123658180237\n",
      "Epoch [2/3], Batch [1514/2500], Loss: 0.3473621606826782\n",
      "Epoch [2/3], Batch [1515/2500], Loss: 0.02432878129184246\n",
      "Epoch [2/3], Batch [1516/2500], Loss: 0.09444428980350494\n",
      "Epoch [2/3], Batch [1517/2500], Loss: 0.052801672369241714\n",
      "Epoch [2/3], Batch [1518/2500], Loss: 0.03705717623233795\n",
      "Epoch [2/3], Batch [1519/2500], Loss: 0.052034080028533936\n",
      "Epoch [2/3], Batch [1520/2500], Loss: 0.5329998731613159\n",
      "Epoch [2/3], Batch [1521/2500], Loss: 0.27900850772857666\n",
      "Epoch [2/3], Batch [1522/2500], Loss: 0.1426617056131363\n",
      "Epoch [2/3], Batch [1523/2500], Loss: 0.3759951889514923\n",
      "Epoch [2/3], Batch [1524/2500], Loss: 0.11323823779821396\n",
      "Epoch [2/3], Batch [1525/2500], Loss: 0.3781892955303192\n",
      "Epoch [2/3], Batch [1526/2500], Loss: 0.7785694599151611\n",
      "Epoch [2/3], Batch [1527/2500], Loss: 0.028783537447452545\n",
      "Epoch [2/3], Batch [1528/2500], Loss: 0.05611099302768707\n",
      "Epoch [2/3], Batch [1529/2500], Loss: 0.09334352612495422\n",
      "Epoch [2/3], Batch [1530/2500], Loss: 0.06996618211269379\n",
      "Epoch [2/3], Batch [1531/2500], Loss: 0.045720718801021576\n",
      "Epoch [2/3], Batch [1532/2500], Loss: 0.12474137544631958\n",
      "Epoch [2/3], Batch [1533/2500], Loss: 0.08289464563131332\n",
      "Epoch [2/3], Batch [1534/2500], Loss: 0.2918092608451843\n",
      "Epoch [2/3], Batch [1535/2500], Loss: 0.029999230057001114\n",
      "Epoch [2/3], Batch [1536/2500], Loss: 0.11120646446943283\n",
      "Epoch [2/3], Batch [1537/2500], Loss: 0.056434981524944305\n",
      "Epoch [2/3], Batch [1538/2500], Loss: 0.2597578465938568\n",
      "Epoch [2/3], Batch [1539/2500], Loss: 0.37388455867767334\n",
      "Epoch [2/3], Batch [1540/2500], Loss: 0.33895862102508545\n",
      "Epoch [2/3], Batch [1541/2500], Loss: 0.33971989154815674\n",
      "Epoch [2/3], Batch [1542/2500], Loss: 0.25229498744010925\n",
      "Epoch [2/3], Batch [1543/2500], Loss: 0.0588415153324604\n",
      "Epoch [2/3], Batch [1544/2500], Loss: 0.07891197502613068\n",
      "Epoch [2/3], Batch [1545/2500], Loss: 0.14669571816921234\n",
      "Epoch [2/3], Batch [1546/2500], Loss: 0.1644633710384369\n",
      "Epoch [2/3], Batch [1547/2500], Loss: 0.17026090621948242\n",
      "Epoch [2/3], Batch [1548/2500], Loss: 0.08334921300411224\n",
      "Epoch [2/3], Batch [1549/2500], Loss: 0.2292162925004959\n",
      "Epoch [2/3], Batch [1550/2500], Loss: 0.21472029387950897\n",
      "Epoch [2/3], Batch [1551/2500], Loss: 0.2089867889881134\n",
      "Epoch [2/3], Batch [1552/2500], Loss: 0.02993948385119438\n",
      "Epoch [2/3], Batch [1553/2500], Loss: 0.012033523060381413\n",
      "Epoch [2/3], Batch [1554/2500], Loss: 0.2623618245124817\n",
      "Epoch [2/3], Batch [1555/2500], Loss: 0.029018711298704147\n",
      "Epoch [2/3], Batch [1556/2500], Loss: 0.10058215260505676\n",
      "Epoch [2/3], Batch [1557/2500], Loss: 0.19279880821704865\n",
      "Epoch [2/3], Batch [1558/2500], Loss: 0.2847444713115692\n",
      "Epoch [2/3], Batch [1559/2500], Loss: 0.1132921651005745\n",
      "Epoch [2/3], Batch [1560/2500], Loss: 0.1020192801952362\n",
      "Epoch [2/3], Batch [1561/2500], Loss: 0.295126348733902\n",
      "Epoch [2/3], Batch [1562/2500], Loss: 0.18494030833244324\n",
      "Epoch [2/3], Batch [1563/2500], Loss: 0.16769620776176453\n",
      "Epoch [2/3], Batch [1564/2500], Loss: 0.0153737748041749\n",
      "Epoch [2/3], Batch [1565/2500], Loss: 0.21562734246253967\n",
      "Epoch [2/3], Batch [1566/2500], Loss: 0.3620133697986603\n",
      "Epoch [2/3], Batch [1567/2500], Loss: 0.19135059416294098\n",
      "Epoch [2/3], Batch [1568/2500], Loss: 0.2624213397502899\n",
      "Epoch [2/3], Batch [1569/2500], Loss: 0.14462962746620178\n",
      "Epoch [2/3], Batch [1570/2500], Loss: 0.32016679644584656\n",
      "Epoch [2/3], Batch [1571/2500], Loss: 0.0375886894762516\n",
      "Epoch [2/3], Batch [1572/2500], Loss: 0.08930609375238419\n",
      "Epoch [2/3], Batch [1573/2500], Loss: 0.16840258240699768\n",
      "Epoch [2/3], Batch [1574/2500], Loss: 0.10213978588581085\n",
      "Epoch [2/3], Batch [1575/2500], Loss: 0.14665929973125458\n",
      "Epoch [2/3], Batch [1576/2500], Loss: 0.20287100970745087\n",
      "Epoch [2/3], Batch [1577/2500], Loss: 0.032012149691581726\n",
      "Epoch [2/3], Batch [1578/2500], Loss: 0.28560593724250793\n",
      "Epoch [2/3], Batch [1579/2500], Loss: 0.13996517658233643\n",
      "Epoch [2/3], Batch [1580/2500], Loss: 0.07343239337205887\n",
      "Epoch [2/3], Batch [1581/2500], Loss: 0.1885175257921219\n",
      "Epoch [2/3], Batch [1582/2500], Loss: 0.05996539071202278\n",
      "Epoch [2/3], Batch [1583/2500], Loss: 0.11088506132364273\n",
      "Epoch [2/3], Batch [1584/2500], Loss: 0.13229262828826904\n",
      "Epoch [2/3], Batch [1585/2500], Loss: 0.06701480597257614\n",
      "Epoch [2/3], Batch [1586/2500], Loss: 0.5037922263145447\n",
      "Epoch [2/3], Batch [1587/2500], Loss: 0.222706139087677\n",
      "Epoch [2/3], Batch [1588/2500], Loss: 0.23583167791366577\n",
      "Epoch [2/3], Batch [1589/2500], Loss: 0.014009404927492142\n",
      "Epoch [2/3], Batch [1590/2500], Loss: 0.42129749059677124\n",
      "Epoch [2/3], Batch [1591/2500], Loss: 0.12093029171228409\n",
      "Epoch [2/3], Batch [1592/2500], Loss: 0.21740685403347015\n",
      "Epoch [2/3], Batch [1593/2500], Loss: 0.03534487634897232\n",
      "Epoch [2/3], Batch [1594/2500], Loss: 0.07727956026792526\n",
      "Epoch [2/3], Batch [1595/2500], Loss: 0.022316135466098785\n",
      "Epoch [2/3], Batch [1596/2500], Loss: 0.2608124613761902\n",
      "Epoch [2/3], Batch [1597/2500], Loss: 0.25967487692832947\n",
      "Epoch [2/3], Batch [1598/2500], Loss: 0.3107949495315552\n",
      "Epoch [2/3], Batch [1599/2500], Loss: 0.054882682859897614\n",
      "Epoch [2/3], Batch [1600/2500], Loss: 0.1851305067539215\n",
      "Epoch [2/3], Batch [1601/2500], Loss: 0.08830542117357254\n",
      "Epoch [2/3], Batch [1602/2500], Loss: 0.2577933967113495\n",
      "Epoch [2/3], Batch [1603/2500], Loss: 0.06837356090545654\n",
      "Epoch [2/3], Batch [1604/2500], Loss: 0.2891771197319031\n",
      "Epoch [2/3], Batch [1605/2500], Loss: 0.009778759442269802\n",
      "Epoch [2/3], Batch [1606/2500], Loss: 0.22126621007919312\n",
      "Epoch [2/3], Batch [1607/2500], Loss: 0.15395857393741608\n",
      "Epoch [2/3], Batch [1608/2500], Loss: 0.0835510715842247\n",
      "Epoch [2/3], Batch [1609/2500], Loss: 0.18185453116893768\n",
      "Epoch [2/3], Batch [1610/2500], Loss: 0.2522802948951721\n",
      "Epoch [2/3], Batch [1611/2500], Loss: 0.15532204508781433\n",
      "Epoch [2/3], Batch [1612/2500], Loss: 0.014748968183994293\n",
      "Epoch [2/3], Batch [1613/2500], Loss: 0.26128071546554565\n",
      "Epoch [2/3], Batch [1614/2500], Loss: 0.3059755265712738\n",
      "Epoch [2/3], Batch [1615/2500], Loss: 0.13444802165031433\n",
      "Epoch [2/3], Batch [1616/2500], Loss: 0.12475482374429703\n",
      "Epoch [2/3], Batch [1617/2500], Loss: 0.0705062597990036\n",
      "Epoch [2/3], Batch [1618/2500], Loss: 0.2748478651046753\n",
      "Epoch [2/3], Batch [1619/2500], Loss: 0.27318087220191956\n",
      "Epoch [2/3], Batch [1620/2500], Loss: 0.1232002004981041\n",
      "Epoch [2/3], Batch [1621/2500], Loss: 0.12439669668674469\n",
      "Epoch [2/3], Batch [1622/2500], Loss: 0.1322808414697647\n",
      "Epoch [2/3], Batch [1623/2500], Loss: 0.16826346516609192\n",
      "Epoch [2/3], Batch [1624/2500], Loss: 0.0937059298157692\n",
      "Epoch [2/3], Batch [1625/2500], Loss: 0.05859507620334625\n",
      "Epoch [2/3], Batch [1626/2500], Loss: 0.08779246360063553\n",
      "Epoch [2/3], Batch [1627/2500], Loss: 0.16746054589748383\n",
      "Epoch [2/3], Batch [1628/2500], Loss: 0.6905838847160339\n",
      "Epoch [2/3], Batch [1629/2500], Loss: 0.28331223130226135\n",
      "Epoch [2/3], Batch [1630/2500], Loss: 0.2433510422706604\n",
      "Epoch [2/3], Batch [1631/2500], Loss: 0.07116799056529999\n",
      "Epoch [2/3], Batch [1632/2500], Loss: 0.2206685096025467\n",
      "Epoch [2/3], Batch [1633/2500], Loss: 0.19100457429885864\n",
      "Epoch [2/3], Batch [1634/2500], Loss: 0.12388798594474792\n",
      "Epoch [2/3], Batch [1635/2500], Loss: 0.04463248327374458\n",
      "Epoch [2/3], Batch [1636/2500], Loss: 0.13128060102462769\n",
      "Epoch [2/3], Batch [1637/2500], Loss: 0.14378255605697632\n",
      "Epoch [2/3], Batch [1638/2500], Loss: 0.23673628270626068\n",
      "Epoch [2/3], Batch [1639/2500], Loss: 0.27207744121551514\n",
      "Epoch [2/3], Batch [1640/2500], Loss: 0.17448221147060394\n",
      "Epoch [2/3], Batch [1641/2500], Loss: 0.2112179547548294\n",
      "Epoch [2/3], Batch [1642/2500], Loss: 0.23020802438259125\n",
      "Epoch [2/3], Batch [1643/2500], Loss: 0.21646887063980103\n",
      "Epoch [2/3], Batch [1644/2500], Loss: 0.13093498349189758\n",
      "Epoch [2/3], Batch [1645/2500], Loss: 0.15584585070610046\n",
      "Epoch [2/3], Batch [1646/2500], Loss: 0.16319510340690613\n",
      "Epoch [2/3], Batch [1647/2500], Loss: 0.18338441848754883\n",
      "Epoch [2/3], Batch [1648/2500], Loss: 0.4361560344696045\n",
      "Epoch [2/3], Batch [1649/2500], Loss: 0.19223392009735107\n",
      "Epoch [2/3], Batch [1650/2500], Loss: 0.07125762104988098\n",
      "Epoch [2/3], Batch [1651/2500], Loss: 0.3337579667568207\n",
      "Epoch [2/3], Batch [1652/2500], Loss: 0.04293355345726013\n",
      "Epoch [2/3], Batch [1653/2500], Loss: 0.16007737815380096\n",
      "Epoch [2/3], Batch [1654/2500], Loss: 0.05047577992081642\n",
      "Epoch [2/3], Batch [1655/2500], Loss: 0.25514960289001465\n",
      "Epoch [2/3], Batch [1656/2500], Loss: 0.038284048438072205\n",
      "Epoch [2/3], Batch [1657/2500], Loss: 0.13652276992797852\n",
      "Epoch [2/3], Batch [1658/2500], Loss: 0.06345682591199875\n",
      "Epoch [2/3], Batch [1659/2500], Loss: 0.6280232667922974\n",
      "Epoch [2/3], Batch [1660/2500], Loss: 0.23747490346431732\n",
      "Epoch [2/3], Batch [1661/2500], Loss: 0.33675259351730347\n",
      "Epoch [2/3], Batch [1662/2500], Loss: 0.04226992279291153\n",
      "Epoch [2/3], Batch [1663/2500], Loss: 0.25120049715042114\n",
      "Epoch [2/3], Batch [1664/2500], Loss: 0.3426048755645752\n",
      "Epoch [2/3], Batch [1665/2500], Loss: 0.34436511993408203\n",
      "Epoch [2/3], Batch [1666/2500], Loss: 0.4704580008983612\n",
      "Epoch [2/3], Batch [1667/2500], Loss: 0.6322230696678162\n",
      "Epoch [2/3], Batch [1668/2500], Loss: 0.16384661197662354\n",
      "Epoch [2/3], Batch [1669/2500], Loss: 0.18919862806797028\n",
      "Epoch [2/3], Batch [1670/2500], Loss: 0.5052037835121155\n",
      "Epoch [2/3], Batch [1671/2500], Loss: 0.39845046401023865\n",
      "Epoch [2/3], Batch [1672/2500], Loss: 0.12741124629974365\n",
      "Epoch [2/3], Batch [1673/2500], Loss: 0.10299304872751236\n",
      "Epoch [2/3], Batch [1674/2500], Loss: 0.1616334170103073\n",
      "Epoch [2/3], Batch [1675/2500], Loss: 0.2814180850982666\n",
      "Epoch [2/3], Batch [1676/2500], Loss: 0.05584041401743889\n",
      "Epoch [2/3], Batch [1677/2500], Loss: 0.17485825717449188\n",
      "Epoch [2/3], Batch [1678/2500], Loss: 0.23053790628910065\n",
      "Epoch [2/3], Batch [1679/2500], Loss: 0.09687786549329758\n",
      "Epoch [2/3], Batch [1680/2500], Loss: 0.0769050121307373\n",
      "Epoch [2/3], Batch [1681/2500], Loss: 0.016267845407128334\n",
      "Epoch [2/3], Batch [1682/2500], Loss: 0.17911159992218018\n",
      "Epoch [2/3], Batch [1683/2500], Loss: 0.14715592563152313\n",
      "Epoch [2/3], Batch [1684/2500], Loss: 0.3207104504108429\n",
      "Epoch [2/3], Batch [1685/2500], Loss: 0.32937559485435486\n",
      "Epoch [2/3], Batch [1686/2500], Loss: 0.14607642590999603\n",
      "Epoch [2/3], Batch [1687/2500], Loss: 0.1683102399110794\n",
      "Epoch [2/3], Batch [1688/2500], Loss: 0.48771798610687256\n",
      "Epoch [2/3], Batch [1689/2500], Loss: 0.10314887762069702\n",
      "Epoch [2/3], Batch [1690/2500], Loss: 0.1458289474248886\n",
      "Epoch [2/3], Batch [1691/2500], Loss: 0.5455706715583801\n",
      "Epoch [2/3], Batch [1692/2500], Loss: 0.2466825246810913\n",
      "Epoch [2/3], Batch [1693/2500], Loss: 0.0623355358839035\n",
      "Epoch [2/3], Batch [1694/2500], Loss: 0.14222024381160736\n",
      "Epoch [2/3], Batch [1695/2500], Loss: 0.09402628242969513\n",
      "Epoch [2/3], Batch [1696/2500], Loss: 0.13139651715755463\n",
      "Epoch [2/3], Batch [1697/2500], Loss: 0.1993284523487091\n",
      "Epoch [2/3], Batch [1698/2500], Loss: 0.14093957841396332\n",
      "Epoch [2/3], Batch [1699/2500], Loss: 0.04327094927430153\n",
      "Epoch [2/3], Batch [1700/2500], Loss: 0.050706151872873306\n",
      "Epoch [2/3], Batch [1701/2500], Loss: 0.12356335669755936\n",
      "Epoch [2/3], Batch [1702/2500], Loss: 0.2267528772354126\n",
      "Epoch [2/3], Batch [1703/2500], Loss: 0.26407530903816223\n",
      "Epoch [2/3], Batch [1704/2500], Loss: 0.0648360326886177\n",
      "Epoch [2/3], Batch [1705/2500], Loss: 0.30092692375183105\n",
      "Epoch [2/3], Batch [1706/2500], Loss: 0.46485790610313416\n",
      "Epoch [2/3], Batch [1707/2500], Loss: 0.3089171051979065\n",
      "Epoch [2/3], Batch [1708/2500], Loss: 0.0725451335310936\n",
      "Epoch [2/3], Batch [1709/2500], Loss: 0.12945663928985596\n",
      "Epoch [2/3], Batch [1710/2500], Loss: 0.19165219366550446\n",
      "Epoch [2/3], Batch [1711/2500], Loss: 0.20988324284553528\n",
      "Epoch [2/3], Batch [1712/2500], Loss: 0.45668384432792664\n",
      "Epoch [2/3], Batch [1713/2500], Loss: 0.10015098750591278\n",
      "Epoch [2/3], Batch [1714/2500], Loss: 0.38898536562919617\n",
      "Epoch [2/3], Batch [1715/2500], Loss: 0.5173953771591187\n",
      "Epoch [2/3], Batch [1716/2500], Loss: 0.18516267836093903\n",
      "Epoch [2/3], Batch [1717/2500], Loss: 0.05843241512775421\n",
      "Epoch [2/3], Batch [1718/2500], Loss: 0.09979722648859024\n",
      "Epoch [2/3], Batch [1719/2500], Loss: 0.3076637089252472\n",
      "Epoch [2/3], Batch [1720/2500], Loss: 0.23511826992034912\n",
      "Epoch [2/3], Batch [1721/2500], Loss: 0.1129067987203598\n",
      "Epoch [2/3], Batch [1722/2500], Loss: 0.2687828242778778\n",
      "Epoch [2/3], Batch [1723/2500], Loss: 0.3698578178882599\n",
      "Epoch [2/3], Batch [1724/2500], Loss: 0.2991678714752197\n",
      "Epoch [2/3], Batch [1725/2500], Loss: 0.23815637826919556\n",
      "Epoch [2/3], Batch [1726/2500], Loss: 0.23720364272594452\n",
      "Epoch [2/3], Batch [1727/2500], Loss: 0.16924719512462616\n",
      "Epoch [2/3], Batch [1728/2500], Loss: 0.08470484614372253\n",
      "Epoch [2/3], Batch [1729/2500], Loss: 0.6157302856445312\n",
      "Epoch [2/3], Batch [1730/2500], Loss: 0.175738126039505\n",
      "Epoch [2/3], Batch [1731/2500], Loss: 0.11963146179914474\n",
      "Epoch [2/3], Batch [1732/2500], Loss: 0.07636229693889618\n",
      "Epoch [2/3], Batch [1733/2500], Loss: 0.2684747278690338\n",
      "Epoch [2/3], Batch [1734/2500], Loss: 0.3163512647151947\n",
      "Epoch [2/3], Batch [1735/2500], Loss: 0.38146480917930603\n",
      "Epoch [2/3], Batch [1736/2500], Loss: 0.5293028950691223\n",
      "Epoch [2/3], Batch [1737/2500], Loss: 0.17179401218891144\n",
      "Epoch [2/3], Batch [1738/2500], Loss: 0.17057834565639496\n",
      "Epoch [2/3], Batch [1739/2500], Loss: 0.12292735278606415\n",
      "Epoch [2/3], Batch [1740/2500], Loss: 0.0805458277463913\n",
      "Epoch [2/3], Batch [1741/2500], Loss: 0.04131137952208519\n",
      "Epoch [2/3], Batch [1742/2500], Loss: 0.29055869579315186\n",
      "Epoch [2/3], Batch [1743/2500], Loss: 0.19167394936084747\n",
      "Epoch [2/3], Batch [1744/2500], Loss: 0.0851893201470375\n",
      "Epoch [2/3], Batch [1745/2500], Loss: 0.08062279224395752\n",
      "Epoch [2/3], Batch [1746/2500], Loss: 0.15681427717208862\n",
      "Epoch [2/3], Batch [1747/2500], Loss: 0.1018882691860199\n",
      "Epoch [2/3], Batch [1748/2500], Loss: 0.04874797537922859\n",
      "Epoch [2/3], Batch [1749/2500], Loss: 0.2671213448047638\n",
      "Epoch [2/3], Batch [1750/2500], Loss: 0.22708760201931\n",
      "Epoch [2/3], Batch [1751/2500], Loss: 0.14043565094470978\n",
      "Epoch [2/3], Batch [1752/2500], Loss: 0.05063626170158386\n",
      "Epoch [2/3], Batch [1753/2500], Loss: 0.25862616300582886\n",
      "Epoch [2/3], Batch [1754/2500], Loss: 0.09552590548992157\n",
      "Epoch [2/3], Batch [1755/2500], Loss: 0.08312968164682388\n",
      "Epoch [2/3], Batch [1756/2500], Loss: 0.07120776921510696\n",
      "Epoch [2/3], Batch [1757/2500], Loss: 0.07338538020849228\n",
      "Epoch [2/3], Batch [1758/2500], Loss: 0.16115233302116394\n",
      "Epoch [2/3], Batch [1759/2500], Loss: 0.27548131346702576\n",
      "Epoch [2/3], Batch [1760/2500], Loss: 0.04446744918823242\n",
      "Epoch [2/3], Batch [1761/2500], Loss: 0.4001598358154297\n",
      "Epoch [2/3], Batch [1762/2500], Loss: 0.01669296808540821\n",
      "Epoch [2/3], Batch [1763/2500], Loss: 0.7209762930870056\n",
      "Epoch [2/3], Batch [1764/2500], Loss: 0.48993542790412903\n",
      "Epoch [2/3], Batch [1765/2500], Loss: 0.17292067408561707\n",
      "Epoch [2/3], Batch [1766/2500], Loss: 0.3327931761741638\n",
      "Epoch [2/3], Batch [1767/2500], Loss: 0.6157655119895935\n",
      "Epoch [2/3], Batch [1768/2500], Loss: 0.03763987496495247\n",
      "Epoch [2/3], Batch [1769/2500], Loss: 0.27599844336509705\n",
      "Epoch [2/3], Batch [1770/2500], Loss: 0.06064127758145332\n",
      "Epoch [2/3], Batch [1771/2500], Loss: 0.0562979020178318\n",
      "Epoch [2/3], Batch [1772/2500], Loss: 0.03388957679271698\n",
      "Epoch [2/3], Batch [1773/2500], Loss: 0.03579791262745857\n",
      "Epoch [2/3], Batch [1774/2500], Loss: 0.23930640518665314\n",
      "Epoch [2/3], Batch [1775/2500], Loss: 0.12425508350133896\n",
      "Epoch [2/3], Batch [1776/2500], Loss: 0.0673326775431633\n",
      "Epoch [2/3], Batch [1777/2500], Loss: 0.11987745761871338\n",
      "Epoch [2/3], Batch [1778/2500], Loss: 0.30047839879989624\n",
      "Epoch [2/3], Batch [1779/2500], Loss: 0.08656014502048492\n",
      "Epoch [2/3], Batch [1780/2500], Loss: 0.0993012860417366\n",
      "Epoch [2/3], Batch [1781/2500], Loss: 0.14970101416110992\n",
      "Epoch [2/3], Batch [1782/2500], Loss: 0.32364895939826965\n",
      "Epoch [2/3], Batch [1783/2500], Loss: 0.17573881149291992\n",
      "Epoch [2/3], Batch [1784/2500], Loss: 0.19306068122386932\n",
      "Epoch [2/3], Batch [1785/2500], Loss: 0.06567586213350296\n",
      "Epoch [2/3], Batch [1786/2500], Loss: 0.345538467168808\n",
      "Epoch [2/3], Batch [1787/2500], Loss: 0.22330394387245178\n",
      "Epoch [2/3], Batch [1788/2500], Loss: 0.2920101583003998\n",
      "Epoch [2/3], Batch [1789/2500], Loss: 0.08571670949459076\n",
      "Epoch [2/3], Batch [1790/2500], Loss: 0.27633267641067505\n",
      "Epoch [2/3], Batch [1791/2500], Loss: 0.1265043467283249\n",
      "Epoch [2/3], Batch [1792/2500], Loss: 0.27881520986557007\n",
      "Epoch [2/3], Batch [1793/2500], Loss: 0.11047936230897903\n",
      "Epoch [2/3], Batch [1794/2500], Loss: 0.15736913681030273\n",
      "Epoch [2/3], Batch [1795/2500], Loss: 0.05434255301952362\n",
      "Epoch [2/3], Batch [1796/2500], Loss: 0.20321416854858398\n",
      "Epoch [2/3], Batch [1797/2500], Loss: 0.26874256134033203\n",
      "Epoch [2/3], Batch [1798/2500], Loss: 0.24546445906162262\n",
      "Epoch [2/3], Batch [1799/2500], Loss: 0.17231661081314087\n",
      "Epoch [2/3], Batch [1800/2500], Loss: 0.36748549342155457\n",
      "Epoch [2/3], Batch [1801/2500], Loss: 0.03178510442376137\n",
      "Epoch [2/3], Batch [1802/2500], Loss: 0.15642856061458588\n",
      "Epoch [2/3], Batch [1803/2500], Loss: 0.20304454863071442\n",
      "Epoch [2/3], Batch [1804/2500], Loss: 0.03699518367648125\n",
      "Epoch [2/3], Batch [1805/2500], Loss: 0.7911332249641418\n",
      "Epoch [2/3], Batch [1806/2500], Loss: 0.02858411893248558\n",
      "Epoch [2/3], Batch [1807/2500], Loss: 0.06005421280860901\n",
      "Epoch [2/3], Batch [1808/2500], Loss: 0.06527753174304962\n",
      "Epoch [2/3], Batch [1809/2500], Loss: 0.1020333543419838\n",
      "Epoch [2/3], Batch [1810/2500], Loss: 0.03528909385204315\n",
      "Epoch [2/3], Batch [1811/2500], Loss: 0.11718960106372833\n",
      "Epoch [2/3], Batch [1812/2500], Loss: 0.7131996750831604\n",
      "Epoch [2/3], Batch [1813/2500], Loss: 0.14577721059322357\n",
      "Epoch [2/3], Batch [1814/2500], Loss: 0.06309276074171066\n",
      "Epoch [2/3], Batch [1815/2500], Loss: 0.47882845997810364\n",
      "Epoch [2/3], Batch [1816/2500], Loss: 0.05185333639383316\n",
      "Epoch [2/3], Batch [1817/2500], Loss: 0.34227898716926575\n",
      "Epoch [2/3], Batch [1818/2500], Loss: 0.18807393312454224\n",
      "Epoch [2/3], Batch [1819/2500], Loss: 0.4781807065010071\n",
      "Epoch [2/3], Batch [1820/2500], Loss: 0.20720231533050537\n",
      "Epoch [2/3], Batch [1821/2500], Loss: 0.7395449876785278\n",
      "Epoch [2/3], Batch [1822/2500], Loss: 0.21364285051822662\n",
      "Epoch [2/3], Batch [1823/2500], Loss: 0.0558929443359375\n",
      "Epoch [2/3], Batch [1824/2500], Loss: 0.2999967932701111\n",
      "Epoch [2/3], Batch [1825/2500], Loss: 0.16517674922943115\n",
      "Epoch [2/3], Batch [1826/2500], Loss: 0.08263850957155228\n",
      "Epoch [2/3], Batch [1827/2500], Loss: 0.304360568523407\n",
      "Epoch [2/3], Batch [1828/2500], Loss: 0.24828475713729858\n",
      "Epoch [2/3], Batch [1829/2500], Loss: 0.21893349289894104\n",
      "Epoch [2/3], Batch [1830/2500], Loss: 0.47434186935424805\n",
      "Epoch [2/3], Batch [1831/2500], Loss: 0.18324393033981323\n",
      "Epoch [2/3], Batch [1832/2500], Loss: 0.16158811748027802\n",
      "Epoch [2/3], Batch [1833/2500], Loss: 0.8038875460624695\n",
      "Epoch [2/3], Batch [1834/2500], Loss: 0.24366365373134613\n",
      "Epoch [2/3], Batch [1835/2500], Loss: 0.233954519033432\n",
      "Epoch [2/3], Batch [1836/2500], Loss: 0.31878119707107544\n",
      "Epoch [2/3], Batch [1837/2500], Loss: 0.09533674269914627\n",
      "Epoch [2/3], Batch [1838/2500], Loss: 0.3712921440601349\n",
      "Epoch [2/3], Batch [1839/2500], Loss: 0.14716653525829315\n",
      "Epoch [2/3], Batch [1840/2500], Loss: 0.12434427440166473\n",
      "Epoch [2/3], Batch [1841/2500], Loss: 0.09755201637744904\n",
      "Epoch [2/3], Batch [1842/2500], Loss: 0.19342373311519623\n",
      "Epoch [2/3], Batch [1843/2500], Loss: 0.2850204110145569\n",
      "Epoch [2/3], Batch [1844/2500], Loss: 0.06600894033908844\n",
      "Epoch [2/3], Batch [1845/2500], Loss: 0.12063860893249512\n",
      "Epoch [2/3], Batch [1846/2500], Loss: 0.11121641844511032\n",
      "Epoch [2/3], Batch [1847/2500], Loss: 0.1442640721797943\n",
      "Epoch [2/3], Batch [1848/2500], Loss: 0.15334588289260864\n",
      "Epoch [2/3], Batch [1849/2500], Loss: 0.23901796340942383\n",
      "Epoch [2/3], Batch [1850/2500], Loss: 0.38870614767074585\n",
      "Epoch [2/3], Batch [1851/2500], Loss: 0.11274539679288864\n",
      "Epoch [2/3], Batch [1852/2500], Loss: 0.3655247092247009\n",
      "Epoch [2/3], Batch [1853/2500], Loss: 0.27680400013923645\n",
      "Epoch [2/3], Batch [1854/2500], Loss: 0.1232156902551651\n",
      "Epoch [2/3], Batch [1855/2500], Loss: 0.15761077404022217\n",
      "Epoch [2/3], Batch [1856/2500], Loss: 0.05075613409280777\n",
      "Epoch [2/3], Batch [1857/2500], Loss: 0.29433295130729675\n",
      "Epoch [2/3], Batch [1858/2500], Loss: 0.43176719546318054\n",
      "Epoch [2/3], Batch [1859/2500], Loss: 0.221469908952713\n",
      "Epoch [2/3], Batch [1860/2500], Loss: 0.114183709025383\n",
      "Epoch [2/3], Batch [1861/2500], Loss: 0.12165544927120209\n",
      "Epoch [2/3], Batch [1862/2500], Loss: 0.044469162821769714\n",
      "Epoch [2/3], Batch [1863/2500], Loss: 0.629069983959198\n",
      "Epoch [2/3], Batch [1864/2500], Loss: 0.036567941308021545\n",
      "Epoch [2/3], Batch [1865/2500], Loss: 0.262885183095932\n",
      "Epoch [2/3], Batch [1866/2500], Loss: 0.1096528097987175\n",
      "Epoch [2/3], Batch [1867/2500], Loss: 0.03915904462337494\n",
      "Epoch [2/3], Batch [1868/2500], Loss: 0.21777091920375824\n",
      "Epoch [2/3], Batch [1869/2500], Loss: 0.4330429136753082\n",
      "Epoch [2/3], Batch [1870/2500], Loss: 0.05949696525931358\n",
      "Epoch [2/3], Batch [1871/2500], Loss: 0.06472184509038925\n",
      "Epoch [2/3], Batch [1872/2500], Loss: 0.11038048565387726\n",
      "Epoch [2/3], Batch [1873/2500], Loss: 0.1866338551044464\n",
      "Epoch [2/3], Batch [1874/2500], Loss: 0.3060750961303711\n",
      "Epoch [2/3], Batch [1875/2500], Loss: 0.07385965436697006\n",
      "Epoch [2/3], Batch [1876/2500], Loss: 0.10950946062803268\n",
      "Epoch [2/3], Batch [1877/2500], Loss: 0.028473813086748123\n",
      "Epoch [2/3], Batch [1878/2500], Loss: 0.40526238083839417\n",
      "Epoch [2/3], Batch [1879/2500], Loss: 0.12046786397695541\n",
      "Epoch [2/3], Batch [1880/2500], Loss: 0.1576162725687027\n",
      "Epoch [2/3], Batch [1881/2500], Loss: 0.2421129047870636\n",
      "Epoch [2/3], Batch [1882/2500], Loss: 0.12240693718194962\n",
      "Epoch [2/3], Batch [1883/2500], Loss: 0.1895466148853302\n",
      "Epoch [2/3], Batch [1884/2500], Loss: 0.09235873073339462\n",
      "Epoch [2/3], Batch [1885/2500], Loss: 0.2916867136955261\n",
      "Epoch [2/3], Batch [1886/2500], Loss: 0.1235048919916153\n",
      "Epoch [2/3], Batch [1887/2500], Loss: 0.23944969475269318\n",
      "Epoch [2/3], Batch [1888/2500], Loss: 0.06215430051088333\n",
      "Epoch [2/3], Batch [1889/2500], Loss: 0.10968237370252609\n",
      "Epoch [2/3], Batch [1890/2500], Loss: 0.41826555132865906\n",
      "Epoch [2/3], Batch [1891/2500], Loss: 0.0552041232585907\n",
      "Epoch [2/3], Batch [1892/2500], Loss: 0.25428274273872375\n",
      "Epoch [2/3], Batch [1893/2500], Loss: 0.05186838656663895\n",
      "Epoch [2/3], Batch [1894/2500], Loss: 0.07725292444229126\n",
      "Epoch [2/3], Batch [1895/2500], Loss: 0.21103741228580475\n",
      "Epoch [2/3], Batch [1896/2500], Loss: 0.037143368273973465\n",
      "Epoch [2/3], Batch [1897/2500], Loss: 0.12398286163806915\n",
      "Epoch [2/3], Batch [1898/2500], Loss: 0.23493878543376923\n",
      "Epoch [2/3], Batch [1899/2500], Loss: 0.2552116811275482\n",
      "Epoch [2/3], Batch [1900/2500], Loss: 0.5430506467819214\n",
      "Epoch [2/3], Batch [1901/2500], Loss: 0.11670149117708206\n",
      "Epoch [2/3], Batch [1902/2500], Loss: 0.22607506811618805\n",
      "Epoch [2/3], Batch [1903/2500], Loss: 0.07965516299009323\n",
      "Epoch [2/3], Batch [1904/2500], Loss: 0.13329285383224487\n",
      "Epoch [2/3], Batch [1905/2500], Loss: 0.07104336470365524\n",
      "Epoch [2/3], Batch [1906/2500], Loss: 0.03921179845929146\n",
      "Epoch [2/3], Batch [1907/2500], Loss: 0.20839381217956543\n",
      "Epoch [2/3], Batch [1908/2500], Loss: 0.30527764558792114\n",
      "Epoch [2/3], Batch [1909/2500], Loss: 0.18700052797794342\n",
      "Epoch [2/3], Batch [1910/2500], Loss: 0.024036744609475136\n",
      "Epoch [2/3], Batch [1911/2500], Loss: 0.019914695993065834\n",
      "Epoch [2/3], Batch [1912/2500], Loss: 0.2897707223892212\n",
      "Epoch [2/3], Batch [1913/2500], Loss: 0.13443303108215332\n",
      "Epoch [2/3], Batch [1914/2500], Loss: 0.14226235449314117\n",
      "Epoch [2/3], Batch [1915/2500], Loss: 0.28725096583366394\n",
      "Epoch [2/3], Batch [1916/2500], Loss: 0.038350217044353485\n",
      "Epoch [2/3], Batch [1917/2500], Loss: 0.09204848855733871\n",
      "Epoch [2/3], Batch [1918/2500], Loss: 0.15099315345287323\n",
      "Epoch [2/3], Batch [1919/2500], Loss: 0.09777146577835083\n",
      "Epoch [2/3], Batch [1920/2500], Loss: 0.09017161279916763\n",
      "Epoch [2/3], Batch [1921/2500], Loss: 0.10193654149770737\n",
      "Epoch [2/3], Batch [1922/2500], Loss: 0.0519605427980423\n",
      "Epoch [2/3], Batch [1923/2500], Loss: 0.06183009594678879\n",
      "Epoch [2/3], Batch [1924/2500], Loss: 0.2720642387866974\n",
      "Epoch [2/3], Batch [1925/2500], Loss: 0.4885603189468384\n",
      "Epoch [2/3], Batch [1926/2500], Loss: 0.3880440592765808\n",
      "Epoch [2/3], Batch [1927/2500], Loss: 0.0794106051325798\n",
      "Epoch [2/3], Batch [1928/2500], Loss: 0.06663241982460022\n",
      "Epoch [2/3], Batch [1929/2500], Loss: 0.3007514774799347\n",
      "Epoch [2/3], Batch [1930/2500], Loss: 0.06393469125032425\n",
      "Epoch [2/3], Batch [1931/2500], Loss: 0.061318397521972656\n",
      "Epoch [2/3], Batch [1932/2500], Loss: 0.01810844987630844\n",
      "Epoch [2/3], Batch [1933/2500], Loss: 0.03128276392817497\n",
      "Epoch [2/3], Batch [1934/2500], Loss: 0.05469968169927597\n",
      "Epoch [2/3], Batch [1935/2500], Loss: 0.19015705585479736\n",
      "Epoch [2/3], Batch [1936/2500], Loss: 0.08376452326774597\n",
      "Epoch [2/3], Batch [1937/2500], Loss: 0.22700782120227814\n",
      "Epoch [2/3], Batch [1938/2500], Loss: 0.07485303282737732\n",
      "Epoch [2/3], Batch [1939/2500], Loss: 0.38692206144332886\n",
      "Epoch [2/3], Batch [1940/2500], Loss: 1.1028424501419067\n",
      "Epoch [2/3], Batch [1941/2500], Loss: 0.0964331328868866\n",
      "Epoch [2/3], Batch [1942/2500], Loss: 0.47426021099090576\n",
      "Epoch [2/3], Batch [1943/2500], Loss: 0.17514672875404358\n",
      "Epoch [2/3], Batch [1944/2500], Loss: 0.6424100995063782\n",
      "Epoch [2/3], Batch [1945/2500], Loss: 0.25358304381370544\n",
      "Epoch [2/3], Batch [1946/2500], Loss: 0.04034287482500076\n",
      "Epoch [2/3], Batch [1947/2500], Loss: 0.2707728445529938\n",
      "Epoch [2/3], Batch [1948/2500], Loss: 0.04752501845359802\n",
      "Epoch [2/3], Batch [1949/2500], Loss: 0.0756642073392868\n",
      "Epoch [2/3], Batch [1950/2500], Loss: 0.08028895407915115\n",
      "Epoch [2/3], Batch [1951/2500], Loss: 0.47523418068885803\n",
      "Epoch [2/3], Batch [1952/2500], Loss: 0.30195221304893494\n",
      "Epoch [2/3], Batch [1953/2500], Loss: 0.02486014924943447\n",
      "Epoch [2/3], Batch [1954/2500], Loss: 0.07965072989463806\n",
      "Epoch [2/3], Batch [1955/2500], Loss: 0.04602852463722229\n",
      "Epoch [2/3], Batch [1956/2500], Loss: 0.08744020015001297\n",
      "Epoch [2/3], Batch [1957/2500], Loss: 0.05013582855463028\n",
      "Epoch [2/3], Batch [1958/2500], Loss: 0.15886810421943665\n",
      "Epoch [2/3], Batch [1959/2500], Loss: 0.3027532696723938\n",
      "Epoch [2/3], Batch [1960/2500], Loss: 0.050118912011384964\n",
      "Epoch [2/3], Batch [1961/2500], Loss: 0.5622950196266174\n",
      "Epoch [2/3], Batch [1962/2500], Loss: 0.2742568850517273\n",
      "Epoch [2/3], Batch [1963/2500], Loss: 0.06864744424819946\n",
      "Epoch [2/3], Batch [1964/2500], Loss: 0.10088955610990524\n",
      "Epoch [2/3], Batch [1965/2500], Loss: 0.3858628571033478\n",
      "Epoch [2/3], Batch [1966/2500], Loss: 0.16742536425590515\n",
      "Epoch [2/3], Batch [1967/2500], Loss: 0.13279031217098236\n",
      "Epoch [2/3], Batch [1968/2500], Loss: 0.415923535823822\n",
      "Epoch [2/3], Batch [1969/2500], Loss: 0.4038602411746979\n",
      "Epoch [2/3], Batch [1970/2500], Loss: 0.25252899527549744\n",
      "Epoch [2/3], Batch [1971/2500], Loss: 0.16296236217021942\n",
      "Epoch [2/3], Batch [1972/2500], Loss: 0.28425419330596924\n",
      "Epoch [2/3], Batch [1973/2500], Loss: 0.08780834823846817\n",
      "Epoch [2/3], Batch [1974/2500], Loss: 0.19014565646648407\n",
      "Epoch [2/3], Batch [1975/2500], Loss: 0.11387024074792862\n",
      "Epoch [2/3], Batch [1976/2500], Loss: 0.06569728255271912\n",
      "Epoch [2/3], Batch [1977/2500], Loss: 0.20320308208465576\n",
      "Epoch [2/3], Batch [1978/2500], Loss: 0.18281014263629913\n",
      "Epoch [2/3], Batch [1979/2500], Loss: 0.0579206682741642\n",
      "Epoch [2/3], Batch [1980/2500], Loss: 0.2749171853065491\n",
      "Epoch [2/3], Batch [1981/2500], Loss: 0.11732837557792664\n",
      "Epoch [2/3], Batch [1982/2500], Loss: 0.19874852895736694\n",
      "Epoch [2/3], Batch [1983/2500], Loss: 0.14825668931007385\n",
      "Epoch [2/3], Batch [1984/2500], Loss: 0.049305953085422516\n",
      "Epoch [2/3], Batch [1985/2500], Loss: 0.11021384596824646\n",
      "Epoch [2/3], Batch [1986/2500], Loss: 0.10558383166790009\n",
      "Epoch [2/3], Batch [1987/2500], Loss: 0.6719128489494324\n",
      "Epoch [2/3], Batch [1988/2500], Loss: 0.13258987665176392\n",
      "Epoch [2/3], Batch [1989/2500], Loss: 0.08683372288942337\n",
      "Epoch [2/3], Batch [1990/2500], Loss: 0.20116062462329865\n",
      "Epoch [2/3], Batch [1991/2500], Loss: 0.2831064462661743\n",
      "Epoch [2/3], Batch [1992/2500], Loss: 0.06149337440729141\n",
      "Epoch [2/3], Batch [1993/2500], Loss: 0.11092764884233475\n",
      "Epoch [2/3], Batch [1994/2500], Loss: 0.2264418601989746\n",
      "Epoch [2/3], Batch [1995/2500], Loss: 0.10120518505573273\n",
      "Epoch [2/3], Batch [1996/2500], Loss: 0.27162259817123413\n",
      "Epoch [2/3], Batch [1997/2500], Loss: 0.15383929014205933\n",
      "Epoch [2/3], Batch [1998/2500], Loss: 0.19729705154895782\n",
      "Epoch [2/3], Batch [1999/2500], Loss: 0.42329141497612\n",
      "Epoch [2/3], Batch [2000/2500], Loss: 0.0633038729429245\n",
      "Epoch [2/3], Batch [2001/2500], Loss: 0.30521005392074585\n",
      "Epoch [2/3], Batch [2002/2500], Loss: 0.20051909983158112\n",
      "Epoch [2/3], Batch [2003/2500], Loss: 0.12779225409030914\n",
      "Epoch [2/3], Batch [2004/2500], Loss: 0.03843920677900314\n",
      "Epoch [2/3], Batch [2005/2500], Loss: 0.26046454906463623\n",
      "Epoch [2/3], Batch [2006/2500], Loss: 0.30889979004859924\n",
      "Epoch [2/3], Batch [2007/2500], Loss: 0.08566385507583618\n",
      "Epoch [2/3], Batch [2008/2500], Loss: 0.07209616899490356\n",
      "Epoch [2/3], Batch [2009/2500], Loss: 0.19813331961631775\n",
      "Epoch [2/3], Batch [2010/2500], Loss: 0.2572368085384369\n",
      "Epoch [2/3], Batch [2011/2500], Loss: 0.7000243663787842\n",
      "Epoch [2/3], Batch [2012/2500], Loss: 0.2959557771682739\n",
      "Epoch [2/3], Batch [2013/2500], Loss: 0.06469961255788803\n",
      "Epoch [2/3], Batch [2014/2500], Loss: 0.38862183690071106\n",
      "Epoch [2/3], Batch [2015/2500], Loss: 0.018397759646177292\n",
      "Epoch [2/3], Batch [2016/2500], Loss: 0.1329113245010376\n",
      "Epoch [2/3], Batch [2017/2500], Loss: 0.061360977590084076\n",
      "Epoch [2/3], Batch [2018/2500], Loss: 0.13809435069561005\n",
      "Epoch [2/3], Batch [2019/2500], Loss: 0.1383049488067627\n",
      "Epoch [2/3], Batch [2020/2500], Loss: 0.07717305421829224\n",
      "Epoch [2/3], Batch [2021/2500], Loss: 0.05795901268720627\n",
      "Epoch [2/3], Batch [2022/2500], Loss: 0.0697224885225296\n",
      "Epoch [2/3], Batch [2023/2500], Loss: 0.07698497921228409\n",
      "Epoch [2/3], Batch [2024/2500], Loss: 0.24165424704551697\n",
      "Epoch [2/3], Batch [2025/2500], Loss: 0.12474661320447922\n",
      "Epoch [2/3], Batch [2026/2500], Loss: 0.037256285548210144\n",
      "Epoch [2/3], Batch [2027/2500], Loss: 0.0962853878736496\n",
      "Epoch [2/3], Batch [2028/2500], Loss: 0.0978584885597229\n",
      "Epoch [2/3], Batch [2029/2500], Loss: 0.10567240417003632\n",
      "Epoch [2/3], Batch [2030/2500], Loss: 0.2604459226131439\n",
      "Epoch [2/3], Batch [2031/2500], Loss: 0.10416530817747116\n",
      "Epoch [2/3], Batch [2032/2500], Loss: 0.30689671635627747\n",
      "Epoch [2/3], Batch [2033/2500], Loss: 0.04320705309510231\n",
      "Epoch [2/3], Batch [2034/2500], Loss: 0.3066341280937195\n",
      "Epoch [2/3], Batch [2035/2500], Loss: 0.4554065465927124\n",
      "Epoch [2/3], Batch [2036/2500], Loss: 0.1903921365737915\n",
      "Epoch [2/3], Batch [2037/2500], Loss: 0.3708422780036926\n",
      "Epoch [2/3], Batch [2038/2500], Loss: 0.23210272192955017\n",
      "Epoch [2/3], Batch [2039/2500], Loss: 0.08694092929363251\n",
      "Epoch [2/3], Batch [2040/2500], Loss: 0.25649604201316833\n",
      "Epoch [2/3], Batch [2041/2500], Loss: 0.0843363106250763\n",
      "Epoch [2/3], Batch [2042/2500], Loss: 0.09276682883501053\n",
      "Epoch [2/3], Batch [2043/2500], Loss: 0.2685728669166565\n",
      "Epoch [2/3], Batch [2044/2500], Loss: 0.188865065574646\n",
      "Epoch [2/3], Batch [2045/2500], Loss: 0.3643335998058319\n",
      "Epoch [2/3], Batch [2046/2500], Loss: 0.5224900245666504\n",
      "Epoch [2/3], Batch [2047/2500], Loss: 0.03569314628839493\n",
      "Epoch [2/3], Batch [2048/2500], Loss: 0.06175833195447922\n",
      "Epoch [2/3], Batch [2049/2500], Loss: 0.11956499516963959\n",
      "Epoch [2/3], Batch [2050/2500], Loss: 0.043282803148031235\n",
      "Epoch [2/3], Batch [2051/2500], Loss: 0.11112534254789352\n",
      "Epoch [2/3], Batch [2052/2500], Loss: 0.20476138591766357\n",
      "Epoch [2/3], Batch [2053/2500], Loss: 0.3796975016593933\n",
      "Epoch [2/3], Batch [2054/2500], Loss: 0.18878377974033356\n",
      "Epoch [2/3], Batch [2055/2500], Loss: 0.04710378870368004\n",
      "Epoch [2/3], Batch [2056/2500], Loss: 0.24789878726005554\n",
      "Epoch [2/3], Batch [2057/2500], Loss: 0.17530736327171326\n",
      "Epoch [2/3], Batch [2058/2500], Loss: 0.06860260665416718\n",
      "Epoch [2/3], Batch [2059/2500], Loss: 0.4020369052886963\n",
      "Epoch [2/3], Batch [2060/2500], Loss: 0.272050678730011\n",
      "Epoch [2/3], Batch [2061/2500], Loss: 0.08968547731637955\n",
      "Epoch [2/3], Batch [2062/2500], Loss: 0.2716900408267975\n",
      "Epoch [2/3], Batch [2063/2500], Loss: 0.26991012692451477\n",
      "Epoch [2/3], Batch [2064/2500], Loss: 0.07594373822212219\n",
      "Epoch [2/3], Batch [2065/2500], Loss: 0.3581436574459076\n",
      "Epoch [2/3], Batch [2066/2500], Loss: 0.14029259979724884\n",
      "Epoch [2/3], Batch [2067/2500], Loss: 0.04005841165781021\n",
      "Epoch [2/3], Batch [2068/2500], Loss: 0.09984444081783295\n",
      "Epoch [2/3], Batch [2069/2500], Loss: 0.09911206364631653\n",
      "Epoch [2/3], Batch [2070/2500], Loss: 0.23234359920024872\n",
      "Epoch [2/3], Batch [2071/2500], Loss: 0.48868805170059204\n",
      "Epoch [2/3], Batch [2072/2500], Loss: 0.07943687587976456\n",
      "Epoch [2/3], Batch [2073/2500], Loss: 0.8027011156082153\n",
      "Epoch [2/3], Batch [2074/2500], Loss: 0.16400963068008423\n",
      "Epoch [2/3], Batch [2075/2500], Loss: 0.06699647009372711\n",
      "Epoch [2/3], Batch [2076/2500], Loss: 0.08814571797847748\n",
      "Epoch [2/3], Batch [2077/2500], Loss: 0.0264828372746706\n",
      "Epoch [2/3], Batch [2078/2500], Loss: 0.31214699149131775\n",
      "Epoch [2/3], Batch [2079/2500], Loss: 0.3297950327396393\n",
      "Epoch [2/3], Batch [2080/2500], Loss: 0.2588590681552887\n",
      "Epoch [2/3], Batch [2081/2500], Loss: 0.04278137534856796\n",
      "Epoch [2/3], Batch [2082/2500], Loss: 0.06870751827955246\n",
      "Epoch [2/3], Batch [2083/2500], Loss: 0.13933134078979492\n",
      "Epoch [2/3], Batch [2084/2500], Loss: 0.05248304083943367\n",
      "Epoch [2/3], Batch [2085/2500], Loss: 0.3838663101196289\n",
      "Epoch [2/3], Batch [2086/2500], Loss: 0.4327191710472107\n",
      "Epoch [2/3], Batch [2087/2500], Loss: 0.4241982102394104\n",
      "Epoch [2/3], Batch [2088/2500], Loss: 0.3878694474697113\n",
      "Epoch [2/3], Batch [2089/2500], Loss: 0.09467145055532455\n",
      "Epoch [2/3], Batch [2090/2500], Loss: 0.12387925386428833\n",
      "Epoch [2/3], Batch [2091/2500], Loss: 0.07220122963190079\n",
      "Epoch [2/3], Batch [2092/2500], Loss: 0.41427353024482727\n",
      "Epoch [2/3], Batch [2093/2500], Loss: 0.06626848131418228\n",
      "Epoch [2/3], Batch [2094/2500], Loss: 0.05883911997079849\n",
      "Epoch [2/3], Batch [2095/2500], Loss: 0.2703956365585327\n",
      "Epoch [2/3], Batch [2096/2500], Loss: 0.35100826621055603\n",
      "Epoch [2/3], Batch [2097/2500], Loss: 0.1441343128681183\n",
      "Epoch [2/3], Batch [2098/2500], Loss: 0.21659770607948303\n",
      "Epoch [2/3], Batch [2099/2500], Loss: 0.6578634977340698\n",
      "Epoch [2/3], Batch [2100/2500], Loss: 0.11680156737565994\n",
      "Epoch [2/3], Batch [2101/2500], Loss: 0.0598248615860939\n",
      "Epoch [2/3], Batch [2102/2500], Loss: 0.08432275056838989\n",
      "Epoch [2/3], Batch [2103/2500], Loss: 0.10690218210220337\n",
      "Epoch [2/3], Batch [2104/2500], Loss: 0.1619914323091507\n",
      "Epoch [2/3], Batch [2105/2500], Loss: 0.7246975898742676\n",
      "Epoch [2/3], Batch [2106/2500], Loss: 0.5068826675415039\n",
      "Epoch [2/3], Batch [2107/2500], Loss: 0.4584306478500366\n",
      "Epoch [2/3], Batch [2108/2500], Loss: 0.04512573778629303\n",
      "Epoch [2/3], Batch [2109/2500], Loss: 0.1009177714586258\n",
      "Epoch [2/3], Batch [2110/2500], Loss: 0.05772585794329643\n",
      "Epoch [2/3], Batch [2111/2500], Loss: 0.3531431555747986\n",
      "Epoch [2/3], Batch [2112/2500], Loss: 0.11736197024583817\n",
      "Epoch [2/3], Batch [2113/2500], Loss: 0.12103341519832611\n",
      "Epoch [2/3], Batch [2114/2500], Loss: 0.10068240761756897\n",
      "Epoch [2/3], Batch [2115/2500], Loss: 0.17990611493587494\n",
      "Epoch [2/3], Batch [2116/2500], Loss: 0.15803246200084686\n",
      "Epoch [2/3], Batch [2117/2500], Loss: 0.187253937125206\n",
      "Epoch [2/3], Batch [2118/2500], Loss: 0.11590877920389175\n",
      "Epoch [2/3], Batch [2119/2500], Loss: 0.0819287970662117\n",
      "Epoch [2/3], Batch [2120/2500], Loss: 0.21785451471805573\n",
      "Epoch [2/3], Batch [2121/2500], Loss: 0.07018126547336578\n",
      "Epoch [2/3], Batch [2122/2500], Loss: 0.12222782522439957\n",
      "Epoch [2/3], Batch [2123/2500], Loss: 0.11121360957622528\n",
      "Epoch [2/3], Batch [2124/2500], Loss: 0.5044820308685303\n",
      "Epoch [2/3], Batch [2125/2500], Loss: 0.13931266963481903\n",
      "Epoch [2/3], Batch [2126/2500], Loss: 0.16709686815738678\n",
      "Epoch [2/3], Batch [2127/2500], Loss: 0.10999289155006409\n",
      "Epoch [2/3], Batch [2128/2500], Loss: 0.11344428360462189\n",
      "Epoch [2/3], Batch [2129/2500], Loss: 0.36212003231048584\n",
      "Epoch [2/3], Batch [2130/2500], Loss: 0.11863599717617035\n",
      "Epoch [2/3], Batch [2131/2500], Loss: 0.3483583331108093\n",
      "Epoch [2/3], Batch [2132/2500], Loss: 0.05619107931852341\n",
      "Epoch [2/3], Batch [2133/2500], Loss: 0.24796172976493835\n",
      "Epoch [2/3], Batch [2134/2500], Loss: 0.06601198762655258\n",
      "Epoch [2/3], Batch [2135/2500], Loss: 0.08262307941913605\n",
      "Epoch [2/3], Batch [2136/2500], Loss: 0.08756008744239807\n",
      "Epoch [2/3], Batch [2137/2500], Loss: 0.2753710150718689\n",
      "Epoch [2/3], Batch [2138/2500], Loss: 0.16751103103160858\n",
      "Epoch [2/3], Batch [2139/2500], Loss: 0.26707538962364197\n",
      "Epoch [2/3], Batch [2140/2500], Loss: 0.03974111005663872\n",
      "Epoch [2/3], Batch [2141/2500], Loss: 0.01823163777589798\n",
      "Epoch [2/3], Batch [2142/2500], Loss: 0.025760579854249954\n",
      "Epoch [2/3], Batch [2143/2500], Loss: 0.151561439037323\n",
      "Epoch [2/3], Batch [2144/2500], Loss: 0.11322033405303955\n",
      "Epoch [2/3], Batch [2145/2500], Loss: 0.6095796823501587\n",
      "Epoch [2/3], Batch [2146/2500], Loss: 0.021061886101961136\n",
      "Epoch [2/3], Batch [2147/2500], Loss: 0.10653462260961533\n",
      "Epoch [2/3], Batch [2148/2500], Loss: 0.3994331657886505\n",
      "Epoch [2/3], Batch [2149/2500], Loss: 0.1027936190366745\n",
      "Epoch [2/3], Batch [2150/2500], Loss: 0.11755598336458206\n",
      "Epoch [2/3], Batch [2151/2500], Loss: 0.1594870686531067\n",
      "Epoch [2/3], Batch [2152/2500], Loss: 0.20436857640743256\n",
      "Epoch [2/3], Batch [2153/2500], Loss: 0.07370984554290771\n",
      "Epoch [2/3], Batch [2154/2500], Loss: 0.10294213891029358\n",
      "Epoch [2/3], Batch [2155/2500], Loss: 0.17771907150745392\n",
      "Epoch [2/3], Batch [2156/2500], Loss: 0.10707617551088333\n",
      "Epoch [2/3], Batch [2157/2500], Loss: 0.10137694329023361\n",
      "Epoch [2/3], Batch [2158/2500], Loss: 0.30264854431152344\n",
      "Epoch [2/3], Batch [2159/2500], Loss: 0.2936911880970001\n",
      "Epoch [2/3], Batch [2160/2500], Loss: 0.19447733461856842\n",
      "Epoch [2/3], Batch [2161/2500], Loss: 0.03461833670735359\n",
      "Epoch [2/3], Batch [2162/2500], Loss: 0.0796208530664444\n",
      "Epoch [2/3], Batch [2163/2500], Loss: 0.13726948201656342\n",
      "Epoch [2/3], Batch [2164/2500], Loss: 0.07438234984874725\n",
      "Epoch [2/3], Batch [2165/2500], Loss: 0.05390749126672745\n",
      "Epoch [2/3], Batch [2166/2500], Loss: 0.10045371949672699\n",
      "Epoch [2/3], Batch [2167/2500], Loss: 0.0180806964635849\n",
      "Epoch [2/3], Batch [2168/2500], Loss: 0.04059571027755737\n",
      "Epoch [2/3], Batch [2169/2500], Loss: 0.25959980487823486\n",
      "Epoch [2/3], Batch [2170/2500], Loss: 0.27301886677742004\n",
      "Epoch [2/3], Batch [2171/2500], Loss: 0.05520763620734215\n",
      "Epoch [2/3], Batch [2172/2500], Loss: 0.05504711717367172\n",
      "Epoch [2/3], Batch [2173/2500], Loss: 0.201559379696846\n",
      "Epoch [2/3], Batch [2174/2500], Loss: 0.05451057106256485\n",
      "Epoch [2/3], Batch [2175/2500], Loss: 0.5290062427520752\n",
      "Epoch [2/3], Batch [2176/2500], Loss: 0.17312009632587433\n",
      "Epoch [2/3], Batch [2177/2500], Loss: 0.07801958918571472\n",
      "Epoch [2/3], Batch [2178/2500], Loss: 0.02427275851368904\n",
      "Epoch [2/3], Batch [2179/2500], Loss: 0.30679717659950256\n",
      "Epoch [2/3], Batch [2180/2500], Loss: 0.25196921825408936\n",
      "Epoch [2/3], Batch [2181/2500], Loss: 0.23334971070289612\n",
      "Epoch [2/3], Batch [2182/2500], Loss: 0.05696386843919754\n",
      "Epoch [2/3], Batch [2183/2500], Loss: 0.09593552350997925\n",
      "Epoch [2/3], Batch [2184/2500], Loss: 0.02933228388428688\n",
      "Epoch [2/3], Batch [2185/2500], Loss: 0.07707821577787399\n",
      "Epoch [2/3], Batch [2186/2500], Loss: 0.21921886503696442\n",
      "Epoch [2/3], Batch [2187/2500], Loss: 0.3424476683139801\n",
      "Epoch [2/3], Batch [2188/2500], Loss: 0.015212854370474815\n",
      "Epoch [2/3], Batch [2189/2500], Loss: 0.056344274431467056\n",
      "Epoch [2/3], Batch [2190/2500], Loss: 0.09538895636796951\n",
      "Epoch [2/3], Batch [2191/2500], Loss: 0.08097286522388458\n",
      "Epoch [2/3], Batch [2192/2500], Loss: 0.16399331390857697\n",
      "Epoch [2/3], Batch [2193/2500], Loss: 0.09238002449274063\n",
      "Epoch [2/3], Batch [2194/2500], Loss: 0.18436270952224731\n",
      "Epoch [2/3], Batch [2195/2500], Loss: 0.2748427391052246\n",
      "Epoch [2/3], Batch [2196/2500], Loss: 0.3306553065776825\n",
      "Epoch [2/3], Batch [2197/2500], Loss: 0.31621360778808594\n",
      "Epoch [2/3], Batch [2198/2500], Loss: 0.06901527941226959\n",
      "Epoch [2/3], Batch [2199/2500], Loss: 0.0819239690899849\n",
      "Epoch [2/3], Batch [2200/2500], Loss: 0.03756776079535484\n",
      "Epoch [2/3], Batch [2201/2500], Loss: 0.07811786234378815\n",
      "Epoch [2/3], Batch [2202/2500], Loss: 0.16155606508255005\n",
      "Epoch [2/3], Batch [2203/2500], Loss: 0.05011410638689995\n",
      "Epoch [2/3], Batch [2204/2500], Loss: 0.03397092968225479\n",
      "Epoch [2/3], Batch [2205/2500], Loss: 0.20891250669956207\n",
      "Epoch [2/3], Batch [2206/2500], Loss: 0.4656917452812195\n",
      "Epoch [2/3], Batch [2207/2500], Loss: 0.04038901999592781\n",
      "Epoch [2/3], Batch [2208/2500], Loss: 0.11458329856395721\n",
      "Epoch [2/3], Batch [2209/2500], Loss: 0.36095336079597473\n",
      "Epoch [2/3], Batch [2210/2500], Loss: 0.24792607128620148\n",
      "Epoch [2/3], Batch [2211/2500], Loss: 0.23666779696941376\n",
      "Epoch [2/3], Batch [2212/2500], Loss: 0.06642338633537292\n",
      "Epoch [2/3], Batch [2213/2500], Loss: 0.1695617139339447\n",
      "Epoch [2/3], Batch [2214/2500], Loss: 0.061364464461803436\n",
      "Epoch [2/3], Batch [2215/2500], Loss: 0.12741918861865997\n",
      "Epoch [2/3], Batch [2216/2500], Loss: 0.1316974014043808\n",
      "Epoch [2/3], Batch [2217/2500], Loss: 0.11957934498786926\n",
      "Epoch [2/3], Batch [2218/2500], Loss: 0.03324336186051369\n",
      "Epoch [2/3], Batch [2219/2500], Loss: 0.3116937279701233\n",
      "Epoch [2/3], Batch [2220/2500], Loss: 0.5630661249160767\n",
      "Epoch [2/3], Batch [2221/2500], Loss: 0.11145570874214172\n",
      "Epoch [2/3], Batch [2222/2500], Loss: 0.0816616341471672\n",
      "Epoch [2/3], Batch [2223/2500], Loss: 0.48592832684516907\n",
      "Epoch [2/3], Batch [2224/2500], Loss: 0.08914083987474442\n",
      "Epoch [2/3], Batch [2225/2500], Loss: 0.05432886257767677\n",
      "Epoch [2/3], Batch [2226/2500], Loss: 0.09190239757299423\n",
      "Epoch [2/3], Batch [2227/2500], Loss: 0.15036340057849884\n",
      "Epoch [2/3], Batch [2228/2500], Loss: 0.10956491529941559\n",
      "Epoch [2/3], Batch [2229/2500], Loss: 0.132425457239151\n",
      "Epoch [2/3], Batch [2230/2500], Loss: 0.15822547674179077\n",
      "Epoch [2/3], Batch [2231/2500], Loss: 0.04913631081581116\n",
      "Epoch [2/3], Batch [2232/2500], Loss: 0.29085105657577515\n",
      "Epoch [2/3], Batch [2233/2500], Loss: 0.17043530941009521\n",
      "Epoch [2/3], Batch [2234/2500], Loss: 0.2687378227710724\n",
      "Epoch [2/3], Batch [2235/2500], Loss: 0.1641409993171692\n",
      "Epoch [2/3], Batch [2236/2500], Loss: 0.11029133945703506\n",
      "Epoch [2/3], Batch [2237/2500], Loss: 0.47065359354019165\n",
      "Epoch [2/3], Batch [2238/2500], Loss: 0.07520012557506561\n",
      "Epoch [2/3], Batch [2239/2500], Loss: 0.1923547238111496\n",
      "Epoch [2/3], Batch [2240/2500], Loss: 0.03452448174357414\n",
      "Epoch [2/3], Batch [2241/2500], Loss: 0.13172350823879242\n",
      "Epoch [2/3], Batch [2242/2500], Loss: 0.28294017910957336\n",
      "Epoch [2/3], Batch [2243/2500], Loss: 0.014462234452366829\n",
      "Epoch [2/3], Batch [2244/2500], Loss: 0.30267688632011414\n",
      "Epoch [2/3], Batch [2245/2500], Loss: 0.015624744817614555\n",
      "Epoch [2/3], Batch [2246/2500], Loss: 0.14799067378044128\n",
      "Epoch [2/3], Batch [2247/2500], Loss: 0.11265167593955994\n",
      "Epoch [2/3], Batch [2248/2500], Loss: 0.06924139708280563\n",
      "Epoch [2/3], Batch [2249/2500], Loss: 0.28083863854408264\n",
      "Epoch [2/3], Batch [2250/2500], Loss: 0.15456198155879974\n",
      "Epoch [2/3], Batch [2251/2500], Loss: 0.10206826031208038\n",
      "Epoch [2/3], Batch [2252/2500], Loss: 0.10252707451581955\n",
      "Epoch [2/3], Batch [2253/2500], Loss: 0.08722643554210663\n",
      "Epoch [2/3], Batch [2254/2500], Loss: 0.19327344000339508\n",
      "Epoch [2/3], Batch [2255/2500], Loss: 0.2508678138256073\n",
      "Epoch [2/3], Batch [2256/2500], Loss: 0.008307134732604027\n",
      "Epoch [2/3], Batch [2257/2500], Loss: 0.015324337407946587\n",
      "Epoch [2/3], Batch [2258/2500], Loss: 0.33298346400260925\n",
      "Epoch [2/3], Batch [2259/2500], Loss: 0.19490398466587067\n",
      "Epoch [2/3], Batch [2260/2500], Loss: 0.14587214589118958\n",
      "Epoch [2/3], Batch [2261/2500], Loss: 0.08529439568519592\n",
      "Epoch [2/3], Batch [2262/2500], Loss: 0.08360135555267334\n",
      "Epoch [2/3], Batch [2263/2500], Loss: 0.7449769973754883\n",
      "Epoch [2/3], Batch [2264/2500], Loss: 0.28321078419685364\n",
      "Epoch [2/3], Batch [2265/2500], Loss: 0.10880708694458008\n",
      "Epoch [2/3], Batch [2266/2500], Loss: 0.18213719129562378\n",
      "Epoch [2/3], Batch [2267/2500], Loss: 0.03254805877804756\n",
      "Epoch [2/3], Batch [2268/2500], Loss: 0.30526459217071533\n",
      "Epoch [2/3], Batch [2269/2500], Loss: 0.1132979691028595\n",
      "Epoch [2/3], Batch [2270/2500], Loss: 0.23835550248622894\n",
      "Epoch [2/3], Batch [2271/2500], Loss: 0.860958456993103\n",
      "Epoch [2/3], Batch [2272/2500], Loss: 0.0475626178085804\n",
      "Epoch [2/3], Batch [2273/2500], Loss: 0.23970063030719757\n",
      "Epoch [2/3], Batch [2274/2500], Loss: 0.40515217185020447\n",
      "Epoch [2/3], Batch [2275/2500], Loss: 0.02352014183998108\n",
      "Epoch [2/3], Batch [2276/2500], Loss: 0.22711899876594543\n",
      "Epoch [2/3], Batch [2277/2500], Loss: 0.3842623233795166\n",
      "Epoch [2/3], Batch [2278/2500], Loss: 0.3126280605792999\n",
      "Epoch [2/3], Batch [2279/2500], Loss: 0.2172071486711502\n",
      "Epoch [2/3], Batch [2280/2500], Loss: 0.24766817688941956\n",
      "Epoch [2/3], Batch [2281/2500], Loss: 0.2650320827960968\n",
      "Epoch [2/3], Batch [2282/2500], Loss: 0.07636290788650513\n",
      "Epoch [2/3], Batch [2283/2500], Loss: 0.2453770488500595\n",
      "Epoch [2/3], Batch [2284/2500], Loss: 0.2090851217508316\n",
      "Epoch [2/3], Batch [2285/2500], Loss: 0.2668783962726593\n",
      "Epoch [2/3], Batch [2286/2500], Loss: 0.06856308877468109\n",
      "Epoch [2/3], Batch [2287/2500], Loss: 0.2592045068740845\n",
      "Epoch [2/3], Batch [2288/2500], Loss: 0.3164801001548767\n",
      "Epoch [2/3], Batch [2289/2500], Loss: 0.1733706146478653\n",
      "Epoch [2/3], Batch [2290/2500], Loss: 0.21452826261520386\n",
      "Epoch [2/3], Batch [2291/2500], Loss: 0.2295009344816208\n",
      "Epoch [2/3], Batch [2292/2500], Loss: 0.02408161759376526\n",
      "Epoch [2/3], Batch [2293/2500], Loss: 0.1373334527015686\n",
      "Epoch [2/3], Batch [2294/2500], Loss: 0.20086894929409027\n",
      "Epoch [2/3], Batch [2295/2500], Loss: 0.31850528717041016\n",
      "Epoch [2/3], Batch [2296/2500], Loss: 0.29116493463516235\n",
      "Epoch [2/3], Batch [2297/2500], Loss: 0.31624704599380493\n",
      "Epoch [2/3], Batch [2298/2500], Loss: 0.10204977542161942\n",
      "Epoch [2/3], Batch [2299/2500], Loss: 0.28045445680618286\n",
      "Epoch [2/3], Batch [2300/2500], Loss: 0.2309909462928772\n",
      "Epoch [2/3], Batch [2301/2500], Loss: 0.10188733786344528\n",
      "Epoch [2/3], Batch [2302/2500], Loss: 0.265259712934494\n",
      "Epoch [2/3], Batch [2303/2500], Loss: 0.0356699638068676\n",
      "Epoch [2/3], Batch [2304/2500], Loss: 0.019168134778738022\n",
      "Epoch [2/3], Batch [2305/2500], Loss: 0.258556604385376\n",
      "Epoch [2/3], Batch [2306/2500], Loss: 0.28941091895103455\n",
      "Epoch [2/3], Batch [2307/2500], Loss: 0.026385042816400528\n",
      "Epoch [2/3], Batch [2308/2500], Loss: 0.11816605180501938\n",
      "Epoch [2/3], Batch [2309/2500], Loss: 0.12049158662557602\n",
      "Epoch [2/3], Batch [2310/2500], Loss: 0.13462106883525848\n",
      "Epoch [2/3], Batch [2311/2500], Loss: 0.06963059306144714\n",
      "Epoch [2/3], Batch [2312/2500], Loss: 0.10904477536678314\n",
      "Epoch [2/3], Batch [2313/2500], Loss: 0.5805296897888184\n",
      "Epoch [2/3], Batch [2314/2500], Loss: 0.13300193846225739\n",
      "Epoch [2/3], Batch [2315/2500], Loss: 0.06729461997747421\n",
      "Epoch [2/3], Batch [2316/2500], Loss: 0.44472238421440125\n",
      "Epoch [2/3], Batch [2317/2500], Loss: 0.09894422441720963\n",
      "Epoch [2/3], Batch [2318/2500], Loss: 0.3863917291164398\n",
      "Epoch [2/3], Batch [2319/2500], Loss: 0.03172079473733902\n",
      "Epoch [2/3], Batch [2320/2500], Loss: 0.17425791919231415\n",
      "Epoch [2/3], Batch [2321/2500], Loss: 0.1322842240333557\n",
      "Epoch [2/3], Batch [2322/2500], Loss: 0.3866436183452606\n",
      "Epoch [2/3], Batch [2323/2500], Loss: 0.14574766159057617\n",
      "Epoch [2/3], Batch [2324/2500], Loss: 0.21455641090869904\n",
      "Epoch [2/3], Batch [2325/2500], Loss: 0.4168448746204376\n",
      "Epoch [2/3], Batch [2326/2500], Loss: 0.26739203929901123\n",
      "Epoch [2/3], Batch [2327/2500], Loss: 0.18960730731487274\n",
      "Epoch [2/3], Batch [2328/2500], Loss: 0.09251104295253754\n",
      "Epoch [2/3], Batch [2329/2500], Loss: 0.15739691257476807\n",
      "Epoch [2/3], Batch [2330/2500], Loss: 0.3981771767139435\n",
      "Epoch [2/3], Batch [2331/2500], Loss: 0.017694760113954544\n",
      "Epoch [2/3], Batch [2332/2500], Loss: 0.38015419244766235\n",
      "Epoch [2/3], Batch [2333/2500], Loss: 0.12596717476844788\n",
      "Epoch [2/3], Batch [2334/2500], Loss: 0.10489404946565628\n",
      "Epoch [2/3], Batch [2335/2500], Loss: 0.195724755525589\n",
      "Epoch [2/3], Batch [2336/2500], Loss: 0.269731730222702\n",
      "Epoch [2/3], Batch [2337/2500], Loss: 0.19460570812225342\n",
      "Epoch [2/3], Batch [2338/2500], Loss: 0.5249930024147034\n",
      "Epoch [2/3], Batch [2339/2500], Loss: 0.1614956110715866\n",
      "Epoch [2/3], Batch [2340/2500], Loss: 0.20667502284049988\n",
      "Epoch [2/3], Batch [2341/2500], Loss: 0.06567131727933884\n",
      "Epoch [2/3], Batch [2342/2500], Loss: 0.16043421626091003\n",
      "Epoch [2/3], Batch [2343/2500], Loss: 0.07355693727731705\n",
      "Epoch [2/3], Batch [2344/2500], Loss: 0.13604897260665894\n",
      "Epoch [2/3], Batch [2345/2500], Loss: 0.10537348687648773\n",
      "Epoch [2/3], Batch [2346/2500], Loss: 0.15113267302513123\n",
      "Epoch [2/3], Batch [2347/2500], Loss: 0.3691449761390686\n",
      "Epoch [2/3], Batch [2348/2500], Loss: 0.11310078948736191\n",
      "Epoch [2/3], Batch [2349/2500], Loss: 0.11976893246173859\n",
      "Epoch [2/3], Batch [2350/2500], Loss: 0.20828071236610413\n",
      "Epoch [2/3], Batch [2351/2500], Loss: 0.09633998572826385\n",
      "Epoch [2/3], Batch [2352/2500], Loss: 0.169434055685997\n",
      "Epoch [2/3], Batch [2353/2500], Loss: 0.10280969738960266\n",
      "Epoch [2/3], Batch [2354/2500], Loss: 0.053081341087818146\n",
      "Epoch [2/3], Batch [2355/2500], Loss: 0.3122435212135315\n",
      "Epoch [2/3], Batch [2356/2500], Loss: 0.18240231275558472\n",
      "Epoch [2/3], Batch [2357/2500], Loss: 0.20726338028907776\n",
      "Epoch [2/3], Batch [2358/2500], Loss: 0.4390830993652344\n",
      "Epoch [2/3], Batch [2359/2500], Loss: 0.06320206820964813\n",
      "Epoch [2/3], Batch [2360/2500], Loss: 0.06516232341527939\n",
      "Epoch [2/3], Batch [2361/2500], Loss: 0.1800769716501236\n",
      "Epoch [2/3], Batch [2362/2500], Loss: 0.22146287560462952\n",
      "Epoch [2/3], Batch [2363/2500], Loss: 0.019936932250857353\n",
      "Epoch [2/3], Batch [2364/2500], Loss: 0.09552118182182312\n",
      "Epoch [2/3], Batch [2365/2500], Loss: 0.2722195088863373\n",
      "Epoch [2/3], Batch [2366/2500], Loss: 0.07497616112232208\n",
      "Epoch [2/3], Batch [2367/2500], Loss: 0.3013840317726135\n",
      "Epoch [2/3], Batch [2368/2500], Loss: 0.1822773665189743\n",
      "Epoch [2/3], Batch [2369/2500], Loss: 0.1795169711112976\n",
      "Epoch [2/3], Batch [2370/2500], Loss: 0.2806520164012909\n",
      "Epoch [2/3], Batch [2371/2500], Loss: 0.08336169272661209\n",
      "Epoch [2/3], Batch [2372/2500], Loss: 0.11774405837059021\n",
      "Epoch [2/3], Batch [2373/2500], Loss: 0.11889202892780304\n",
      "Epoch [2/3], Batch [2374/2500], Loss: 0.12225901335477829\n",
      "Epoch [2/3], Batch [2375/2500], Loss: 0.1510578989982605\n",
      "Epoch [2/3], Batch [2376/2500], Loss: 0.07292196899652481\n",
      "Epoch [2/3], Batch [2377/2500], Loss: 0.13888804614543915\n",
      "Epoch [2/3], Batch [2378/2500], Loss: 0.0782499834895134\n",
      "Epoch [2/3], Batch [2379/2500], Loss: 0.050042130053043365\n",
      "Epoch [2/3], Batch [2380/2500], Loss: 0.0320001021027565\n",
      "Epoch [2/3], Batch [2381/2500], Loss: 0.5545675754547119\n",
      "Epoch [2/3], Batch [2382/2500], Loss: 0.05526147037744522\n",
      "Epoch [2/3], Batch [2383/2500], Loss: 0.06460613012313843\n",
      "Epoch [2/3], Batch [2384/2500], Loss: 0.18906721472740173\n",
      "Epoch [2/3], Batch [2385/2500], Loss: 0.04575897380709648\n",
      "Epoch [2/3], Batch [2386/2500], Loss: 0.3419300317764282\n",
      "Epoch [2/3], Batch [2387/2500], Loss: 0.21622677147388458\n",
      "Epoch [2/3], Batch [2388/2500], Loss: 0.2377651333808899\n",
      "Epoch [2/3], Batch [2389/2500], Loss: 0.354204922914505\n",
      "Epoch [2/3], Batch [2390/2500], Loss: 0.09937088191509247\n",
      "Epoch [2/3], Batch [2391/2500], Loss: 0.08138521760702133\n",
      "Epoch [2/3], Batch [2392/2500], Loss: 0.09076658636331558\n",
      "Epoch [2/3], Batch [2393/2500], Loss: 0.8439959287643433\n",
      "Epoch [2/3], Batch [2394/2500], Loss: 0.015973836183547974\n",
      "Epoch [2/3], Batch [2395/2500], Loss: 0.024661343544721603\n",
      "Epoch [2/3], Batch [2396/2500], Loss: 0.17213506996631622\n",
      "Epoch [2/3], Batch [2397/2500], Loss: 0.388373464345932\n",
      "Epoch [2/3], Batch [2398/2500], Loss: 0.08268013596534729\n",
      "Epoch [2/3], Batch [2399/2500], Loss: 0.21566200256347656\n",
      "Epoch [2/3], Batch [2400/2500], Loss: 0.42424142360687256\n",
      "Epoch [2/3], Batch [2401/2500], Loss: 0.09637194126844406\n",
      "Epoch [2/3], Batch [2402/2500], Loss: 0.016927845776081085\n",
      "Epoch [2/3], Batch [2403/2500], Loss: 0.6104381680488586\n",
      "Epoch [2/3], Batch [2404/2500], Loss: 0.15393148362636566\n",
      "Epoch [2/3], Batch [2405/2500], Loss: 0.5883375406265259\n",
      "Epoch [2/3], Batch [2406/2500], Loss: 0.11500437557697296\n",
      "Epoch [2/3], Batch [2407/2500], Loss: 0.3785788118839264\n",
      "Epoch [2/3], Batch [2408/2500], Loss: 0.10519331693649292\n",
      "Epoch [2/3], Batch [2409/2500], Loss: 0.15269380807876587\n",
      "Epoch [2/3], Batch [2410/2500], Loss: 0.09318019449710846\n",
      "Epoch [2/3], Batch [2411/2500], Loss: 0.08525512367486954\n",
      "Epoch [2/3], Batch [2412/2500], Loss: 0.23575609922409058\n",
      "Epoch [2/3], Batch [2413/2500], Loss: 0.15253567695617676\n",
      "Epoch [2/3], Batch [2414/2500], Loss: 0.18400314450263977\n",
      "Epoch [2/3], Batch [2415/2500], Loss: 0.06802265346050262\n",
      "Epoch [2/3], Batch [2416/2500], Loss: 0.16577190160751343\n",
      "Epoch [2/3], Batch [2417/2500], Loss: 0.10737745463848114\n",
      "Epoch [2/3], Batch [2418/2500], Loss: 0.04339643567800522\n",
      "Epoch [2/3], Batch [2419/2500], Loss: 0.4382410943508148\n",
      "Epoch [2/3], Batch [2420/2500], Loss: 0.19087335467338562\n",
      "Epoch [2/3], Batch [2421/2500], Loss: 0.13362853229045868\n",
      "Epoch [2/3], Batch [2422/2500], Loss: 0.7814339995384216\n",
      "Epoch [2/3], Batch [2423/2500], Loss: 0.464996874332428\n",
      "Epoch [2/3], Batch [2424/2500], Loss: 0.2609058916568756\n",
      "Epoch [2/3], Batch [2425/2500], Loss: 0.2662681043148041\n",
      "Epoch [2/3], Batch [2426/2500], Loss: 0.1654212772846222\n",
      "Epoch [2/3], Batch [2427/2500], Loss: 0.1374405473470688\n",
      "Epoch [2/3], Batch [2428/2500], Loss: 0.1790197342634201\n",
      "Epoch [2/3], Batch [2429/2500], Loss: 0.07767939567565918\n",
      "Epoch [2/3], Batch [2430/2500], Loss: 0.15571969747543335\n",
      "Epoch [2/3], Batch [2431/2500], Loss: 0.03286982327699661\n",
      "Epoch [2/3], Batch [2432/2500], Loss: 0.1019117459654808\n",
      "Epoch [2/3], Batch [2433/2500], Loss: 0.11991021037101746\n",
      "Epoch [2/3], Batch [2434/2500], Loss: 0.2049078792333603\n",
      "Epoch [2/3], Batch [2435/2500], Loss: 0.21906234323978424\n",
      "Epoch [2/3], Batch [2436/2500], Loss: 0.08218022435903549\n",
      "Epoch [2/3], Batch [2437/2500], Loss: 0.2786683738231659\n",
      "Epoch [2/3], Batch [2438/2500], Loss: 0.2090824991464615\n",
      "Epoch [2/3], Batch [2439/2500], Loss: 0.5499895811080933\n",
      "Epoch [2/3], Batch [2440/2500], Loss: 0.38390353322029114\n",
      "Epoch [2/3], Batch [2441/2500], Loss: 0.026394929736852646\n",
      "Epoch [2/3], Batch [2442/2500], Loss: 0.5207390189170837\n",
      "Epoch [2/3], Batch [2443/2500], Loss: 0.39399808645248413\n",
      "Epoch [2/3], Batch [2444/2500], Loss: 0.03558928892016411\n",
      "Epoch [2/3], Batch [2445/2500], Loss: 0.024773508310317993\n",
      "Epoch [2/3], Batch [2446/2500], Loss: 0.09720080345869064\n",
      "Epoch [2/3], Batch [2447/2500], Loss: 0.4884788691997528\n",
      "Epoch [2/3], Batch [2448/2500], Loss: 0.14289051294326782\n",
      "Epoch [2/3], Batch [2449/2500], Loss: 0.07019811868667603\n",
      "Epoch [2/3], Batch [2450/2500], Loss: 0.3208974599838257\n",
      "Epoch [2/3], Batch [2451/2500], Loss: 0.07594744116067886\n",
      "Epoch [2/3], Batch [2452/2500], Loss: 0.13868480920791626\n",
      "Epoch [2/3], Batch [2453/2500], Loss: 0.3137159049510956\n",
      "Epoch [2/3], Batch [2454/2500], Loss: 0.44921475648880005\n",
      "Epoch [2/3], Batch [2455/2500], Loss: 0.12308085709810257\n",
      "Epoch [2/3], Batch [2456/2500], Loss: 0.1598464548587799\n",
      "Epoch [2/3], Batch [2457/2500], Loss: 0.15687093138694763\n",
      "Epoch [2/3], Batch [2458/2500], Loss: 0.11203303933143616\n",
      "Epoch [2/3], Batch [2459/2500], Loss: 0.26139602065086365\n",
      "Epoch [2/3], Batch [2460/2500], Loss: 0.14547273516654968\n",
      "Epoch [2/3], Batch [2461/2500], Loss: 0.06914205849170685\n",
      "Epoch [2/3], Batch [2462/2500], Loss: 0.07937171310186386\n",
      "Epoch [2/3], Batch [2463/2500], Loss: 0.20993034541606903\n",
      "Epoch [2/3], Batch [2464/2500], Loss: 0.15664643049240112\n",
      "Epoch [2/3], Batch [2465/2500], Loss: 0.43923258781433105\n",
      "Epoch [2/3], Batch [2466/2500], Loss: 0.06515546143054962\n",
      "Epoch [2/3], Batch [2467/2500], Loss: 0.26505517959594727\n",
      "Epoch [2/3], Batch [2468/2500], Loss: 0.02498718351125717\n",
      "Epoch [2/3], Batch [2469/2500], Loss: 0.05395914241671562\n",
      "Epoch [2/3], Batch [2470/2500], Loss: 0.03915215656161308\n",
      "Epoch [2/3], Batch [2471/2500], Loss: 0.12216316163539886\n",
      "Epoch [2/3], Batch [2472/2500], Loss: 0.4307105541229248\n",
      "Epoch [2/3], Batch [2473/2500], Loss: 0.2791253328323364\n",
      "Epoch [2/3], Batch [2474/2500], Loss: 0.07271599769592285\n",
      "Epoch [2/3], Batch [2475/2500], Loss: 0.24383071064949036\n",
      "Epoch [2/3], Batch [2476/2500], Loss: 0.16074049472808838\n",
      "Epoch [2/3], Batch [2477/2500], Loss: 0.1462460160255432\n",
      "Epoch [2/3], Batch [2478/2500], Loss: 0.6993662714958191\n",
      "Epoch [2/3], Batch [2479/2500], Loss: 0.1608327180147171\n",
      "Epoch [2/3], Batch [2480/2500], Loss: 0.26875895261764526\n",
      "Epoch [2/3], Batch [2481/2500], Loss: 0.23027722537517548\n",
      "Epoch [2/3], Batch [2482/2500], Loss: 0.10276924073696136\n",
      "Epoch [2/3], Batch [2483/2500], Loss: 0.2540819048881531\n",
      "Epoch [2/3], Batch [2484/2500], Loss: 0.188278928399086\n",
      "Epoch [2/3], Batch [2485/2500], Loss: 0.4214991331100464\n",
      "Epoch [2/3], Batch [2486/2500], Loss: 0.30758464336395264\n",
      "Epoch [2/3], Batch [2487/2500], Loss: 0.4269542098045349\n",
      "Epoch [2/3], Batch [2488/2500], Loss: 0.2455778419971466\n",
      "Epoch [2/3], Batch [2489/2500], Loss: 0.2573772668838501\n",
      "Epoch [2/3], Batch [2490/2500], Loss: 0.08751285821199417\n",
      "Epoch [2/3], Batch [2491/2500], Loss: 0.36443057656288147\n",
      "Epoch [2/3], Batch [2492/2500], Loss: 0.42102646827697754\n",
      "Epoch [2/3], Batch [2493/2500], Loss: 0.12998554110527039\n",
      "Epoch [2/3], Batch [2494/2500], Loss: 0.2553543746471405\n",
      "Epoch [2/3], Batch [2495/2500], Loss: 0.14527717232704163\n",
      "Epoch [2/3], Batch [2496/2500], Loss: 0.32366108894348145\n",
      "Epoch [2/3], Batch [2497/2500], Loss: 0.11431946605443954\n",
      "Epoch [2/3], Batch [2498/2500], Loss: 0.106581911444664\n",
      "Epoch [2/3], Batch [2499/2500], Loss: 0.0770234614610672\n",
      "Epoch [2/3], Batch [2500/2500], Loss: 0.2503410577774048\n",
      "Epoch [2/3] Average Loss: 0.19631572096273303\n",
      "Epoch 3/3\n",
      "Epoch [3/3], Batch [1/2500], Loss: 0.20809009671211243\n",
      "Epoch [3/3], Batch [2/2500], Loss: 0.07502616941928864\n",
      "Epoch [3/3], Batch [3/2500], Loss: 0.47729912400245667\n",
      "Epoch [3/3], Batch [4/2500], Loss: 0.1966283619403839\n",
      "Epoch [3/3], Batch [5/2500], Loss: 0.5427566766738892\n",
      "Epoch [3/3], Batch [6/2500], Loss: 0.2091710865497589\n",
      "Epoch [3/3], Batch [7/2500], Loss: 0.19429264962673187\n",
      "Epoch [3/3], Batch [8/2500], Loss: 0.10447928309440613\n",
      "Epoch [3/3], Batch [9/2500], Loss: 0.4815305769443512\n",
      "Epoch [3/3], Batch [10/2500], Loss: 0.10772855579853058\n",
      "Epoch [3/3], Batch [11/2500], Loss: 0.052899397909641266\n",
      "Epoch [3/3], Batch [12/2500], Loss: 0.541860818862915\n",
      "Epoch [3/3], Batch [13/2500], Loss: 0.10016832500696182\n",
      "Epoch [3/3], Batch [14/2500], Loss: 0.40708455443382263\n",
      "Epoch [3/3], Batch [15/2500], Loss: 0.045088037848472595\n",
      "Epoch [3/3], Batch [16/2500], Loss: 0.09643673151731491\n",
      "Epoch [3/3], Batch [17/2500], Loss: 0.2036205530166626\n",
      "Epoch [3/3], Batch [18/2500], Loss: 0.17749711871147156\n",
      "Epoch [3/3], Batch [19/2500], Loss: 0.4892714023590088\n",
      "Epoch [3/3], Batch [20/2500], Loss: 0.12392258644104004\n",
      "Epoch [3/3], Batch [21/2500], Loss: 0.10109402984380722\n",
      "Epoch [3/3], Batch [22/2500], Loss: 0.28202545642852783\n",
      "Epoch [3/3], Batch [23/2500], Loss: 0.12226064503192902\n",
      "Epoch [3/3], Batch [24/2500], Loss: 0.31225618720054626\n",
      "Epoch [3/3], Batch [25/2500], Loss: 0.28970375657081604\n",
      "Epoch [3/3], Batch [26/2500], Loss: 0.12161827832460403\n",
      "Epoch [3/3], Batch [27/2500], Loss: 0.16893769800662994\n",
      "Epoch [3/3], Batch [28/2500], Loss: 0.0758109837770462\n",
      "Epoch [3/3], Batch [29/2500], Loss: 0.04240895435214043\n",
      "Epoch [3/3], Batch [30/2500], Loss: 0.10769665241241455\n",
      "Epoch [3/3], Batch [31/2500], Loss: 0.19754581153392792\n",
      "Epoch [3/3], Batch [32/2500], Loss: 0.15723897516727448\n",
      "Epoch [3/3], Batch [33/2500], Loss: 0.16592848300933838\n",
      "Epoch [3/3], Batch [34/2500], Loss: 0.15137986838817596\n",
      "Epoch [3/3], Batch [35/2500], Loss: 0.12171359360218048\n",
      "Epoch [3/3], Batch [36/2500], Loss: 0.03556804358959198\n",
      "Epoch [3/3], Batch [37/2500], Loss: 0.21349281072616577\n",
      "Epoch [3/3], Batch [38/2500], Loss: 0.05716346576809883\n",
      "Epoch [3/3], Batch [39/2500], Loss: 0.20440813899040222\n",
      "Epoch [3/3], Batch [40/2500], Loss: 0.10894234478473663\n",
      "Epoch [3/3], Batch [41/2500], Loss: 0.0630669966340065\n",
      "Epoch [3/3], Batch [42/2500], Loss: 0.18183633685112\n",
      "Epoch [3/3], Batch [43/2500], Loss: 0.1478852927684784\n",
      "Epoch [3/3], Batch [44/2500], Loss: 0.32249608635902405\n",
      "Epoch [3/3], Batch [45/2500], Loss: 0.20430490374565125\n",
      "Epoch [3/3], Batch [46/2500], Loss: 0.19014973938465118\n",
      "Epoch [3/3], Batch [47/2500], Loss: 0.10597985237836838\n",
      "Epoch [3/3], Batch [48/2500], Loss: 0.13766691088676453\n",
      "Epoch [3/3], Batch [49/2500], Loss: 0.0390508733689785\n",
      "Epoch [3/3], Batch [50/2500], Loss: 0.3584578335285187\n",
      "Epoch [3/3], Batch [51/2500], Loss: 0.17384661734104156\n",
      "Epoch [3/3], Batch [52/2500], Loss: 0.1812002956867218\n",
      "Epoch [3/3], Batch [53/2500], Loss: 0.31882575154304504\n",
      "Epoch [3/3], Batch [54/2500], Loss: 0.16811561584472656\n",
      "Epoch [3/3], Batch [55/2500], Loss: 0.18083634972572327\n",
      "Epoch [3/3], Batch [56/2500], Loss: 0.04445663467049599\n",
      "Epoch [3/3], Batch [57/2500], Loss: 0.03841758891940117\n",
      "Epoch [3/3], Batch [58/2500], Loss: 0.19122427701950073\n",
      "Epoch [3/3], Batch [59/2500], Loss: 0.023938732221722603\n",
      "Epoch [3/3], Batch [60/2500], Loss: 0.09045963734388351\n",
      "Epoch [3/3], Batch [61/2500], Loss: 0.29110997915267944\n",
      "Epoch [3/3], Batch [62/2500], Loss: 0.07230986654758453\n",
      "Epoch [3/3], Batch [63/2500], Loss: 0.1337740272283554\n",
      "Epoch [3/3], Batch [64/2500], Loss: 0.04937032610177994\n",
      "Epoch [3/3], Batch [65/2500], Loss: 0.019775763154029846\n",
      "Epoch [3/3], Batch [66/2500], Loss: 0.08595724403858185\n",
      "Epoch [3/3], Batch [67/2500], Loss: 0.18233299255371094\n",
      "Epoch [3/3], Batch [68/2500], Loss: 0.06745164096355438\n",
      "Epoch [3/3], Batch [69/2500], Loss: 0.13535860180854797\n",
      "Epoch [3/3], Batch [70/2500], Loss: 0.2820451855659485\n",
      "Epoch [3/3], Batch [71/2500], Loss: 0.11378484964370728\n",
      "Epoch [3/3], Batch [72/2500], Loss: 0.08562371879816055\n",
      "Epoch [3/3], Batch [73/2500], Loss: 0.09662528336048126\n",
      "Epoch [3/3], Batch [74/2500], Loss: 0.033014073967933655\n",
      "Epoch [3/3], Batch [75/2500], Loss: 0.6017588376998901\n",
      "Epoch [3/3], Batch [76/2500], Loss: 0.2758225202560425\n",
      "Epoch [3/3], Batch [77/2500], Loss: 0.05698557198047638\n",
      "Epoch [3/3], Batch [78/2500], Loss: 0.17899532616138458\n",
      "Epoch [3/3], Batch [79/2500], Loss: 0.03935585170984268\n",
      "Epoch [3/3], Batch [80/2500], Loss: 0.07521311938762665\n",
      "Epoch [3/3], Batch [81/2500], Loss: 0.0650942325592041\n",
      "Epoch [3/3], Batch [82/2500], Loss: 0.22537831962108612\n",
      "Epoch [3/3], Batch [83/2500], Loss: 0.0923706665635109\n",
      "Epoch [3/3], Batch [84/2500], Loss: 0.18808916211128235\n",
      "Epoch [3/3], Batch [85/2500], Loss: 0.05336760729551315\n",
      "Epoch [3/3], Batch [86/2500], Loss: 0.026404283940792084\n",
      "Epoch [3/3], Batch [87/2500], Loss: 0.02919515036046505\n",
      "Epoch [3/3], Batch [88/2500], Loss: 0.42959800362586975\n",
      "Epoch [3/3], Batch [89/2500], Loss: 0.12072840332984924\n",
      "Epoch [3/3], Batch [90/2500], Loss: 0.15177392959594727\n",
      "Epoch [3/3], Batch [91/2500], Loss: 0.1785130500793457\n",
      "Epoch [3/3], Batch [92/2500], Loss: 0.038211025297641754\n",
      "Epoch [3/3], Batch [93/2500], Loss: 0.02525443583726883\n",
      "Epoch [3/3], Batch [94/2500], Loss: 0.23283086717128754\n",
      "Epoch [3/3], Batch [95/2500], Loss: 0.03968888521194458\n",
      "Epoch [3/3], Batch [96/2500], Loss: 0.11697673797607422\n",
      "Epoch [3/3], Batch [97/2500], Loss: 0.23011845350265503\n",
      "Epoch [3/3], Batch [98/2500], Loss: 0.39216506481170654\n",
      "Epoch [3/3], Batch [99/2500], Loss: 0.2686121165752411\n",
      "Epoch [3/3], Batch [100/2500], Loss: 0.057054970413446426\n",
      "Epoch [3/3], Batch [101/2500], Loss: 0.474115252494812\n",
      "Epoch [3/3], Batch [102/2500], Loss: 0.15898944437503815\n",
      "Epoch [3/3], Batch [103/2500], Loss: 0.0765841156244278\n",
      "Epoch [3/3], Batch [104/2500], Loss: 0.41874152421951294\n",
      "Epoch [3/3], Batch [105/2500], Loss: 0.45761141180992126\n",
      "Epoch [3/3], Batch [106/2500], Loss: 0.17273446917533875\n",
      "Epoch [3/3], Batch [107/2500], Loss: 0.047048475593328476\n",
      "Epoch [3/3], Batch [108/2500], Loss: 0.09441234171390533\n",
      "Epoch [3/3], Batch [109/2500], Loss: 0.1739639937877655\n",
      "Epoch [3/3], Batch [110/2500], Loss: 0.17586639523506165\n",
      "Epoch [3/3], Batch [111/2500], Loss: 0.1704816371202469\n",
      "Epoch [3/3], Batch [112/2500], Loss: 0.31486716866493225\n",
      "Epoch [3/3], Batch [113/2500], Loss: 0.17103657126426697\n",
      "Epoch [3/3], Batch [114/2500], Loss: 0.44423919916152954\n",
      "Epoch [3/3], Batch [115/2500], Loss: 0.20877012610435486\n",
      "Epoch [3/3], Batch [116/2500], Loss: 0.12157484889030457\n",
      "Epoch [3/3], Batch [117/2500], Loss: 0.12558937072753906\n",
      "Epoch [3/3], Batch [118/2500], Loss: 0.35830485820770264\n",
      "Epoch [3/3], Batch [119/2500], Loss: 0.03649517893791199\n",
      "Epoch [3/3], Batch [120/2500], Loss: 0.17015942931175232\n",
      "Epoch [3/3], Batch [121/2500], Loss: 0.15448583662509918\n",
      "Epoch [3/3], Batch [122/2500], Loss: 0.17734378576278687\n",
      "Epoch [3/3], Batch [123/2500], Loss: 0.20732896029949188\n",
      "Epoch [3/3], Batch [124/2500], Loss: 0.02779967710375786\n",
      "Epoch [3/3], Batch [125/2500], Loss: 0.27720457315444946\n",
      "Epoch [3/3], Batch [126/2500], Loss: 0.12211941182613373\n",
      "Epoch [3/3], Batch [127/2500], Loss: 0.09674528241157532\n",
      "Epoch [3/3], Batch [128/2500], Loss: 0.16446200013160706\n",
      "Epoch [3/3], Batch [129/2500], Loss: 0.18983906507492065\n",
      "Epoch [3/3], Batch [130/2500], Loss: 0.4056372046470642\n",
      "Epoch [3/3], Batch [131/2500], Loss: 0.18214569985866547\n",
      "Epoch [3/3], Batch [132/2500], Loss: 0.11955083906650543\n",
      "Epoch [3/3], Batch [133/2500], Loss: 0.09146628528833389\n",
      "Epoch [3/3], Batch [134/2500], Loss: 0.05601324886083603\n",
      "Epoch [3/3], Batch [135/2500], Loss: 0.041350170969963074\n",
      "Epoch [3/3], Batch [136/2500], Loss: 0.310570627450943\n",
      "Epoch [3/3], Batch [137/2500], Loss: 0.13771815598011017\n",
      "Epoch [3/3], Batch [138/2500], Loss: 0.16662326455116272\n",
      "Epoch [3/3], Batch [139/2500], Loss: 0.15663573145866394\n",
      "Epoch [3/3], Batch [140/2500], Loss: 0.2507873475551605\n",
      "Epoch [3/3], Batch [141/2500], Loss: 0.2654079496860504\n",
      "Epoch [3/3], Batch [142/2500], Loss: 0.28177422285079956\n",
      "Epoch [3/3], Batch [143/2500], Loss: 0.12720385193824768\n",
      "Epoch [3/3], Batch [144/2500], Loss: 0.06572277843952179\n",
      "Epoch [3/3], Batch [145/2500], Loss: 0.23559269309043884\n",
      "Epoch [3/3], Batch [146/2500], Loss: 0.07919294387102127\n",
      "Epoch [3/3], Batch [147/2500], Loss: 0.11668794602155685\n",
      "Epoch [3/3], Batch [148/2500], Loss: 0.12640541791915894\n",
      "Epoch [3/3], Batch [149/2500], Loss: 0.18371059000492096\n",
      "Epoch [3/3], Batch [150/2500], Loss: 0.4370058476924896\n",
      "Epoch [3/3], Batch [151/2500], Loss: 0.21756215393543243\n",
      "Epoch [3/3], Batch [152/2500], Loss: 0.02830331213772297\n",
      "Epoch [3/3], Batch [153/2500], Loss: 0.052810296416282654\n",
      "Epoch [3/3], Batch [154/2500], Loss: 0.1953418254852295\n",
      "Epoch [3/3], Batch [155/2500], Loss: 0.30167239904403687\n",
      "Epoch [3/3], Batch [156/2500], Loss: 0.03810600936412811\n",
      "Epoch [3/3], Batch [157/2500], Loss: 0.05332190543413162\n",
      "Epoch [3/3], Batch [158/2500], Loss: 0.10921234637498856\n",
      "Epoch [3/3], Batch [159/2500], Loss: 0.05799764394760132\n",
      "Epoch [3/3], Batch [160/2500], Loss: 0.3218849301338196\n",
      "Epoch [3/3], Batch [161/2500], Loss: 0.06900870054960251\n",
      "Epoch [3/3], Batch [162/2500], Loss: 0.12045291066169739\n",
      "Epoch [3/3], Batch [163/2500], Loss: 0.2107577621936798\n",
      "Epoch [3/3], Batch [164/2500], Loss: 0.4115806221961975\n",
      "Epoch [3/3], Batch [165/2500], Loss: 0.06998179107904434\n",
      "Epoch [3/3], Batch [166/2500], Loss: 0.03210726007819176\n",
      "Epoch [3/3], Batch [167/2500], Loss: 0.10221855342388153\n",
      "Epoch [3/3], Batch [168/2500], Loss: 0.15251299738883972\n",
      "Epoch [3/3], Batch [169/2500], Loss: 0.26384949684143066\n",
      "Epoch [3/3], Batch [170/2500], Loss: 0.10169617831707001\n",
      "Epoch [3/3], Batch [171/2500], Loss: 0.110056072473526\n",
      "Epoch [3/3], Batch [172/2500], Loss: 0.29773080348968506\n",
      "Epoch [3/3], Batch [173/2500], Loss: 0.2571953535079956\n",
      "Epoch [3/3], Batch [174/2500], Loss: 0.03142521157860756\n",
      "Epoch [3/3], Batch [175/2500], Loss: 0.07626471668481827\n",
      "Epoch [3/3], Batch [176/2500], Loss: 0.16662639379501343\n",
      "Epoch [3/3], Batch [177/2500], Loss: 0.10213416814804077\n",
      "Epoch [3/3], Batch [178/2500], Loss: 0.24696145951747894\n",
      "Epoch [3/3], Batch [179/2500], Loss: 0.19194242358207703\n",
      "Epoch [3/3], Batch [180/2500], Loss: 0.049156833440065384\n",
      "Epoch [3/3], Batch [181/2500], Loss: 0.09195810556411743\n",
      "Epoch [3/3], Batch [182/2500], Loss: 0.012805326841771603\n",
      "Epoch [3/3], Batch [183/2500], Loss: 0.1065351590514183\n",
      "Epoch [3/3], Batch [184/2500], Loss: 0.11444103717803955\n",
      "Epoch [3/3], Batch [185/2500], Loss: 0.014609090983867645\n",
      "Epoch [3/3], Batch [186/2500], Loss: 0.0694730207324028\n",
      "Epoch [3/3], Batch [187/2500], Loss: 0.2062322497367859\n",
      "Epoch [3/3], Batch [188/2500], Loss: 0.11582569777965546\n",
      "Epoch [3/3], Batch [189/2500], Loss: 0.3295845091342926\n",
      "Epoch [3/3], Batch [190/2500], Loss: 0.22897684574127197\n",
      "Epoch [3/3], Batch [191/2500], Loss: 0.08492067456245422\n",
      "Epoch [3/3], Batch [192/2500], Loss: 0.03241798281669617\n",
      "Epoch [3/3], Batch [193/2500], Loss: 0.06163457781076431\n",
      "Epoch [3/3], Batch [194/2500], Loss: 0.21940554678440094\n",
      "Epoch [3/3], Batch [195/2500], Loss: 0.13599556684494019\n",
      "Epoch [3/3], Batch [196/2500], Loss: 0.11126188188791275\n",
      "Epoch [3/3], Batch [197/2500], Loss: 0.4481750428676605\n",
      "Epoch [3/3], Batch [198/2500], Loss: 0.24502116441726685\n",
      "Epoch [3/3], Batch [199/2500], Loss: 0.23817689716815948\n",
      "Epoch [3/3], Batch [200/2500], Loss: 0.13796642422676086\n",
      "Epoch [3/3], Batch [201/2500], Loss: 0.21621999144554138\n",
      "Epoch [3/3], Batch [202/2500], Loss: 0.3426287770271301\n",
      "Epoch [3/3], Batch [203/2500], Loss: 0.07205455750226974\n",
      "Epoch [3/3], Batch [204/2500], Loss: 0.060237474739551544\n",
      "Epoch [3/3], Batch [205/2500], Loss: 0.056145016103982925\n",
      "Epoch [3/3], Batch [206/2500], Loss: 0.05628294497728348\n",
      "Epoch [3/3], Batch [207/2500], Loss: 0.048038363456726074\n",
      "Epoch [3/3], Batch [208/2500], Loss: 0.24990656971931458\n",
      "Epoch [3/3], Batch [209/2500], Loss: 0.05044969171285629\n",
      "Epoch [3/3], Batch [210/2500], Loss: 0.046995267271995544\n",
      "Epoch [3/3], Batch [211/2500], Loss: 0.23604804277420044\n",
      "Epoch [3/3], Batch [212/2500], Loss: 0.06642680615186691\n",
      "Epoch [3/3], Batch [213/2500], Loss: 0.014211795292794704\n",
      "Epoch [3/3], Batch [214/2500], Loss: 0.08727588504552841\n",
      "Epoch [3/3], Batch [215/2500], Loss: 0.21367304027080536\n",
      "Epoch [3/3], Batch [216/2500], Loss: 0.11548521369695663\n",
      "Epoch [3/3], Batch [217/2500], Loss: 0.4562355875968933\n",
      "Epoch [3/3], Batch [218/2500], Loss: 0.03800535947084427\n",
      "Epoch [3/3], Batch [219/2500], Loss: 0.04680607467889786\n",
      "Epoch [3/3], Batch [220/2500], Loss: 0.32711294293403625\n",
      "Epoch [3/3], Batch [221/2500], Loss: 0.31840330362319946\n",
      "Epoch [3/3], Batch [222/2500], Loss: 0.21158738434314728\n",
      "Epoch [3/3], Batch [223/2500], Loss: 0.11602778732776642\n",
      "Epoch [3/3], Batch [224/2500], Loss: 0.23781757056713104\n",
      "Epoch [3/3], Batch [225/2500], Loss: 0.10414397716522217\n",
      "Epoch [3/3], Batch [226/2500], Loss: 0.10684105008840561\n",
      "Epoch [3/3], Batch [227/2500], Loss: 0.03567209467291832\n",
      "Epoch [3/3], Batch [228/2500], Loss: 0.03924354165792465\n",
      "Epoch [3/3], Batch [229/2500], Loss: 0.281393438577652\n",
      "Epoch [3/3], Batch [230/2500], Loss: 0.027758557349443436\n",
      "Epoch [3/3], Batch [231/2500], Loss: 0.09242470562458038\n",
      "Epoch [3/3], Batch [232/2500], Loss: 0.12814360857009888\n",
      "Epoch [3/3], Batch [233/2500], Loss: 0.09462796896696091\n",
      "Epoch [3/3], Batch [234/2500], Loss: 0.04022860527038574\n",
      "Epoch [3/3], Batch [235/2500], Loss: 0.2941712439060211\n",
      "Epoch [3/3], Batch [236/2500], Loss: 0.2917727530002594\n",
      "Epoch [3/3], Batch [237/2500], Loss: 0.048395201563835144\n",
      "Epoch [3/3], Batch [238/2500], Loss: 0.09447475522756577\n",
      "Epoch [3/3], Batch [239/2500], Loss: 0.013487915508449078\n",
      "Epoch [3/3], Batch [240/2500], Loss: 0.2866053283214569\n",
      "Epoch [3/3], Batch [241/2500], Loss: 0.013626293279230595\n",
      "Epoch [3/3], Batch [242/2500], Loss: 0.08403228968381882\n",
      "Epoch [3/3], Batch [243/2500], Loss: 0.14776232838630676\n",
      "Epoch [3/3], Batch [244/2500], Loss: 0.5565606951713562\n",
      "Epoch [3/3], Batch [245/2500], Loss: 0.16526862978935242\n",
      "Epoch [3/3], Batch [246/2500], Loss: 0.3717063367366791\n",
      "Epoch [3/3], Batch [247/2500], Loss: 0.32496699690818787\n",
      "Epoch [3/3], Batch [248/2500], Loss: 0.2490481585264206\n",
      "Epoch [3/3], Batch [249/2500], Loss: 0.06267210096120834\n",
      "Epoch [3/3], Batch [250/2500], Loss: 0.08308213949203491\n",
      "Epoch [3/3], Batch [251/2500], Loss: 0.44497784972190857\n",
      "Epoch [3/3], Batch [252/2500], Loss: 0.19062387943267822\n",
      "Epoch [3/3], Batch [253/2500], Loss: 0.08875392377376556\n",
      "Epoch [3/3], Batch [254/2500], Loss: 0.15726831555366516\n",
      "Epoch [3/3], Batch [255/2500], Loss: 0.08195969462394714\n",
      "Epoch [3/3], Batch [256/2500], Loss: 0.14359743893146515\n",
      "Epoch [3/3], Batch [257/2500], Loss: 0.19879455864429474\n",
      "Epoch [3/3], Batch [258/2500], Loss: 0.24303875863552094\n",
      "Epoch [3/3], Batch [259/2500], Loss: 0.216008722782135\n",
      "Epoch [3/3], Batch [260/2500], Loss: 0.09589175879955292\n",
      "Epoch [3/3], Batch [261/2500], Loss: 0.1745690554380417\n",
      "Epoch [3/3], Batch [262/2500], Loss: 0.29216527938842773\n",
      "Epoch [3/3], Batch [263/2500], Loss: 0.15691393613815308\n",
      "Epoch [3/3], Batch [264/2500], Loss: 0.010852362960577011\n",
      "Epoch [3/3], Batch [265/2500], Loss: 0.0785345584154129\n",
      "Epoch [3/3], Batch [266/2500], Loss: 0.03461964428424835\n",
      "Epoch [3/3], Batch [267/2500], Loss: 0.08323043584823608\n",
      "Epoch [3/3], Batch [268/2500], Loss: 0.21528948843479156\n",
      "Epoch [3/3], Batch [269/2500], Loss: 0.17589806020259857\n",
      "Epoch [3/3], Batch [270/2500], Loss: 0.2083873599767685\n",
      "Epoch [3/3], Batch [271/2500], Loss: 0.08693359047174454\n",
      "Epoch [3/3], Batch [272/2500], Loss: 0.09967857599258423\n",
      "Epoch [3/3], Batch [273/2500], Loss: 0.2566608786582947\n",
      "Epoch [3/3], Batch [274/2500], Loss: 0.03663678839802742\n",
      "Epoch [3/3], Batch [275/2500], Loss: 0.07137198746204376\n",
      "Epoch [3/3], Batch [276/2500], Loss: 0.2143893539905548\n",
      "Epoch [3/3], Batch [277/2500], Loss: 0.014856839552521706\n",
      "Epoch [3/3], Batch [278/2500], Loss: 0.062474414706230164\n",
      "Epoch [3/3], Batch [279/2500], Loss: 1.0284138917922974\n",
      "Epoch [3/3], Batch [280/2500], Loss: 0.26828745007514954\n",
      "Epoch [3/3], Batch [281/2500], Loss: 0.1761808693408966\n",
      "Epoch [3/3], Batch [282/2500], Loss: 0.37256771326065063\n",
      "Epoch [3/3], Batch [283/2500], Loss: 0.03934084624052048\n",
      "Epoch [3/3], Batch [284/2500], Loss: 0.687431275844574\n",
      "Epoch [3/3], Batch [285/2500], Loss: 0.1700471192598343\n",
      "Epoch [3/3], Batch [286/2500], Loss: 0.08890552073717117\n",
      "Epoch [3/3], Batch [287/2500], Loss: 0.06240849941968918\n",
      "Epoch [3/3], Batch [288/2500], Loss: 0.5117070078849792\n",
      "Epoch [3/3], Batch [289/2500], Loss: 0.04834694415330887\n",
      "Epoch [3/3], Batch [290/2500], Loss: 0.0902930498123169\n",
      "Epoch [3/3], Batch [291/2500], Loss: 0.5690848231315613\n",
      "Epoch [3/3], Batch [292/2500], Loss: 0.12953776121139526\n",
      "Epoch [3/3], Batch [293/2500], Loss: 0.42266330122947693\n",
      "Epoch [3/3], Batch [294/2500], Loss: 0.07956007122993469\n",
      "Epoch [3/3], Batch [295/2500], Loss: 0.03509971499443054\n",
      "Epoch [3/3], Batch [296/2500], Loss: 0.26416441798210144\n",
      "Epoch [3/3], Batch [297/2500], Loss: 0.11636508256196976\n",
      "Epoch [3/3], Batch [298/2500], Loss: 0.18048374354839325\n",
      "Epoch [3/3], Batch [299/2500], Loss: 0.11252691596746445\n",
      "Epoch [3/3], Batch [300/2500], Loss: 0.13468565046787262\n",
      "Epoch [3/3], Batch [301/2500], Loss: 0.1391664445400238\n",
      "Epoch [3/3], Batch [302/2500], Loss: 0.3285910487174988\n",
      "Epoch [3/3], Batch [303/2500], Loss: 0.35483992099761963\n",
      "Epoch [3/3], Batch [304/2500], Loss: 0.11029721051454544\n",
      "Epoch [3/3], Batch [305/2500], Loss: 0.13607238233089447\n",
      "Epoch [3/3], Batch [306/2500], Loss: 0.30761194229125977\n",
      "Epoch [3/3], Batch [307/2500], Loss: 0.09428609907627106\n",
      "Epoch [3/3], Batch [308/2500], Loss: 0.19052571058273315\n",
      "Epoch [3/3], Batch [309/2500], Loss: 0.24422702193260193\n",
      "Epoch [3/3], Batch [310/2500], Loss: 0.34156477451324463\n",
      "Epoch [3/3], Batch [311/2500], Loss: 0.20514938235282898\n",
      "Epoch [3/3], Batch [312/2500], Loss: 0.07891138643026352\n",
      "Epoch [3/3], Batch [313/2500], Loss: 0.13495081663131714\n",
      "Epoch [3/3], Batch [314/2500], Loss: 0.2273114174604416\n",
      "Epoch [3/3], Batch [315/2500], Loss: 0.07453691214323044\n",
      "Epoch [3/3], Batch [316/2500], Loss: 0.13965663313865662\n",
      "Epoch [3/3], Batch [317/2500], Loss: 0.09657175093889236\n",
      "Epoch [3/3], Batch [318/2500], Loss: 0.2711711525917053\n",
      "Epoch [3/3], Batch [319/2500], Loss: 0.08788461983203888\n",
      "Epoch [3/3], Batch [320/2500], Loss: 0.36177298426628113\n",
      "Epoch [3/3], Batch [321/2500], Loss: 0.25794997811317444\n",
      "Epoch [3/3], Batch [322/2500], Loss: 0.23231081664562225\n",
      "Epoch [3/3], Batch [323/2500], Loss: 0.22835499048233032\n",
      "Epoch [3/3], Batch [324/2500], Loss: 0.05766668915748596\n",
      "Epoch [3/3], Batch [325/2500], Loss: 0.36991140246391296\n",
      "Epoch [3/3], Batch [326/2500], Loss: 0.06822691112756729\n",
      "Epoch [3/3], Batch [327/2500], Loss: 0.09539570659399033\n",
      "Epoch [3/3], Batch [328/2500], Loss: 0.03534300625324249\n",
      "Epoch [3/3], Batch [329/2500], Loss: 0.2393476665019989\n",
      "Epoch [3/3], Batch [330/2500], Loss: 0.018583282828330994\n",
      "Epoch [3/3], Batch [331/2500], Loss: 0.1920662373304367\n",
      "Epoch [3/3], Batch [332/2500], Loss: 0.2080352008342743\n",
      "Epoch [3/3], Batch [333/2500], Loss: 0.2788126766681671\n",
      "Epoch [3/3], Batch [334/2500], Loss: 0.24562497437000275\n",
      "Epoch [3/3], Batch [335/2500], Loss: 0.5520736575126648\n",
      "Epoch [3/3], Batch [336/2500], Loss: 0.12216059118509293\n",
      "Epoch [3/3], Batch [337/2500], Loss: 0.2540118992328644\n",
      "Epoch [3/3], Batch [338/2500], Loss: 0.1052551344037056\n",
      "Epoch [3/3], Batch [339/2500], Loss: 0.3281174600124359\n",
      "Epoch [3/3], Batch [340/2500], Loss: 0.8639881014823914\n",
      "Epoch [3/3], Batch [341/2500], Loss: 0.2508823573589325\n",
      "Epoch [3/3], Batch [342/2500], Loss: 0.11199933290481567\n",
      "Epoch [3/3], Batch [343/2500], Loss: 0.10477755218744278\n",
      "Epoch [3/3], Batch [344/2500], Loss: 0.013377569615840912\n",
      "Epoch [3/3], Batch [345/2500], Loss: 0.1708320677280426\n",
      "Epoch [3/3], Batch [346/2500], Loss: 0.3842698931694031\n",
      "Epoch [3/3], Batch [347/2500], Loss: 0.15240585803985596\n",
      "Epoch [3/3], Batch [348/2500], Loss: 0.2405780851840973\n",
      "Epoch [3/3], Batch [349/2500], Loss: 0.06162048876285553\n",
      "Epoch [3/3], Batch [350/2500], Loss: 0.08055749535560608\n",
      "Epoch [3/3], Batch [351/2500], Loss: 0.15676555037498474\n",
      "Epoch [3/3], Batch [352/2500], Loss: 0.4332968294620514\n",
      "Epoch [3/3], Batch [353/2500], Loss: 0.45974382758140564\n",
      "Epoch [3/3], Batch [354/2500], Loss: 0.0898033082485199\n",
      "Epoch [3/3], Batch [355/2500], Loss: 0.2962304353713989\n",
      "Epoch [3/3], Batch [356/2500], Loss: 0.0346636101603508\n",
      "Epoch [3/3], Batch [357/2500], Loss: 0.14923717081546783\n",
      "Epoch [3/3], Batch [358/2500], Loss: 0.0554996132850647\n",
      "Epoch [3/3], Batch [359/2500], Loss: 0.10802330821752548\n",
      "Epoch [3/3], Batch [360/2500], Loss: 0.09808522462844849\n",
      "Epoch [3/3], Batch [361/2500], Loss: 0.02295055240392685\n",
      "Epoch [3/3], Batch [362/2500], Loss: 0.5208477973937988\n",
      "Epoch [3/3], Batch [363/2500], Loss: 0.1259334683418274\n",
      "Epoch [3/3], Batch [364/2500], Loss: 0.1593368798494339\n",
      "Epoch [3/3], Batch [365/2500], Loss: 0.15644194185733795\n",
      "Epoch [3/3], Batch [366/2500], Loss: 0.08047475665807724\n",
      "Epoch [3/3], Batch [367/2500], Loss: 0.060688041150569916\n",
      "Epoch [3/3], Batch [368/2500], Loss: 0.15664438903331757\n",
      "Epoch [3/3], Batch [369/2500], Loss: 0.21760977804660797\n",
      "Epoch [3/3], Batch [370/2500], Loss: 0.08145850151777267\n",
      "Epoch [3/3], Batch [371/2500], Loss: 0.1943836361169815\n",
      "Epoch [3/3], Batch [372/2500], Loss: 0.20222125947475433\n",
      "Epoch [3/3], Batch [373/2500], Loss: 0.21679185330867767\n",
      "Epoch [3/3], Batch [374/2500], Loss: 0.028856178745627403\n",
      "Epoch [3/3], Batch [375/2500], Loss: 0.27379730343818665\n",
      "Epoch [3/3], Batch [376/2500], Loss: 0.23167835175991058\n",
      "Epoch [3/3], Batch [377/2500], Loss: 0.09128376841545105\n",
      "Epoch [3/3], Batch [378/2500], Loss: 0.34611979126930237\n",
      "Epoch [3/3], Batch [379/2500], Loss: 0.14317287504673004\n",
      "Epoch [3/3], Batch [380/2500], Loss: 0.05018673464655876\n",
      "Epoch [3/3], Batch [381/2500], Loss: 0.1065802052617073\n",
      "Epoch [3/3], Batch [382/2500], Loss: 0.14522825181484222\n",
      "Epoch [3/3], Batch [383/2500], Loss: 0.029899565503001213\n",
      "Epoch [3/3], Batch [384/2500], Loss: 0.08786226809024811\n",
      "Epoch [3/3], Batch [385/2500], Loss: 0.22297883033752441\n",
      "Epoch [3/3], Batch [386/2500], Loss: 0.29654979705810547\n",
      "Epoch [3/3], Batch [387/2500], Loss: 0.09405231475830078\n",
      "Epoch [3/3], Batch [388/2500], Loss: 0.15627199411392212\n",
      "Epoch [3/3], Batch [389/2500], Loss: 0.016482718288898468\n",
      "Epoch [3/3], Batch [390/2500], Loss: 0.128685861825943\n",
      "Epoch [3/3], Batch [391/2500], Loss: 0.15119121968746185\n",
      "Epoch [3/3], Batch [392/2500], Loss: 0.14782047271728516\n",
      "Epoch [3/3], Batch [393/2500], Loss: 0.22636178135871887\n",
      "Epoch [3/3], Batch [394/2500], Loss: 0.12430374324321747\n",
      "Epoch [3/3], Batch [395/2500], Loss: 0.13130642473697662\n",
      "Epoch [3/3], Batch [396/2500], Loss: 0.020394308492541313\n",
      "Epoch [3/3], Batch [397/2500], Loss: 0.19160622358322144\n",
      "Epoch [3/3], Batch [398/2500], Loss: 0.1664176732301712\n",
      "Epoch [3/3], Batch [399/2500], Loss: 0.19332033395767212\n",
      "Epoch [3/3], Batch [400/2500], Loss: 0.16944536566734314\n",
      "Epoch [3/3], Batch [401/2500], Loss: 0.08973871171474457\n",
      "Epoch [3/3], Batch [402/2500], Loss: 0.23293547332286835\n",
      "Epoch [3/3], Batch [403/2500], Loss: 0.06433984637260437\n",
      "Epoch [3/3], Batch [404/2500], Loss: 0.13669613003730774\n",
      "Epoch [3/3], Batch [405/2500], Loss: 0.016205810010433197\n",
      "Epoch [3/3], Batch [406/2500], Loss: 0.022806407883763313\n",
      "Epoch [3/3], Batch [407/2500], Loss: 0.3202870488166809\n",
      "Epoch [3/3], Batch [408/2500], Loss: 0.05664997547864914\n",
      "Epoch [3/3], Batch [409/2500], Loss: 0.1551392823457718\n",
      "Epoch [3/3], Batch [410/2500], Loss: 0.030737200751900673\n",
      "Epoch [3/3], Batch [411/2500], Loss: 0.06801284104585648\n",
      "Epoch [3/3], Batch [412/2500], Loss: 0.2345462143421173\n",
      "Epoch [3/3], Batch [413/2500], Loss: 0.06481954455375671\n",
      "Epoch [3/3], Batch [414/2500], Loss: 0.026968326419591904\n",
      "Epoch [3/3], Batch [415/2500], Loss: 0.08642452210187912\n",
      "Epoch [3/3], Batch [416/2500], Loss: 0.07523119449615479\n",
      "Epoch [3/3], Batch [417/2500], Loss: 0.08209799975156784\n",
      "Epoch [3/3], Batch [418/2500], Loss: 0.09945245087146759\n",
      "Epoch [3/3], Batch [419/2500], Loss: 0.35601523518562317\n",
      "Epoch [3/3], Batch [420/2500], Loss: 0.12927287817001343\n",
      "Epoch [3/3], Batch [421/2500], Loss: 0.05161546915769577\n",
      "Epoch [3/3], Batch [422/2500], Loss: 0.36014097929000854\n",
      "Epoch [3/3], Batch [423/2500], Loss: 0.06535087525844574\n",
      "Epoch [3/3], Batch [424/2500], Loss: 0.01817111112177372\n",
      "Epoch [3/3], Batch [425/2500], Loss: 0.018638040870428085\n",
      "Epoch [3/3], Batch [426/2500], Loss: 0.34649214148521423\n",
      "Epoch [3/3], Batch [427/2500], Loss: 0.32209667563438416\n",
      "Epoch [3/3], Batch [428/2500], Loss: 0.0229423176497221\n",
      "Epoch [3/3], Batch [429/2500], Loss: 0.2679196000099182\n",
      "Epoch [3/3], Batch [430/2500], Loss: 0.40630730986595154\n",
      "Epoch [3/3], Batch [431/2500], Loss: 0.2795701026916504\n",
      "Epoch [3/3], Batch [432/2500], Loss: 0.026403803378343582\n",
      "Epoch [3/3], Batch [433/2500], Loss: 0.026099666953086853\n",
      "Epoch [3/3], Batch [434/2500], Loss: 0.3064485490322113\n",
      "Epoch [3/3], Batch [435/2500], Loss: 0.2913036644458771\n",
      "Epoch [3/3], Batch [436/2500], Loss: 0.08432038128376007\n",
      "Epoch [3/3], Batch [437/2500], Loss: 0.3293708860874176\n",
      "Epoch [3/3], Batch [438/2500], Loss: 0.07037343829870224\n",
      "Epoch [3/3], Batch [439/2500], Loss: 0.13146927952766418\n",
      "Epoch [3/3], Batch [440/2500], Loss: 0.07529406994581223\n",
      "Epoch [3/3], Batch [441/2500], Loss: 0.14851880073547363\n",
      "Epoch [3/3], Batch [442/2500], Loss: 0.02191556617617607\n",
      "Epoch [3/3], Batch [443/2500], Loss: 0.09947860985994339\n",
      "Epoch [3/3], Batch [444/2500], Loss: 0.05105924606323242\n",
      "Epoch [3/3], Batch [445/2500], Loss: 0.04028373956680298\n",
      "Epoch [3/3], Batch [446/2500], Loss: 0.22085890173912048\n",
      "Epoch [3/3], Batch [447/2500], Loss: 0.20330362021923065\n",
      "Epoch [3/3], Batch [448/2500], Loss: 0.18460795283317566\n",
      "Epoch [3/3], Batch [449/2500], Loss: 0.2804602384567261\n",
      "Epoch [3/3], Batch [450/2500], Loss: 0.11883033066987991\n",
      "Epoch [3/3], Batch [451/2500], Loss: 0.12652330100536346\n",
      "Epoch [3/3], Batch [452/2500], Loss: 0.11346124857664108\n",
      "Epoch [3/3], Batch [453/2500], Loss: 0.15629491209983826\n",
      "Epoch [3/3], Batch [454/2500], Loss: 0.16968697309494019\n",
      "Epoch [3/3], Batch [455/2500], Loss: 0.1853453814983368\n",
      "Epoch [3/3], Batch [456/2500], Loss: 0.29882872104644775\n",
      "Epoch [3/3], Batch [457/2500], Loss: 0.669013261795044\n",
      "Epoch [3/3], Batch [458/2500], Loss: 0.16093683242797852\n",
      "Epoch [3/3], Batch [459/2500], Loss: 0.020262133330106735\n",
      "Epoch [3/3], Batch [460/2500], Loss: 0.35970738530158997\n",
      "Epoch [3/3], Batch [461/2500], Loss: 0.1436730921268463\n",
      "Epoch [3/3], Batch [462/2500], Loss: 0.0245522353798151\n",
      "Epoch [3/3], Batch [463/2500], Loss: 0.10045680403709412\n",
      "Epoch [3/3], Batch [464/2500], Loss: 0.03185413032770157\n",
      "Epoch [3/3], Batch [465/2500], Loss: 0.173438161611557\n",
      "Epoch [3/3], Batch [466/2500], Loss: 0.18576151132583618\n",
      "Epoch [3/3], Batch [467/2500], Loss: 0.3966464400291443\n",
      "Epoch [3/3], Batch [468/2500], Loss: 0.08379878848791122\n",
      "Epoch [3/3], Batch [469/2500], Loss: 0.12193853408098221\n",
      "Epoch [3/3], Batch [470/2500], Loss: 0.75484299659729\n",
      "Epoch [3/3], Batch [471/2500], Loss: 0.28427690267562866\n",
      "Epoch [3/3], Batch [472/2500], Loss: 0.14897334575653076\n",
      "Epoch [3/3], Batch [473/2500], Loss: 0.3254534602165222\n",
      "Epoch [3/3], Batch [474/2500], Loss: 0.06440120935440063\n",
      "Epoch [3/3], Batch [475/2500], Loss: 0.17300869524478912\n",
      "Epoch [3/3], Batch [476/2500], Loss: 0.4480831027030945\n",
      "Epoch [3/3], Batch [477/2500], Loss: 0.043471381068229675\n",
      "Epoch [3/3], Batch [478/2500], Loss: 0.09204253554344177\n",
      "Epoch [3/3], Batch [479/2500], Loss: 0.08838044106960297\n",
      "Epoch [3/3], Batch [480/2500], Loss: 0.4641467332839966\n",
      "Epoch [3/3], Batch [481/2500], Loss: 0.34766921401023865\n",
      "Epoch [3/3], Batch [482/2500], Loss: 0.13899441063404083\n",
      "Epoch [3/3], Batch [483/2500], Loss: 0.09657850116491318\n",
      "Epoch [3/3], Batch [484/2500], Loss: 0.26727408170700073\n",
      "Epoch [3/3], Batch [485/2500], Loss: 0.03784496337175369\n",
      "Epoch [3/3], Batch [486/2500], Loss: 0.4979408383369446\n",
      "Epoch [3/3], Batch [487/2500], Loss: 0.0709250271320343\n",
      "Epoch [3/3], Batch [488/2500], Loss: 0.12271028757095337\n",
      "Epoch [3/3], Batch [489/2500], Loss: 0.16011959314346313\n",
      "Epoch [3/3], Batch [490/2500], Loss: 0.14119596779346466\n",
      "Epoch [3/3], Batch [491/2500], Loss: 0.23254208266735077\n",
      "Epoch [3/3], Batch [492/2500], Loss: 0.18056577444076538\n",
      "Epoch [3/3], Batch [493/2500], Loss: 0.05126553028821945\n",
      "Epoch [3/3], Batch [494/2500], Loss: 0.2283753603696823\n",
      "Epoch [3/3], Batch [495/2500], Loss: 0.39981019496917725\n",
      "Epoch [3/3], Batch [496/2500], Loss: 0.331106036901474\n",
      "Epoch [3/3], Batch [497/2500], Loss: 0.19305218756198883\n",
      "Epoch [3/3], Batch [498/2500], Loss: 0.24378128349781036\n",
      "Epoch [3/3], Batch [499/2500], Loss: 0.04568212479352951\n",
      "Epoch [3/3], Batch [500/2500], Loss: 0.2566748857498169\n",
      "Epoch [3/3], Batch [501/2500], Loss: 0.17139992117881775\n",
      "Epoch [3/3], Batch [502/2500], Loss: 0.10495105385780334\n",
      "Epoch [3/3], Batch [503/2500], Loss: 0.09161212295293808\n",
      "Epoch [3/3], Batch [504/2500], Loss: 0.04600316658616066\n",
      "Epoch [3/3], Batch [505/2500], Loss: 0.179205060005188\n",
      "Epoch [3/3], Batch [506/2500], Loss: 0.12694507837295532\n",
      "Epoch [3/3], Batch [507/2500], Loss: 0.14700302481651306\n",
      "Epoch [3/3], Batch [508/2500], Loss: 0.0773308202624321\n",
      "Epoch [3/3], Batch [509/2500], Loss: 0.10791569203138351\n",
      "Epoch [3/3], Batch [510/2500], Loss: 0.08551119267940521\n",
      "Epoch [3/3], Batch [511/2500], Loss: 0.1132766380906105\n",
      "Epoch [3/3], Batch [512/2500], Loss: 0.11863932013511658\n",
      "Epoch [3/3], Batch [513/2500], Loss: 0.35522979497909546\n",
      "Epoch [3/3], Batch [514/2500], Loss: 0.042996011674404144\n",
      "Epoch [3/3], Batch [515/2500], Loss: 0.36492130160331726\n",
      "Epoch [3/3], Batch [516/2500], Loss: 0.17035602033138275\n",
      "Epoch [3/3], Batch [517/2500], Loss: 0.20521940290927887\n",
      "Epoch [3/3], Batch [518/2500], Loss: 0.08026409149169922\n",
      "Epoch [3/3], Batch [519/2500], Loss: 0.11223090440034866\n",
      "Epoch [3/3], Batch [520/2500], Loss: 0.04743017256259918\n",
      "Epoch [3/3], Batch [521/2500], Loss: 0.10696326941251755\n",
      "Epoch [3/3], Batch [522/2500], Loss: 0.06679396331310272\n",
      "Epoch [3/3], Batch [523/2500], Loss: 0.07272299379110336\n",
      "Epoch [3/3], Batch [524/2500], Loss: 0.10024286061525345\n",
      "Epoch [3/3], Batch [525/2500], Loss: 0.4588854908943176\n",
      "Epoch [3/3], Batch [526/2500], Loss: 0.0875077173113823\n",
      "Epoch [3/3], Batch [527/2500], Loss: 0.10867050290107727\n",
      "Epoch [3/3], Batch [528/2500], Loss: 0.18038618564605713\n",
      "Epoch [3/3], Batch [529/2500], Loss: 0.10436321794986725\n",
      "Epoch [3/3], Batch [530/2500], Loss: 0.1984117478132248\n",
      "Epoch [3/3], Batch [531/2500], Loss: 0.24377723038196564\n",
      "Epoch [3/3], Batch [532/2500], Loss: 0.09406496584415436\n",
      "Epoch [3/3], Batch [533/2500], Loss: 0.03960806131362915\n",
      "Epoch [3/3], Batch [534/2500], Loss: 0.23264136910438538\n",
      "Epoch [3/3], Batch [535/2500], Loss: 0.0689571425318718\n",
      "Epoch [3/3], Batch [536/2500], Loss: 0.02032548002898693\n",
      "Epoch [3/3], Batch [537/2500], Loss: 0.19966885447502136\n",
      "Epoch [3/3], Batch [538/2500], Loss: 0.17871332168579102\n",
      "Epoch [3/3], Batch [539/2500], Loss: 0.13857640326023102\n",
      "Epoch [3/3], Batch [540/2500], Loss: 0.17676234245300293\n",
      "Epoch [3/3], Batch [541/2500], Loss: 0.03794362023472786\n",
      "Epoch [3/3], Batch [542/2500], Loss: 0.3671610355377197\n",
      "Epoch [3/3], Batch [543/2500], Loss: 0.07281287014484406\n",
      "Epoch [3/3], Batch [544/2500], Loss: 0.3945751488208771\n",
      "Epoch [3/3], Batch [545/2500], Loss: 0.1931816041469574\n",
      "Epoch [3/3], Batch [546/2500], Loss: 0.07053019106388092\n",
      "Epoch [3/3], Batch [547/2500], Loss: 0.021374378353357315\n",
      "Epoch [3/3], Batch [548/2500], Loss: 0.2494802176952362\n",
      "Epoch [3/3], Batch [549/2500], Loss: 0.0741569995880127\n",
      "Epoch [3/3], Batch [550/2500], Loss: 0.08083038032054901\n",
      "Epoch [3/3], Batch [551/2500], Loss: 0.3790084421634674\n",
      "Epoch [3/3], Batch [552/2500], Loss: 0.19699302315711975\n",
      "Epoch [3/3], Batch [553/2500], Loss: 0.0817900225520134\n",
      "Epoch [3/3], Batch [554/2500], Loss: 0.1586400717496872\n",
      "Epoch [3/3], Batch [555/2500], Loss: 0.026696205139160156\n",
      "Epoch [3/3], Batch [556/2500], Loss: 0.06938981264829636\n",
      "Epoch [3/3], Batch [557/2500], Loss: 0.02244894579052925\n",
      "Epoch [3/3], Batch [558/2500], Loss: 0.07883933931589127\n",
      "Epoch [3/3], Batch [559/2500], Loss: 0.21449606120586395\n",
      "Epoch [3/3], Batch [560/2500], Loss: 0.20630879700183868\n",
      "Epoch [3/3], Batch [561/2500], Loss: 0.07773260027170181\n",
      "Epoch [3/3], Batch [562/2500], Loss: 0.11425818502902985\n",
      "Epoch [3/3], Batch [563/2500], Loss: 0.03717698156833649\n",
      "Epoch [3/3], Batch [564/2500], Loss: 0.08719372749328613\n",
      "Epoch [3/3], Batch [565/2500], Loss: 0.24965475499629974\n",
      "Epoch [3/3], Batch [566/2500], Loss: 0.09487605094909668\n",
      "Epoch [3/3], Batch [567/2500], Loss: 0.5508493781089783\n",
      "Epoch [3/3], Batch [568/2500], Loss: 0.07401483505964279\n",
      "Epoch [3/3], Batch [569/2500], Loss: 0.04861218482255936\n",
      "Epoch [3/3], Batch [570/2500], Loss: 0.06542251259088516\n",
      "Epoch [3/3], Batch [571/2500], Loss: 0.043204668909311295\n",
      "Epoch [3/3], Batch [572/2500], Loss: 0.020430132746696472\n",
      "Epoch [3/3], Batch [573/2500], Loss: 0.4046654999256134\n",
      "Epoch [3/3], Batch [574/2500], Loss: 0.123196080327034\n",
      "Epoch [3/3], Batch [575/2500], Loss: 0.023210102692246437\n",
      "Epoch [3/3], Batch [576/2500], Loss: 0.031617745757102966\n",
      "Epoch [3/3], Batch [577/2500], Loss: 0.08205001056194305\n",
      "Epoch [3/3], Batch [578/2500], Loss: 0.05395982414484024\n",
      "Epoch [3/3], Batch [579/2500], Loss: 0.06850097328424454\n",
      "Epoch [3/3], Batch [580/2500], Loss: 0.22696518898010254\n",
      "Epoch [3/3], Batch [581/2500], Loss: 0.5810874700546265\n",
      "Epoch [3/3], Batch [582/2500], Loss: 0.24326814711093903\n",
      "Epoch [3/3], Batch [583/2500], Loss: 0.39282193779945374\n",
      "Epoch [3/3], Batch [584/2500], Loss: 0.02795501798391342\n",
      "Epoch [3/3], Batch [585/2500], Loss: 0.027294255793094635\n",
      "Epoch [3/3], Batch [586/2500], Loss: 0.217217817902565\n",
      "Epoch [3/3], Batch [587/2500], Loss: 0.22024166584014893\n",
      "Epoch [3/3], Batch [588/2500], Loss: 0.019638361409306526\n",
      "Epoch [3/3], Batch [589/2500], Loss: 0.053247421979904175\n",
      "Epoch [3/3], Batch [590/2500], Loss: 0.03414051607251167\n",
      "Epoch [3/3], Batch [591/2500], Loss: 0.26180189847946167\n",
      "Epoch [3/3], Batch [592/2500], Loss: 0.11983613669872284\n",
      "Epoch [3/3], Batch [593/2500], Loss: 0.13470439612865448\n",
      "Epoch [3/3], Batch [594/2500], Loss: 0.2144395262002945\n",
      "Epoch [3/3], Batch [595/2500], Loss: 0.1419302523136139\n",
      "Epoch [3/3], Batch [596/2500], Loss: 0.1050889641046524\n",
      "Epoch [3/3], Batch [597/2500], Loss: 0.0680161863565445\n",
      "Epoch [3/3], Batch [598/2500], Loss: 0.13556857407093048\n",
      "Epoch [3/3], Batch [599/2500], Loss: 0.09310153126716614\n",
      "Epoch [3/3], Batch [600/2500], Loss: 0.08666671067476273\n",
      "Epoch [3/3], Batch [601/2500], Loss: 0.326898992061615\n",
      "Epoch [3/3], Batch [602/2500], Loss: 0.2166929543018341\n",
      "Epoch [3/3], Batch [603/2500], Loss: 0.282197505235672\n",
      "Epoch [3/3], Batch [604/2500], Loss: 0.046720121055841446\n",
      "Epoch [3/3], Batch [605/2500], Loss: 0.33163395524024963\n",
      "Epoch [3/3], Batch [606/2500], Loss: 0.018281614407896996\n",
      "Epoch [3/3], Batch [607/2500], Loss: 0.17791852355003357\n",
      "Epoch [3/3], Batch [608/2500], Loss: 0.07918551564216614\n",
      "Epoch [3/3], Batch [609/2500], Loss: 0.1377987563610077\n",
      "Epoch [3/3], Batch [610/2500], Loss: 0.4229018986225128\n",
      "Epoch [3/3], Batch [611/2500], Loss: 0.21932552754878998\n",
      "Epoch [3/3], Batch [612/2500], Loss: 0.11416853219270706\n",
      "Epoch [3/3], Batch [613/2500], Loss: 0.01687709242105484\n",
      "Epoch [3/3], Batch [614/2500], Loss: 0.06706378608942032\n",
      "Epoch [3/3], Batch [615/2500], Loss: 0.028355911374092102\n",
      "Epoch [3/3], Batch [616/2500], Loss: 0.27940794825553894\n",
      "Epoch [3/3], Batch [617/2500], Loss: 0.060547780245542526\n",
      "Epoch [3/3], Batch [618/2500], Loss: 0.04894162714481354\n",
      "Epoch [3/3], Batch [619/2500], Loss: 0.03654927760362625\n",
      "Epoch [3/3], Batch [620/2500], Loss: 0.05838453024625778\n",
      "Epoch [3/3], Batch [621/2500], Loss: 0.12734386324882507\n",
      "Epoch [3/3], Batch [622/2500], Loss: 0.01879691891372204\n",
      "Epoch [3/3], Batch [623/2500], Loss: 0.05370457470417023\n",
      "Epoch [3/3], Batch [624/2500], Loss: 0.19058758020401\n",
      "Epoch [3/3], Batch [625/2500], Loss: 0.43400388956069946\n",
      "Epoch [3/3], Batch [626/2500], Loss: 0.03577490150928497\n",
      "Epoch [3/3], Batch [627/2500], Loss: 0.031310729682445526\n",
      "Epoch [3/3], Batch [628/2500], Loss: 0.18829578161239624\n",
      "Epoch [3/3], Batch [629/2500], Loss: 0.04844928905367851\n",
      "Epoch [3/3], Batch [630/2500], Loss: 0.43931064009666443\n",
      "Epoch [3/3], Batch [631/2500], Loss: 0.3721103370189667\n",
      "Epoch [3/3], Batch [632/2500], Loss: 0.14160077273845673\n",
      "Epoch [3/3], Batch [633/2500], Loss: 0.3085310757160187\n",
      "Epoch [3/3], Batch [634/2500], Loss: 0.3505547046661377\n",
      "Epoch [3/3], Batch [635/2500], Loss: 0.15032337605953217\n",
      "Epoch [3/3], Batch [636/2500], Loss: 0.13474011421203613\n",
      "Epoch [3/3], Batch [637/2500], Loss: 0.21244923770427704\n",
      "Epoch [3/3], Batch [638/2500], Loss: 0.031014394015073776\n",
      "Epoch [3/3], Batch [639/2500], Loss: 0.10912729054689407\n",
      "Epoch [3/3], Batch [640/2500], Loss: 0.2919905483722687\n",
      "Epoch [3/3], Batch [641/2500], Loss: 0.2662513554096222\n",
      "Epoch [3/3], Batch [642/2500], Loss: 0.04591529443860054\n",
      "Epoch [3/3], Batch [643/2500], Loss: 0.19190575182437897\n",
      "Epoch [3/3], Batch [644/2500], Loss: 0.2299003154039383\n",
      "Epoch [3/3], Batch [645/2500], Loss: 0.16613852977752686\n",
      "Epoch [3/3], Batch [646/2500], Loss: 0.04152168333530426\n",
      "Epoch [3/3], Batch [647/2500], Loss: 0.3227095901966095\n",
      "Epoch [3/3], Batch [648/2500], Loss: 0.06593409925699234\n",
      "Epoch [3/3], Batch [649/2500], Loss: 0.18654152750968933\n",
      "Epoch [3/3], Batch [650/2500], Loss: 0.09440769255161285\n",
      "Epoch [3/3], Batch [651/2500], Loss: 0.07224339991807938\n",
      "Epoch [3/3], Batch [652/2500], Loss: 0.12389248609542847\n",
      "Epoch [3/3], Batch [653/2500], Loss: 0.09831320494413376\n",
      "Epoch [3/3], Batch [654/2500], Loss: 0.1163158044219017\n",
      "Epoch [3/3], Batch [655/2500], Loss: 0.11864794790744781\n",
      "Epoch [3/3], Batch [656/2500], Loss: 0.2001020610332489\n",
      "Epoch [3/3], Batch [657/2500], Loss: 0.3813250958919525\n",
      "Epoch [3/3], Batch [658/2500], Loss: 0.26898613572120667\n",
      "Epoch [3/3], Batch [659/2500], Loss: 0.2672465443611145\n",
      "Epoch [3/3], Batch [660/2500], Loss: 0.11858436465263367\n",
      "Epoch [3/3], Batch [661/2500], Loss: 0.07767627388238907\n",
      "Epoch [3/3], Batch [662/2500], Loss: 0.03840991482138634\n",
      "Epoch [3/3], Batch [663/2500], Loss: 0.1157413050532341\n",
      "Epoch [3/3], Batch [664/2500], Loss: 0.3237551748752594\n",
      "Epoch [3/3], Batch [665/2500], Loss: 0.45354774594306946\n",
      "Epoch [3/3], Batch [666/2500], Loss: 0.3930470049381256\n",
      "Epoch [3/3], Batch [667/2500], Loss: 0.3137637972831726\n",
      "Epoch [3/3], Batch [668/2500], Loss: 0.19811879098415375\n",
      "Epoch [3/3], Batch [669/2500], Loss: 0.1582808792591095\n",
      "Epoch [3/3], Batch [670/2500], Loss: 0.1825178861618042\n",
      "Epoch [3/3], Batch [671/2500], Loss: 0.10049985349178314\n",
      "Epoch [3/3], Batch [672/2500], Loss: 0.4568870961666107\n",
      "Epoch [3/3], Batch [673/2500], Loss: 0.3825693428516388\n",
      "Epoch [3/3], Batch [674/2500], Loss: 0.14803452789783478\n",
      "Epoch [3/3], Batch [675/2500], Loss: 0.17166569828987122\n",
      "Epoch [3/3], Batch [676/2500], Loss: 0.08645379543304443\n",
      "Epoch [3/3], Batch [677/2500], Loss: 0.24164491891860962\n",
      "Epoch [3/3], Batch [678/2500], Loss: 0.24760231375694275\n",
      "Epoch [3/3], Batch [679/2500], Loss: 0.14398539066314697\n",
      "Epoch [3/3], Batch [680/2500], Loss: 0.1711217761039734\n",
      "Epoch [3/3], Batch [681/2500], Loss: 0.40055134892463684\n",
      "Epoch [3/3], Batch [682/2500], Loss: 0.14506706595420837\n",
      "Epoch [3/3], Batch [683/2500], Loss: 0.16309846937656403\n",
      "Epoch [3/3], Batch [684/2500], Loss: 0.09991397708654404\n",
      "Epoch [3/3], Batch [685/2500], Loss: 0.059756774455308914\n",
      "Epoch [3/3], Batch [686/2500], Loss: 0.23523777723312378\n",
      "Epoch [3/3], Batch [687/2500], Loss: 0.20117181539535522\n",
      "Epoch [3/3], Batch [688/2500], Loss: 0.22958627343177795\n",
      "Epoch [3/3], Batch [689/2500], Loss: 0.1099388375878334\n",
      "Epoch [3/3], Batch [690/2500], Loss: 0.2264401763677597\n",
      "Epoch [3/3], Batch [691/2500], Loss: 0.1619296371936798\n",
      "Epoch [3/3], Batch [692/2500], Loss: 0.2362448275089264\n",
      "Epoch [3/3], Batch [693/2500], Loss: 0.17840102314949036\n",
      "Epoch [3/3], Batch [694/2500], Loss: 0.35048890113830566\n",
      "Epoch [3/3], Batch [695/2500], Loss: 0.2182196080684662\n",
      "Epoch [3/3], Batch [696/2500], Loss: 0.13850800693035126\n",
      "Epoch [3/3], Batch [697/2500], Loss: 0.17253440618515015\n",
      "Epoch [3/3], Batch [698/2500], Loss: 0.1708592027425766\n",
      "Epoch [3/3], Batch [699/2500], Loss: 0.1332680583000183\n",
      "Epoch [3/3], Batch [700/2500], Loss: 0.06396444141864777\n",
      "Epoch [3/3], Batch [701/2500], Loss: 0.07571285218000412\n",
      "Epoch [3/3], Batch [702/2500], Loss: 0.8099170923233032\n",
      "Epoch [3/3], Batch [703/2500], Loss: 0.15085157752037048\n",
      "Epoch [3/3], Batch [704/2500], Loss: 0.14154386520385742\n",
      "Epoch [3/3], Batch [705/2500], Loss: 0.048998381942510605\n",
      "Epoch [3/3], Batch [706/2500], Loss: 0.15452517569065094\n",
      "Epoch [3/3], Batch [707/2500], Loss: 0.09620696306228638\n",
      "Epoch [3/3], Batch [708/2500], Loss: 0.016171924769878387\n",
      "Epoch [3/3], Batch [709/2500], Loss: 0.28738871216773987\n",
      "Epoch [3/3], Batch [710/2500], Loss: 0.014944110065698624\n",
      "Epoch [3/3], Batch [711/2500], Loss: 0.18879878520965576\n",
      "Epoch [3/3], Batch [712/2500], Loss: 0.24455362558364868\n",
      "Epoch [3/3], Batch [713/2500], Loss: 0.10322029888629913\n",
      "Epoch [3/3], Batch [714/2500], Loss: 0.2592020034790039\n",
      "Epoch [3/3], Batch [715/2500], Loss: 0.2601381838321686\n",
      "Epoch [3/3], Batch [716/2500], Loss: 0.1948430836200714\n",
      "Epoch [3/3], Batch [717/2500], Loss: 0.1982182413339615\n",
      "Epoch [3/3], Batch [718/2500], Loss: 0.12879887223243713\n",
      "Epoch [3/3], Batch [719/2500], Loss: 0.01614689826965332\n",
      "Epoch [3/3], Batch [720/2500], Loss: 0.12553291022777557\n",
      "Epoch [3/3], Batch [721/2500], Loss: 0.09059030562639236\n",
      "Epoch [3/3], Batch [722/2500], Loss: 0.07518977671861649\n",
      "Epoch [3/3], Batch [723/2500], Loss: 0.30167293548583984\n",
      "Epoch [3/3], Batch [724/2500], Loss: 0.11221588402986526\n",
      "Epoch [3/3], Batch [725/2500], Loss: 0.13577544689178467\n",
      "Epoch [3/3], Batch [726/2500], Loss: 0.06712327152490616\n",
      "Epoch [3/3], Batch [727/2500], Loss: 0.11682827025651932\n",
      "Epoch [3/3], Batch [728/2500], Loss: 0.15046338737010956\n",
      "Epoch [3/3], Batch [729/2500], Loss: 0.09761495143175125\n",
      "Epoch [3/3], Batch [730/2500], Loss: 0.03409680351614952\n",
      "Epoch [3/3], Batch [731/2500], Loss: 0.3051905333995819\n",
      "Epoch [3/3], Batch [732/2500], Loss: 0.15616101026535034\n",
      "Epoch [3/3], Batch [733/2500], Loss: 0.2565135955810547\n",
      "Epoch [3/3], Batch [734/2500], Loss: 0.059626832604408264\n",
      "Epoch [3/3], Batch [735/2500], Loss: 0.062044113874435425\n",
      "Epoch [3/3], Batch [736/2500], Loss: 0.06867396086454391\n",
      "Epoch [3/3], Batch [737/2500], Loss: 0.272570937871933\n",
      "Epoch [3/3], Batch [738/2500], Loss: 0.050855498760938644\n",
      "Epoch [3/3], Batch [739/2500], Loss: 0.023146793246269226\n",
      "Epoch [3/3], Batch [740/2500], Loss: 0.03980499133467674\n",
      "Epoch [3/3], Batch [741/2500], Loss: 0.07954012602567673\n",
      "Epoch [3/3], Batch [742/2500], Loss: 0.07999642193317413\n",
      "Epoch [3/3], Batch [743/2500], Loss: 0.34414252638816833\n",
      "Epoch [3/3], Batch [744/2500], Loss: 0.21610337495803833\n",
      "Epoch [3/3], Batch [745/2500], Loss: 0.026751795783638954\n",
      "Epoch [3/3], Batch [746/2500], Loss: 0.014461429789662361\n",
      "Epoch [3/3], Batch [747/2500], Loss: 0.11285050958395004\n",
      "Epoch [3/3], Batch [748/2500], Loss: 0.22353756427764893\n",
      "Epoch [3/3], Batch [749/2500], Loss: 0.014196905307471752\n",
      "Epoch [3/3], Batch [750/2500], Loss: 0.09232901781797409\n",
      "Epoch [3/3], Batch [751/2500], Loss: 0.031187014654278755\n",
      "Epoch [3/3], Batch [752/2500], Loss: 0.1327991783618927\n",
      "Epoch [3/3], Batch [753/2500], Loss: 0.02362932078540325\n",
      "Epoch [3/3], Batch [754/2500], Loss: 0.04470160976052284\n",
      "Epoch [3/3], Batch [755/2500], Loss: 0.03914742171764374\n",
      "Epoch [3/3], Batch [756/2500], Loss: 0.07158496975898743\n",
      "Epoch [3/3], Batch [757/2500], Loss: 0.06177349388599396\n",
      "Epoch [3/3], Batch [758/2500], Loss: 0.010059799998998642\n",
      "Epoch [3/3], Batch [759/2500], Loss: 0.10631350427865982\n",
      "Epoch [3/3], Batch [760/2500], Loss: 0.05595940351486206\n",
      "Epoch [3/3], Batch [761/2500], Loss: 0.0669606477022171\n",
      "Epoch [3/3], Batch [762/2500], Loss: 0.06017918884754181\n",
      "Epoch [3/3], Batch [763/2500], Loss: 0.19749535620212555\n",
      "Epoch [3/3], Batch [764/2500], Loss: 0.021282728761434555\n",
      "Epoch [3/3], Batch [765/2500], Loss: 0.02459735795855522\n",
      "Epoch [3/3], Batch [766/2500], Loss: 0.08863775432109833\n",
      "Epoch [3/3], Batch [767/2500], Loss: 0.01145158614963293\n",
      "Epoch [3/3], Batch [768/2500], Loss: 0.028814144432544708\n",
      "Epoch [3/3], Batch [769/2500], Loss: 0.11373607069253922\n",
      "Epoch [3/3], Batch [770/2500], Loss: 0.3996036946773529\n",
      "Epoch [3/3], Batch [771/2500], Loss: 0.03953518718481064\n",
      "Epoch [3/3], Batch [772/2500], Loss: 0.04559079557657242\n",
      "Epoch [3/3], Batch [773/2500], Loss: 0.0564751923084259\n",
      "Epoch [3/3], Batch [774/2500], Loss: 0.0995858758687973\n",
      "Epoch [3/3], Batch [775/2500], Loss: 0.022749627009034157\n",
      "Epoch [3/3], Batch [776/2500], Loss: 0.02251284010708332\n",
      "Epoch [3/3], Batch [777/2500], Loss: 0.12585915625095367\n",
      "Epoch [3/3], Batch [778/2500], Loss: 0.0471532866358757\n",
      "Epoch [3/3], Batch [779/2500], Loss: 0.13333187997341156\n",
      "Epoch [3/3], Batch [780/2500], Loss: 0.6750006675720215\n",
      "Epoch [3/3], Batch [781/2500], Loss: 0.10002855956554413\n",
      "Epoch [3/3], Batch [782/2500], Loss: 0.28125983476638794\n",
      "Epoch [3/3], Batch [783/2500], Loss: 0.02669590711593628\n",
      "Epoch [3/3], Batch [784/2500], Loss: 0.3447185158729553\n",
      "Epoch [3/3], Batch [785/2500], Loss: 0.16030284762382507\n",
      "Epoch [3/3], Batch [786/2500], Loss: 0.14415466785430908\n",
      "Epoch [3/3], Batch [787/2500], Loss: 0.04707780480384827\n",
      "Epoch [3/3], Batch [788/2500], Loss: 0.04798473045229912\n",
      "Epoch [3/3], Batch [789/2500], Loss: 0.053602252155542374\n",
      "Epoch [3/3], Batch [790/2500], Loss: 0.6376192569732666\n",
      "Epoch [3/3], Batch [791/2500], Loss: 0.2511531710624695\n",
      "Epoch [3/3], Batch [792/2500], Loss: 0.39935433864593506\n",
      "Epoch [3/3], Batch [793/2500], Loss: 0.6043424010276794\n",
      "Epoch [3/3], Batch [794/2500], Loss: 0.1795782595872879\n",
      "Epoch [3/3], Batch [795/2500], Loss: 0.11038293689489365\n",
      "Epoch [3/3], Batch [796/2500], Loss: 0.009417089633643627\n",
      "Epoch [3/3], Batch [797/2500], Loss: 0.038057997822761536\n",
      "Epoch [3/3], Batch [798/2500], Loss: 0.01986490935087204\n",
      "Epoch [3/3], Batch [799/2500], Loss: 0.14175549149513245\n",
      "Epoch [3/3], Batch [800/2500], Loss: 0.18803368508815765\n",
      "Epoch [3/3], Batch [801/2500], Loss: 0.09780703485012054\n",
      "Epoch [3/3], Batch [802/2500], Loss: 0.06644466519355774\n",
      "Epoch [3/3], Batch [803/2500], Loss: 0.25673678517341614\n",
      "Epoch [3/3], Batch [804/2500], Loss: 0.14996793866157532\n",
      "Epoch [3/3], Batch [805/2500], Loss: 0.47835251688957214\n",
      "Epoch [3/3], Batch [806/2500], Loss: 0.18272645771503448\n",
      "Epoch [3/3], Batch [807/2500], Loss: 0.014276555739343166\n",
      "Epoch [3/3], Batch [808/2500], Loss: 0.01554038655012846\n",
      "Epoch [3/3], Batch [809/2500], Loss: 0.3404815196990967\n",
      "Epoch [3/3], Batch [810/2500], Loss: 0.13206186890602112\n",
      "Epoch [3/3], Batch [811/2500], Loss: 0.4422857463359833\n",
      "Epoch [3/3], Batch [812/2500], Loss: 0.7457364201545715\n",
      "Epoch [3/3], Batch [813/2500], Loss: 0.11002522706985474\n",
      "Epoch [3/3], Batch [814/2500], Loss: 0.20506680011749268\n",
      "Epoch [3/3], Batch [815/2500], Loss: 0.014213986694812775\n",
      "Epoch [3/3], Batch [816/2500], Loss: 0.157197505235672\n",
      "Epoch [3/3], Batch [817/2500], Loss: 0.023475436493754387\n",
      "Epoch [3/3], Batch [818/2500], Loss: 0.019262947142124176\n",
      "Epoch [3/3], Batch [819/2500], Loss: 0.12869708240032196\n",
      "Epoch [3/3], Batch [820/2500], Loss: 0.10720004141330719\n",
      "Epoch [3/3], Batch [821/2500], Loss: 0.3349945843219757\n",
      "Epoch [3/3], Batch [822/2500], Loss: 0.06589879840612411\n",
      "Epoch [3/3], Batch [823/2500], Loss: 0.3919679820537567\n",
      "Epoch [3/3], Batch [824/2500], Loss: 0.17601509392261505\n",
      "Epoch [3/3], Batch [825/2500], Loss: 0.04585280269384384\n",
      "Epoch [3/3], Batch [826/2500], Loss: 0.060056645423173904\n",
      "Epoch [3/3], Batch [827/2500], Loss: 0.12605497241020203\n",
      "Epoch [3/3], Batch [828/2500], Loss: 0.16708582639694214\n",
      "Epoch [3/3], Batch [829/2500], Loss: 0.24111142754554749\n",
      "Epoch [3/3], Batch [830/2500], Loss: 0.08417332172393799\n",
      "Epoch [3/3], Batch [831/2500], Loss: 0.2883743345737457\n",
      "Epoch [3/3], Batch [832/2500], Loss: 0.08686354756355286\n",
      "Epoch [3/3], Batch [833/2500], Loss: 0.15300606191158295\n",
      "Epoch [3/3], Batch [834/2500], Loss: 0.2758007049560547\n",
      "Epoch [3/3], Batch [835/2500], Loss: 0.07245420664548874\n",
      "Epoch [3/3], Batch [836/2500], Loss: 0.20465382933616638\n",
      "Epoch [3/3], Batch [837/2500], Loss: 0.34669947624206543\n",
      "Epoch [3/3], Batch [838/2500], Loss: 0.28885558247566223\n",
      "Epoch [3/3], Batch [839/2500], Loss: 0.39163053035736084\n",
      "Epoch [3/3], Batch [840/2500], Loss: 0.03169731795787811\n",
      "Epoch [3/3], Batch [841/2500], Loss: 0.22251851856708527\n",
      "Epoch [3/3], Batch [842/2500], Loss: 0.04663364216685295\n",
      "Epoch [3/3], Batch [843/2500], Loss: 0.27274781465530396\n",
      "Epoch [3/3], Batch [844/2500], Loss: 0.11526848375797272\n",
      "Epoch [3/3], Batch [845/2500], Loss: 0.31011053919792175\n",
      "Epoch [3/3], Batch [846/2500], Loss: 0.05901014804840088\n",
      "Epoch [3/3], Batch [847/2500], Loss: 0.14298658072948456\n",
      "Epoch [3/3], Batch [848/2500], Loss: 0.20347459614276886\n",
      "Epoch [3/3], Batch [849/2500], Loss: 0.07792720198631287\n",
      "Epoch [3/3], Batch [850/2500], Loss: 0.24236516654491425\n",
      "Epoch [3/3], Batch [851/2500], Loss: 0.09174879640340805\n",
      "Epoch [3/3], Batch [852/2500], Loss: 0.29059186577796936\n",
      "Epoch [3/3], Batch [853/2500], Loss: 0.376020610332489\n",
      "Epoch [3/3], Batch [854/2500], Loss: 0.1964220106601715\n",
      "Epoch [3/3], Batch [855/2500], Loss: 0.061868421733379364\n",
      "Epoch [3/3], Batch [856/2500], Loss: 0.1039116308093071\n",
      "Epoch [3/3], Batch [857/2500], Loss: 0.23275355994701385\n",
      "Epoch [3/3], Batch [858/2500], Loss: 0.052001550793647766\n",
      "Epoch [3/3], Batch [859/2500], Loss: 0.13993702828884125\n",
      "Epoch [3/3], Batch [860/2500], Loss: 0.2843628525733948\n",
      "Epoch [3/3], Batch [861/2500], Loss: 0.18138203024864197\n",
      "Epoch [3/3], Batch [862/2500], Loss: 0.1619614213705063\n",
      "Epoch [3/3], Batch [863/2500], Loss: 0.11327722668647766\n",
      "Epoch [3/3], Batch [864/2500], Loss: 0.10012959688901901\n",
      "Epoch [3/3], Batch [865/2500], Loss: 0.12132090330123901\n",
      "Epoch [3/3], Batch [866/2500], Loss: 0.07371177524328232\n",
      "Epoch [3/3], Batch [867/2500], Loss: 0.017954770475625992\n",
      "Epoch [3/3], Batch [868/2500], Loss: 0.07495749741792679\n",
      "Epoch [3/3], Batch [869/2500], Loss: 0.07888898253440857\n",
      "Epoch [3/3], Batch [870/2500], Loss: 0.10769712179899216\n",
      "Epoch [3/3], Batch [871/2500], Loss: 0.02027742937207222\n",
      "Epoch [3/3], Batch [872/2500], Loss: 0.10580746084451675\n",
      "Epoch [3/3], Batch [873/2500], Loss: 0.20034752786159515\n",
      "Epoch [3/3], Batch [874/2500], Loss: 0.06525848060846329\n",
      "Epoch [3/3], Batch [875/2500], Loss: 0.23194380104541779\n",
      "Epoch [3/3], Batch [876/2500], Loss: 0.18636542558670044\n",
      "Epoch [3/3], Batch [877/2500], Loss: 0.12143390625715256\n",
      "Epoch [3/3], Batch [878/2500], Loss: 0.26839208602905273\n",
      "Epoch [3/3], Batch [879/2500], Loss: 0.16397307813167572\n",
      "Epoch [3/3], Batch [880/2500], Loss: 0.029344171285629272\n",
      "Epoch [3/3], Batch [881/2500], Loss: 0.018840327858924866\n",
      "Epoch [3/3], Batch [882/2500], Loss: 0.20276711881160736\n",
      "Epoch [3/3], Batch [883/2500], Loss: 0.23501496016979218\n",
      "Epoch [3/3], Batch [884/2500], Loss: 0.13759419322013855\n",
      "Epoch [3/3], Batch [885/2500], Loss: 0.08188633620738983\n",
      "Epoch [3/3], Batch [886/2500], Loss: 0.05208902433514595\n",
      "Epoch [3/3], Batch [887/2500], Loss: 0.0805293396115303\n",
      "Epoch [3/3], Batch [888/2500], Loss: 0.1739203929901123\n",
      "Epoch [3/3], Batch [889/2500], Loss: 0.015969377011060715\n",
      "Epoch [3/3], Batch [890/2500], Loss: 0.255754679441452\n",
      "Epoch [3/3], Batch [891/2500], Loss: 0.2415461540222168\n",
      "Epoch [3/3], Batch [892/2500], Loss: 0.04177141934633255\n",
      "Epoch [3/3], Batch [893/2500], Loss: 0.04278707504272461\n",
      "Epoch [3/3], Batch [894/2500], Loss: 0.018199685961008072\n",
      "Epoch [3/3], Batch [895/2500], Loss: 0.07588925957679749\n",
      "Epoch [3/3], Batch [896/2500], Loss: 0.17280258238315582\n",
      "Epoch [3/3], Batch [897/2500], Loss: 0.033979348838329315\n",
      "Epoch [3/3], Batch [898/2500], Loss: 0.07648027688264847\n",
      "Epoch [3/3], Batch [899/2500], Loss: 0.025790179148316383\n",
      "Epoch [3/3], Batch [900/2500], Loss: 0.04022431746125221\n",
      "Epoch [3/3], Batch [901/2500], Loss: 0.1711401641368866\n",
      "Epoch [3/3], Batch [902/2500], Loss: 0.14285282790660858\n",
      "Epoch [3/3], Batch [903/2500], Loss: 0.14028185606002808\n",
      "Epoch [3/3], Batch [904/2500], Loss: 0.32687509059906006\n",
      "Epoch [3/3], Batch [905/2500], Loss: 0.16904371976852417\n",
      "Epoch [3/3], Batch [906/2500], Loss: 0.2324761003255844\n",
      "Epoch [3/3], Batch [907/2500], Loss: 0.03958318755030632\n",
      "Epoch [3/3], Batch [908/2500], Loss: 0.03349684178829193\n",
      "Epoch [3/3], Batch [909/2500], Loss: 0.02248264104127884\n",
      "Epoch [3/3], Batch [910/2500], Loss: 0.03734787926077843\n",
      "Epoch [3/3], Batch [911/2500], Loss: 0.0796961560845375\n",
      "Epoch [3/3], Batch [912/2500], Loss: 0.01931839808821678\n",
      "Epoch [3/3], Batch [913/2500], Loss: 0.016913309693336487\n",
      "Epoch [3/3], Batch [914/2500], Loss: 0.05683191120624542\n",
      "Epoch [3/3], Batch [915/2500], Loss: 0.02306142821907997\n",
      "Epoch [3/3], Batch [916/2500], Loss: 0.012760122306644917\n",
      "Epoch [3/3], Batch [917/2500], Loss: 0.0488884374499321\n",
      "Epoch [3/3], Batch [918/2500], Loss: 0.4323481619358063\n",
      "Epoch [3/3], Batch [919/2500], Loss: 0.016821397468447685\n",
      "Epoch [3/3], Batch [920/2500], Loss: 0.025032170116901398\n",
      "Epoch [3/3], Batch [921/2500], Loss: 0.006997107528150082\n",
      "Epoch [3/3], Batch [922/2500], Loss: 0.07086092978715897\n",
      "Epoch [3/3], Batch [923/2500], Loss: 0.07711482048034668\n",
      "Epoch [3/3], Batch [924/2500], Loss: 0.34140580892562866\n",
      "Epoch [3/3], Batch [925/2500], Loss: 0.014246081933379173\n",
      "Epoch [3/3], Batch [926/2500], Loss: 0.02679581381380558\n",
      "Epoch [3/3], Batch [927/2500], Loss: 0.031613364815711975\n",
      "Epoch [3/3], Batch [928/2500], Loss: 0.08204113692045212\n",
      "Epoch [3/3], Batch [929/2500], Loss: 0.03275332227349281\n",
      "Epoch [3/3], Batch [930/2500], Loss: 0.012136463075876236\n",
      "Epoch [3/3], Batch [931/2500], Loss: 0.41850656270980835\n",
      "Epoch [3/3], Batch [932/2500], Loss: 0.032092224806547165\n",
      "Epoch [3/3], Batch [933/2500], Loss: 0.025093041360378265\n",
      "Epoch [3/3], Batch [934/2500], Loss: 0.02402135543525219\n",
      "Epoch [3/3], Batch [935/2500], Loss: 0.17129498720169067\n",
      "Epoch [3/3], Batch [936/2500], Loss: 0.035540658980607986\n",
      "Epoch [3/3], Batch [937/2500], Loss: 0.012634229846298695\n",
      "Epoch [3/3], Batch [938/2500], Loss: 0.02948291040956974\n",
      "Epoch [3/3], Batch [939/2500], Loss: 0.02903209626674652\n",
      "Epoch [3/3], Batch [940/2500], Loss: 0.1816912591457367\n",
      "Epoch [3/3], Batch [941/2500], Loss: 0.3875037431716919\n",
      "Epoch [3/3], Batch [942/2500], Loss: 0.08122166246175766\n",
      "Epoch [3/3], Batch [943/2500], Loss: 0.25890296697616577\n",
      "Epoch [3/3], Batch [944/2500], Loss: 0.15042723715305328\n",
      "Epoch [3/3], Batch [945/2500], Loss: 0.047667041420936584\n",
      "Epoch [3/3], Batch [946/2500], Loss: 0.30106860399246216\n",
      "Epoch [3/3], Batch [947/2500], Loss: 0.21120022237300873\n",
      "Epoch [3/3], Batch [948/2500], Loss: 0.019806664437055588\n",
      "Epoch [3/3], Batch [949/2500], Loss: 0.014489859342575073\n",
      "Epoch [3/3], Batch [950/2500], Loss: 0.015593290328979492\n",
      "Epoch [3/3], Batch [951/2500], Loss: 0.0632038563489914\n",
      "Epoch [3/3], Batch [952/2500], Loss: 0.04076675325632095\n",
      "Epoch [3/3], Batch [953/2500], Loss: 0.35674193501472473\n",
      "Epoch [3/3], Batch [954/2500], Loss: 0.07490372657775879\n",
      "Epoch [3/3], Batch [955/2500], Loss: 0.023031534627079964\n",
      "Epoch [3/3], Batch [956/2500], Loss: 0.053994983434677124\n",
      "Epoch [3/3], Batch [957/2500], Loss: 0.01921534165740013\n",
      "Epoch [3/3], Batch [958/2500], Loss: 0.3268355429172516\n",
      "Epoch [3/3], Batch [959/2500], Loss: 0.026023123413324356\n",
      "Epoch [3/3], Batch [960/2500], Loss: 0.04777858033776283\n",
      "Epoch [3/3], Batch [961/2500], Loss: 0.060291796922683716\n",
      "Epoch [3/3], Batch [962/2500], Loss: 0.08183041214942932\n",
      "Epoch [3/3], Batch [963/2500], Loss: 0.053316861391067505\n",
      "Epoch [3/3], Batch [964/2500], Loss: 0.2018055021762848\n",
      "Epoch [3/3], Batch [965/2500], Loss: 0.20716559886932373\n",
      "Epoch [3/3], Batch [966/2500], Loss: 0.15139880776405334\n",
      "Epoch [3/3], Batch [967/2500], Loss: 0.025651106610894203\n",
      "Epoch [3/3], Batch [968/2500], Loss: 0.012047532945871353\n",
      "Epoch [3/3], Batch [969/2500], Loss: 0.1394941657781601\n",
      "Epoch [3/3], Batch [970/2500], Loss: 0.09690441191196442\n",
      "Epoch [3/3], Batch [971/2500], Loss: 0.04778064414858818\n",
      "Epoch [3/3], Batch [972/2500], Loss: 0.09553408622741699\n",
      "Epoch [3/3], Batch [973/2500], Loss: 0.03008543699979782\n",
      "Epoch [3/3], Batch [974/2500], Loss: 0.02374204434454441\n",
      "Epoch [3/3], Batch [975/2500], Loss: 0.050012875348329544\n",
      "Epoch [3/3], Batch [976/2500], Loss: 0.0746665671467781\n",
      "Epoch [3/3], Batch [977/2500], Loss: 0.04168841242790222\n",
      "Epoch [3/3], Batch [978/2500], Loss: 0.04404458403587341\n",
      "Epoch [3/3], Batch [979/2500], Loss: 0.022014187648892403\n",
      "Epoch [3/3], Batch [980/2500], Loss: 0.02915533073246479\n",
      "Epoch [3/3], Batch [981/2500], Loss: 0.040394239127635956\n",
      "Epoch [3/3], Batch [982/2500], Loss: 0.017755337059497833\n",
      "Epoch [3/3], Batch [983/2500], Loss: 0.01964290626347065\n",
      "Epoch [3/3], Batch [984/2500], Loss: 0.0411418117582798\n",
      "Epoch [3/3], Batch [985/2500], Loss: 0.07493294030427933\n",
      "Epoch [3/3], Batch [986/2500], Loss: 0.08974459022283554\n",
      "Epoch [3/3], Batch [987/2500], Loss: 0.04411908611655235\n",
      "Epoch [3/3], Batch [988/2500], Loss: 0.1505558341741562\n",
      "Epoch [3/3], Batch [989/2500], Loss: 0.04586157947778702\n",
      "Epoch [3/3], Batch [990/2500], Loss: 0.038147177547216415\n",
      "Epoch [3/3], Batch [991/2500], Loss: 0.05918826162815094\n",
      "Epoch [3/3], Batch [992/2500], Loss: 0.03059053048491478\n",
      "Epoch [3/3], Batch [993/2500], Loss: 0.2594107389450073\n",
      "Epoch [3/3], Batch [994/2500], Loss: 0.036147285252809525\n",
      "Epoch [3/3], Batch [995/2500], Loss: 0.02865266241133213\n",
      "Epoch [3/3], Batch [996/2500], Loss: 0.021777763962745667\n",
      "Epoch [3/3], Batch [997/2500], Loss: 0.029356542974710464\n",
      "Epoch [3/3], Batch [998/2500], Loss: 0.08557885885238647\n",
      "Epoch [3/3], Batch [999/2500], Loss: 0.03728489577770233\n",
      "Epoch [3/3], Batch [1000/2500], Loss: 0.09024202823638916\n",
      "Epoch [3/3], Batch [1001/2500], Loss: 0.022015798836946487\n",
      "Epoch [3/3], Batch [1002/2500], Loss: 0.16493459045886993\n",
      "Epoch [3/3], Batch [1003/2500], Loss: 0.016282904893159866\n",
      "Epoch [3/3], Batch [1004/2500], Loss: 0.018001332879066467\n",
      "Epoch [3/3], Batch [1005/2500], Loss: 0.019700773060321808\n",
      "Epoch [3/3], Batch [1006/2500], Loss: 0.0906299501657486\n",
      "Epoch [3/3], Batch [1007/2500], Loss: 0.012052217498421669\n",
      "Epoch [3/3], Batch [1008/2500], Loss: 0.16809040307998657\n",
      "Epoch [3/3], Batch [1009/2500], Loss: 0.050247929990291595\n",
      "Epoch [3/3], Batch [1010/2500], Loss: 0.21589934825897217\n",
      "Epoch [3/3], Batch [1011/2500], Loss: 0.020883429795503616\n",
      "Epoch [3/3], Batch [1012/2500], Loss: 0.35987389087677\n",
      "Epoch [3/3], Batch [1013/2500], Loss: 0.29745087027549744\n",
      "Epoch [3/3], Batch [1014/2500], Loss: 0.1176982969045639\n",
      "Epoch [3/3], Batch [1015/2500], Loss: 0.040795452892780304\n",
      "Epoch [3/3], Batch [1016/2500], Loss: 0.04633970558643341\n",
      "Epoch [3/3], Batch [1017/2500], Loss: 0.09982874244451523\n",
      "Epoch [3/3], Batch [1018/2500], Loss: 0.14053131639957428\n",
      "Epoch [3/3], Batch [1019/2500], Loss: 0.077476866543293\n",
      "Epoch [3/3], Batch [1020/2500], Loss: 0.2835281789302826\n",
      "Epoch [3/3], Batch [1021/2500], Loss: 0.12738734483718872\n",
      "Epoch [3/3], Batch [1022/2500], Loss: 0.09662076085805893\n",
      "Epoch [3/3], Batch [1023/2500], Loss: 0.7276803851127625\n",
      "Epoch [3/3], Batch [1024/2500], Loss: 0.010079262778162956\n",
      "Epoch [3/3], Batch [1025/2500], Loss: 0.05731964856386185\n",
      "Epoch [3/3], Batch [1026/2500], Loss: 0.39128780364990234\n",
      "Epoch [3/3], Batch [1027/2500], Loss: 0.041767291724681854\n",
      "Epoch [3/3], Batch [1028/2500], Loss: 0.21786826848983765\n",
      "Epoch [3/3], Batch [1029/2500], Loss: 0.19070006906986237\n",
      "Epoch [3/3], Batch [1030/2500], Loss: 0.1338702142238617\n",
      "Epoch [3/3], Batch [1031/2500], Loss: 0.2681175172328949\n",
      "Epoch [3/3], Batch [1032/2500], Loss: 0.45383575558662415\n",
      "Epoch [3/3], Batch [1033/2500], Loss: 0.0925104022026062\n",
      "Epoch [3/3], Batch [1034/2500], Loss: 0.1255303919315338\n",
      "Epoch [3/3], Batch [1035/2500], Loss: 0.24271368980407715\n",
      "Epoch [3/3], Batch [1036/2500], Loss: 0.019822265952825546\n",
      "Epoch [3/3], Batch [1037/2500], Loss: 0.0598907433450222\n",
      "Epoch [3/3], Batch [1038/2500], Loss: 0.021287329494953156\n",
      "Epoch [3/3], Batch [1039/2500], Loss: 0.015001822263002396\n",
      "Epoch [3/3], Batch [1040/2500], Loss: 0.06929711252450943\n",
      "Epoch [3/3], Batch [1041/2500], Loss: 0.4307270348072052\n",
      "Epoch [3/3], Batch [1042/2500], Loss: 0.04408871382474899\n",
      "Epoch [3/3], Batch [1043/2500], Loss: 0.40314385294914246\n",
      "Epoch [3/3], Batch [1044/2500], Loss: 0.07051265984773636\n",
      "Epoch [3/3], Batch [1045/2500], Loss: 0.06035975366830826\n",
      "Epoch [3/3], Batch [1046/2500], Loss: 0.39189183712005615\n",
      "Epoch [3/3], Batch [1047/2500], Loss: 0.32131925225257874\n",
      "Epoch [3/3], Batch [1048/2500], Loss: 0.2577251195907593\n",
      "Epoch [3/3], Batch [1049/2500], Loss: 0.013465086929500103\n",
      "Epoch [3/3], Batch [1050/2500], Loss: 0.18693651258945465\n",
      "Epoch [3/3], Batch [1051/2500], Loss: 0.036797113716602325\n",
      "Epoch [3/3], Batch [1052/2500], Loss: 0.03336513414978981\n",
      "Epoch [3/3], Batch [1053/2500], Loss: 0.16674119234085083\n",
      "Epoch [3/3], Batch [1054/2500], Loss: 0.1406966745853424\n",
      "Epoch [3/3], Batch [1055/2500], Loss: 0.015321067534387112\n",
      "Epoch [3/3], Batch [1056/2500], Loss: 0.08358491212129593\n",
      "Epoch [3/3], Batch [1057/2500], Loss: 0.07403583824634552\n",
      "Epoch [3/3], Batch [1058/2500], Loss: 0.02070796862244606\n",
      "Epoch [3/3], Batch [1059/2500], Loss: 0.08558817952871323\n",
      "Epoch [3/3], Batch [1060/2500], Loss: 0.06361807137727737\n",
      "Epoch [3/3], Batch [1061/2500], Loss: 0.15444888174533844\n",
      "Epoch [3/3], Batch [1062/2500], Loss: 0.20062677562236786\n",
      "Epoch [3/3], Batch [1063/2500], Loss: 0.04389280825853348\n",
      "Epoch [3/3], Batch [1064/2500], Loss: 0.15544262528419495\n",
      "Epoch [3/3], Batch [1065/2500], Loss: 0.11970868706703186\n",
      "Epoch [3/3], Batch [1066/2500], Loss: 0.04960962384939194\n",
      "Epoch [3/3], Batch [1067/2500], Loss: 0.06743131577968597\n",
      "Epoch [3/3], Batch [1068/2500], Loss: 0.2040756344795227\n",
      "Epoch [3/3], Batch [1069/2500], Loss: 0.06788963824510574\n",
      "Epoch [3/3], Batch [1070/2500], Loss: 0.1230805516242981\n",
      "Epoch [3/3], Batch [1071/2500], Loss: 0.07391652464866638\n",
      "Epoch [3/3], Batch [1072/2500], Loss: 0.21421654522418976\n",
      "Epoch [3/3], Batch [1073/2500], Loss: 0.039739690721035004\n",
      "Epoch [3/3], Batch [1074/2500], Loss: 0.14636696875095367\n",
      "Epoch [3/3], Batch [1075/2500], Loss: 0.06219853460788727\n",
      "Epoch [3/3], Batch [1076/2500], Loss: 0.0299774631857872\n",
      "Epoch [3/3], Batch [1077/2500], Loss: 0.4544523358345032\n",
      "Epoch [3/3], Batch [1078/2500], Loss: 0.020974157378077507\n",
      "Epoch [3/3], Batch [1079/2500], Loss: 0.058694880455732346\n",
      "Epoch [3/3], Batch [1080/2500], Loss: 0.03028791956603527\n",
      "Epoch [3/3], Batch [1081/2500], Loss: 0.23316584527492523\n",
      "Epoch [3/3], Batch [1082/2500], Loss: 0.3044053018093109\n",
      "Epoch [3/3], Batch [1083/2500], Loss: 0.05572183430194855\n",
      "Epoch [3/3], Batch [1084/2500], Loss: 0.05674626678228378\n",
      "Epoch [3/3], Batch [1085/2500], Loss: 0.015164497308433056\n",
      "Epoch [3/3], Batch [1086/2500], Loss: 0.08408921211957932\n",
      "Epoch [3/3], Batch [1087/2500], Loss: 0.12514564394950867\n",
      "Epoch [3/3], Batch [1088/2500], Loss: 0.01840897649526596\n",
      "Epoch [3/3], Batch [1089/2500], Loss: 0.15738347172737122\n",
      "Epoch [3/3], Batch [1090/2500], Loss: 0.2364826798439026\n",
      "Epoch [3/3], Batch [1091/2500], Loss: 0.010343286208808422\n",
      "Epoch [3/3], Batch [1092/2500], Loss: 0.01872207596898079\n",
      "Epoch [3/3], Batch [1093/2500], Loss: 0.11766847968101501\n",
      "Epoch [3/3], Batch [1094/2500], Loss: 0.1862044632434845\n",
      "Epoch [3/3], Batch [1095/2500], Loss: 0.08914276957511902\n",
      "Epoch [3/3], Batch [1096/2500], Loss: 0.14200547337532043\n",
      "Epoch [3/3], Batch [1097/2500], Loss: 0.18335884809494019\n",
      "Epoch [3/3], Batch [1098/2500], Loss: 0.05495879054069519\n",
      "Epoch [3/3], Batch [1099/2500], Loss: 0.047643739730119705\n",
      "Epoch [3/3], Batch [1100/2500], Loss: 0.02913961559534073\n",
      "Epoch [3/3], Batch [1101/2500], Loss: 0.02995690517127514\n",
      "Epoch [3/3], Batch [1102/2500], Loss: 0.13462717831134796\n",
      "Epoch [3/3], Batch [1103/2500], Loss: 0.0907004103064537\n",
      "Epoch [3/3], Batch [1104/2500], Loss: 0.021154440939426422\n",
      "Epoch [3/3], Batch [1105/2500], Loss: 0.013394448906183243\n",
      "Epoch [3/3], Batch [1106/2500], Loss: 0.11897643655538559\n",
      "Epoch [3/3], Batch [1107/2500], Loss: 0.055147185921669006\n",
      "Epoch [3/3], Batch [1108/2500], Loss: 0.011471682228147984\n",
      "Epoch [3/3], Batch [1109/2500], Loss: 0.023518512025475502\n",
      "Epoch [3/3], Batch [1110/2500], Loss: 0.025311624631285667\n",
      "Epoch [3/3], Batch [1111/2500], Loss: 0.03384298086166382\n",
      "Epoch [3/3], Batch [1112/2500], Loss: 0.5975717306137085\n",
      "Epoch [3/3], Batch [1113/2500], Loss: 0.04492790997028351\n",
      "Epoch [3/3], Batch [1114/2500], Loss: 0.14195294678211212\n",
      "Epoch [3/3], Batch [1115/2500], Loss: 0.1098274439573288\n",
      "Epoch [3/3], Batch [1116/2500], Loss: 0.17780956625938416\n",
      "Epoch [3/3], Batch [1117/2500], Loss: 0.16953296959400177\n",
      "Epoch [3/3], Batch [1118/2500], Loss: 0.022209275513887405\n",
      "Epoch [3/3], Batch [1119/2500], Loss: 0.044414594769477844\n",
      "Epoch [3/3], Batch [1120/2500], Loss: 0.01587955839931965\n",
      "Epoch [3/3], Batch [1121/2500], Loss: 0.025399141013622284\n",
      "Epoch [3/3], Batch [1122/2500], Loss: 0.028011484071612358\n",
      "Epoch [3/3], Batch [1123/2500], Loss: 0.5152813196182251\n",
      "Epoch [3/3], Batch [1124/2500], Loss: 0.5292643904685974\n",
      "Epoch [3/3], Batch [1125/2500], Loss: 0.00912491325289011\n",
      "Epoch [3/3], Batch [1126/2500], Loss: 0.019644731655716896\n",
      "Epoch [3/3], Batch [1127/2500], Loss: 0.13317066431045532\n",
      "Epoch [3/3], Batch [1128/2500], Loss: 0.2706245183944702\n",
      "Epoch [3/3], Batch [1129/2500], Loss: 0.030080856755375862\n",
      "Epoch [3/3], Batch [1130/2500], Loss: 0.32036054134368896\n",
      "Epoch [3/3], Batch [1131/2500], Loss: 0.16327786445617676\n",
      "Epoch [3/3], Batch [1132/2500], Loss: 0.044699542224407196\n",
      "Epoch [3/3], Batch [1133/2500], Loss: 0.7279530167579651\n",
      "Epoch [3/3], Batch [1134/2500], Loss: 0.17181265354156494\n",
      "Epoch [3/3], Batch [1135/2500], Loss: 0.026874851435422897\n",
      "Epoch [3/3], Batch [1136/2500], Loss: 0.03985122963786125\n",
      "Epoch [3/3], Batch [1137/2500], Loss: 0.6003729701042175\n",
      "Epoch [3/3], Batch [1138/2500], Loss: 0.20773057639598846\n",
      "Epoch [3/3], Batch [1139/2500], Loss: 0.06920035183429718\n",
      "Epoch [3/3], Batch [1140/2500], Loss: 0.04615546017885208\n",
      "Epoch [3/3], Batch [1141/2500], Loss: 0.1622411459684372\n",
      "Epoch [3/3], Batch [1142/2500], Loss: 0.03876333683729172\n",
      "Epoch [3/3], Batch [1143/2500], Loss: 0.033706460148096085\n",
      "Epoch [3/3], Batch [1144/2500], Loss: 0.03828132525086403\n",
      "Epoch [3/3], Batch [1145/2500], Loss: 0.08295680582523346\n",
      "Epoch [3/3], Batch [1146/2500], Loss: 0.022552702575922012\n",
      "Epoch [3/3], Batch [1147/2500], Loss: 0.05166948586702347\n",
      "Epoch [3/3], Batch [1148/2500], Loss: 0.015388239175081253\n",
      "Epoch [3/3], Batch [1149/2500], Loss: 0.031144501641392708\n",
      "Epoch [3/3], Batch [1150/2500], Loss: 0.17158925533294678\n",
      "Epoch [3/3], Batch [1151/2500], Loss: 0.028323614969849586\n",
      "Epoch [3/3], Batch [1152/2500], Loss: 0.09770729392766953\n",
      "Epoch [3/3], Batch [1153/2500], Loss: 0.22022207081317902\n",
      "Epoch [3/3], Batch [1154/2500], Loss: 0.16408687829971313\n",
      "Epoch [3/3], Batch [1155/2500], Loss: 0.05634646490216255\n",
      "Epoch [3/3], Batch [1156/2500], Loss: 0.1693839132785797\n",
      "Epoch [3/3], Batch [1157/2500], Loss: 0.11713112890720367\n",
      "Epoch [3/3], Batch [1158/2500], Loss: 0.01739436760544777\n",
      "Epoch [3/3], Batch [1159/2500], Loss: 0.06471290439367294\n",
      "Epoch [3/3], Batch [1160/2500], Loss: 0.28016000986099243\n",
      "Epoch [3/3], Batch [1161/2500], Loss: 0.021525874733924866\n",
      "Epoch [3/3], Batch [1162/2500], Loss: 0.20650549232959747\n",
      "Epoch [3/3], Batch [1163/2500], Loss: 0.017969276756048203\n",
      "Epoch [3/3], Batch [1164/2500], Loss: 0.021162856370210648\n",
      "Epoch [3/3], Batch [1165/2500], Loss: 0.018167879432439804\n",
      "Epoch [3/3], Batch [1166/2500], Loss: 0.10524167865514755\n",
      "Epoch [3/3], Batch [1167/2500], Loss: 0.013922661542892456\n",
      "Epoch [3/3], Batch [1168/2500], Loss: 0.025960132479667664\n",
      "Epoch [3/3], Batch [1169/2500], Loss: 0.7717034220695496\n",
      "Epoch [3/3], Batch [1170/2500], Loss: 0.0444561168551445\n",
      "Epoch [3/3], Batch [1171/2500], Loss: 0.26247867941856384\n",
      "Epoch [3/3], Batch [1172/2500], Loss: 0.044489629566669464\n",
      "Epoch [3/3], Batch [1173/2500], Loss: 0.7104762196540833\n",
      "Epoch [3/3], Batch [1174/2500], Loss: 0.29764890670776367\n",
      "Epoch [3/3], Batch [1175/2500], Loss: 0.14292722940444946\n",
      "Epoch [3/3], Batch [1176/2500], Loss: 0.17219087481498718\n",
      "Epoch [3/3], Batch [1177/2500], Loss: 0.34443309903144836\n",
      "Epoch [3/3], Batch [1178/2500], Loss: 0.3209778964519501\n",
      "Epoch [3/3], Batch [1179/2500], Loss: 0.19735679030418396\n",
      "Epoch [3/3], Batch [1180/2500], Loss: 0.03057953715324402\n",
      "Epoch [3/3], Batch [1181/2500], Loss: 0.1849743276834488\n",
      "Epoch [3/3], Batch [1182/2500], Loss: 0.033528029918670654\n",
      "Epoch [3/3], Batch [1183/2500], Loss: 0.2893751859664917\n",
      "Epoch [3/3], Batch [1184/2500], Loss: 0.16127081215381622\n",
      "Epoch [3/3], Batch [1185/2500], Loss: 0.12070118635892868\n",
      "Epoch [3/3], Batch [1186/2500], Loss: 0.24670711159706116\n",
      "Epoch [3/3], Batch [1187/2500], Loss: 0.0835498571395874\n",
      "Epoch [3/3], Batch [1188/2500], Loss: 0.12041458487510681\n",
      "Epoch [3/3], Batch [1189/2500], Loss: 0.11406193673610687\n",
      "Epoch [3/3], Batch [1190/2500], Loss: 0.10042081028223038\n",
      "Epoch [3/3], Batch [1191/2500], Loss: 0.12340820580720901\n",
      "Epoch [3/3], Batch [1192/2500], Loss: 0.18050505220890045\n",
      "Epoch [3/3], Batch [1193/2500], Loss: 0.09082096815109253\n",
      "Epoch [3/3], Batch [1194/2500], Loss: 0.18044118583202362\n",
      "Epoch [3/3], Batch [1195/2500], Loss: 0.05686408281326294\n",
      "Epoch [3/3], Batch [1196/2500], Loss: 0.11287998408079147\n",
      "Epoch [3/3], Batch [1197/2500], Loss: 0.2704814374446869\n",
      "Epoch [3/3], Batch [1198/2500], Loss: 0.0977194532752037\n",
      "Epoch [3/3], Batch [1199/2500], Loss: 0.06728847324848175\n",
      "Epoch [3/3], Batch [1200/2500], Loss: 0.1743149757385254\n",
      "Epoch [3/3], Batch [1201/2500], Loss: 0.22331321239471436\n",
      "Epoch [3/3], Batch [1202/2500], Loss: 0.07249592989683151\n",
      "Epoch [3/3], Batch [1203/2500], Loss: 0.07830505818128586\n",
      "Epoch [3/3], Batch [1204/2500], Loss: 0.3479783833026886\n",
      "Epoch [3/3], Batch [1205/2500], Loss: 0.1210516095161438\n",
      "Epoch [3/3], Batch [1206/2500], Loss: 0.19749464094638824\n",
      "Epoch [3/3], Batch [1207/2500], Loss: 0.2425726354122162\n",
      "Epoch [3/3], Batch [1208/2500], Loss: 0.04164790362119675\n",
      "Epoch [3/3], Batch [1209/2500], Loss: 0.09880363941192627\n",
      "Epoch [3/3], Batch [1210/2500], Loss: 0.18471930921077728\n",
      "Epoch [3/3], Batch [1211/2500], Loss: 0.04608666151762009\n",
      "Epoch [3/3], Batch [1212/2500], Loss: 0.13980625569820404\n",
      "Epoch [3/3], Batch [1213/2500], Loss: 0.14208701252937317\n",
      "Epoch [3/3], Batch [1214/2500], Loss: 0.1433468759059906\n",
      "Epoch [3/3], Batch [1215/2500], Loss: 0.04639527201652527\n",
      "Epoch [3/3], Batch [1216/2500], Loss: 0.22468619048595428\n",
      "Epoch [3/3], Batch [1217/2500], Loss: 0.04249747470021248\n",
      "Epoch [3/3], Batch [1218/2500], Loss: 0.04793292284011841\n",
      "Epoch [3/3], Batch [1219/2500], Loss: 0.06210383027791977\n",
      "Epoch [3/3], Batch [1220/2500], Loss: 0.10995685309171677\n",
      "Epoch [3/3], Batch [1221/2500], Loss: 0.2950577735900879\n",
      "Epoch [3/3], Batch [1222/2500], Loss: 0.03495647758245468\n",
      "Epoch [3/3], Batch [1223/2500], Loss: 0.02697048708796501\n",
      "Epoch [3/3], Batch [1224/2500], Loss: 0.09410881996154785\n",
      "Epoch [3/3], Batch [1225/2500], Loss: 0.10025698691606522\n",
      "Epoch [3/3], Batch [1226/2500], Loss: 0.2389141023159027\n",
      "Epoch [3/3], Batch [1227/2500], Loss: 0.2205067276954651\n",
      "Epoch [3/3], Batch [1228/2500], Loss: 0.2077201008796692\n",
      "Epoch [3/3], Batch [1229/2500], Loss: 0.24330103397369385\n",
      "Epoch [3/3], Batch [1230/2500], Loss: 0.04963202774524689\n",
      "Epoch [3/3], Batch [1231/2500], Loss: 0.04592205956578255\n",
      "Epoch [3/3], Batch [1232/2500], Loss: 0.058679305016994476\n",
      "Epoch [3/3], Batch [1233/2500], Loss: 0.039076995104551315\n",
      "Epoch [3/3], Batch [1234/2500], Loss: 0.2762150466442108\n",
      "Epoch [3/3], Batch [1235/2500], Loss: 0.08169850707054138\n",
      "Epoch [3/3], Batch [1236/2500], Loss: 0.07838726043701172\n",
      "Epoch [3/3], Batch [1237/2500], Loss: 0.3429202437400818\n",
      "Epoch [3/3], Batch [1238/2500], Loss: 0.09225938469171524\n",
      "Epoch [3/3], Batch [1239/2500], Loss: 0.06746181100606918\n",
      "Epoch [3/3], Batch [1240/2500], Loss: 0.0442688949406147\n",
      "Epoch [3/3], Batch [1241/2500], Loss: 0.08329936116933823\n",
      "Epoch [3/3], Batch [1242/2500], Loss: 0.13718292117118835\n",
      "Epoch [3/3], Batch [1243/2500], Loss: 0.014291087165474892\n",
      "Epoch [3/3], Batch [1244/2500], Loss: 0.04245726391673088\n",
      "Epoch [3/3], Batch [1245/2500], Loss: 0.07491953670978546\n",
      "Epoch [3/3], Batch [1246/2500], Loss: 0.07790806144475937\n",
      "Epoch [3/3], Batch [1247/2500], Loss: 0.056622784584760666\n",
      "Epoch [3/3], Batch [1248/2500], Loss: 0.02437877655029297\n",
      "Epoch [3/3], Batch [1249/2500], Loss: 0.052163511514663696\n",
      "Epoch [3/3], Batch [1250/2500], Loss: 0.02490559034049511\n",
      "Epoch [3/3], Batch [1251/2500], Loss: 0.044373106211423874\n",
      "Epoch [3/3], Batch [1252/2500], Loss: 0.04370945319533348\n",
      "Epoch [3/3], Batch [1253/2500], Loss: 0.12544716894626617\n",
      "Epoch [3/3], Batch [1254/2500], Loss: 0.032224856317043304\n",
      "Epoch [3/3], Batch [1255/2500], Loss: 0.30322012305259705\n",
      "Epoch [3/3], Batch [1256/2500], Loss: 0.09993095695972443\n",
      "Epoch [3/3], Batch [1257/2500], Loss: 0.019671574234962463\n",
      "Epoch [3/3], Batch [1258/2500], Loss: 0.24178069829940796\n",
      "Epoch [3/3], Batch [1259/2500], Loss: 0.026798110455274582\n",
      "Epoch [3/3], Batch [1260/2500], Loss: 0.5341798663139343\n",
      "Epoch [3/3], Batch [1261/2500], Loss: 0.039079174399375916\n",
      "Epoch [3/3], Batch [1262/2500], Loss: 0.012643793597817421\n",
      "Epoch [3/3], Batch [1263/2500], Loss: 0.05567161366343498\n",
      "Epoch [3/3], Batch [1264/2500], Loss: 0.017208755016326904\n",
      "Epoch [3/3], Batch [1265/2500], Loss: 0.31534844636917114\n",
      "Epoch [3/3], Batch [1266/2500], Loss: 0.045858561992645264\n",
      "Epoch [3/3], Batch [1267/2500], Loss: 0.04155383259057999\n",
      "Epoch [3/3], Batch [1268/2500], Loss: 0.1792459487915039\n",
      "Epoch [3/3], Batch [1269/2500], Loss: 0.0738687738776207\n",
      "Epoch [3/3], Batch [1270/2500], Loss: 0.304111123085022\n",
      "Epoch [3/3], Batch [1271/2500], Loss: 0.05770694464445114\n",
      "Epoch [3/3], Batch [1272/2500], Loss: 0.03735335171222687\n",
      "Epoch [3/3], Batch [1273/2500], Loss: 0.07970961928367615\n",
      "Epoch [3/3], Batch [1274/2500], Loss: 0.012091945856809616\n",
      "Epoch [3/3], Batch [1275/2500], Loss: 0.08490819483995438\n",
      "Epoch [3/3], Batch [1276/2500], Loss: 0.4292077124118805\n",
      "Epoch [3/3], Batch [1277/2500], Loss: 0.06247866526246071\n",
      "Epoch [3/3], Batch [1278/2500], Loss: 0.39210695028305054\n",
      "Epoch [3/3], Batch [1279/2500], Loss: 0.010710157454013824\n",
      "Epoch [3/3], Batch [1280/2500], Loss: 0.08676467835903168\n",
      "Epoch [3/3], Batch [1281/2500], Loss: 0.023391403257846832\n",
      "Epoch [3/3], Batch [1282/2500], Loss: 0.021494060754776\n",
      "Epoch [3/3], Batch [1283/2500], Loss: 0.031225722283124924\n",
      "Epoch [3/3], Batch [1284/2500], Loss: 0.18188095092773438\n",
      "Epoch [3/3], Batch [1285/2500], Loss: 0.37249115109443665\n",
      "Epoch [3/3], Batch [1286/2500], Loss: 0.05845371261239052\n",
      "Epoch [3/3], Batch [1287/2500], Loss: 0.12276443839073181\n",
      "Epoch [3/3], Batch [1288/2500], Loss: 0.05566824600100517\n",
      "Epoch [3/3], Batch [1289/2500], Loss: 0.04736483097076416\n",
      "Epoch [3/3], Batch [1290/2500], Loss: 0.10610856860876083\n",
      "Epoch [3/3], Batch [1291/2500], Loss: 0.043398864567279816\n",
      "Epoch [3/3], Batch [1292/2500], Loss: 0.015830866992473602\n",
      "Epoch [3/3], Batch [1293/2500], Loss: 0.1032046377658844\n",
      "Epoch [3/3], Batch [1294/2500], Loss: 0.050507836043834686\n",
      "Epoch [3/3], Batch [1295/2500], Loss: 0.09865905344486237\n",
      "Epoch [3/3], Batch [1296/2500], Loss: 0.04926706850528717\n",
      "Epoch [3/3], Batch [1297/2500], Loss: 0.5998039245605469\n",
      "Epoch [3/3], Batch [1298/2500], Loss: 0.030366893857717514\n",
      "Epoch [3/3], Batch [1299/2500], Loss: 0.027213294059038162\n",
      "Epoch [3/3], Batch [1300/2500], Loss: 0.039584580808877945\n",
      "Epoch [3/3], Batch [1301/2500], Loss: 0.4325745701789856\n",
      "Epoch [3/3], Batch [1302/2500], Loss: 0.013191847130656242\n",
      "Epoch [3/3], Batch [1303/2500], Loss: 0.029293961822986603\n",
      "Epoch [3/3], Batch [1304/2500], Loss: 0.01617402955889702\n",
      "Epoch [3/3], Batch [1305/2500], Loss: 0.027084972709417343\n",
      "Epoch [3/3], Batch [1306/2500], Loss: 0.050185248255729675\n",
      "Epoch [3/3], Batch [1307/2500], Loss: 0.19362366199493408\n",
      "Epoch [3/3], Batch [1308/2500], Loss: 0.05295560508966446\n",
      "Epoch [3/3], Batch [1309/2500], Loss: 0.0776938796043396\n",
      "Epoch [3/3], Batch [1310/2500], Loss: 0.044252026826143265\n",
      "Epoch [3/3], Batch [1311/2500], Loss: 0.038337644189596176\n",
      "Epoch [3/3], Batch [1312/2500], Loss: 0.02368852123618126\n",
      "Epoch [3/3], Batch [1313/2500], Loss: 0.5672903656959534\n",
      "Epoch [3/3], Batch [1314/2500], Loss: 0.07183891534805298\n",
      "Epoch [3/3], Batch [1315/2500], Loss: 0.030663399025797844\n",
      "Epoch [3/3], Batch [1316/2500], Loss: 0.01615987718105316\n",
      "Epoch [3/3], Batch [1317/2500], Loss: 0.48051029443740845\n",
      "Epoch [3/3], Batch [1318/2500], Loss: 0.013108907267451286\n",
      "Epoch [3/3], Batch [1319/2500], Loss: 0.050331078469753265\n",
      "Epoch [3/3], Batch [1320/2500], Loss: 0.07663474231958389\n",
      "Epoch [3/3], Batch [1321/2500], Loss: 0.05845378339290619\n",
      "Epoch [3/3], Batch [1322/2500], Loss: 0.0381971038877964\n",
      "Epoch [3/3], Batch [1323/2500], Loss: 0.4244101345539093\n",
      "Epoch [3/3], Batch [1324/2500], Loss: 0.08427563309669495\n",
      "Epoch [3/3], Batch [1325/2500], Loss: 0.07375650852918625\n",
      "Epoch [3/3], Batch [1326/2500], Loss: 0.025943081825971603\n",
      "Epoch [3/3], Batch [1327/2500], Loss: 0.4112779498100281\n",
      "Epoch [3/3], Batch [1328/2500], Loss: 0.014192920178174973\n",
      "Epoch [3/3], Batch [1329/2500], Loss: 0.099266417324543\n",
      "Epoch [3/3], Batch [1330/2500], Loss: 0.02031807042658329\n",
      "Epoch [3/3], Batch [1331/2500], Loss: 0.022032316774129868\n",
      "Epoch [3/3], Batch [1332/2500], Loss: 0.12721817195415497\n",
      "Epoch [3/3], Batch [1333/2500], Loss: 0.09605622291564941\n",
      "Epoch [3/3], Batch [1334/2500], Loss: 0.11247415840625763\n",
      "Epoch [3/3], Batch [1335/2500], Loss: 0.015228921547532082\n",
      "Epoch [3/3], Batch [1336/2500], Loss: 0.09209266304969788\n",
      "Epoch [3/3], Batch [1337/2500], Loss: 0.043453410267829895\n",
      "Epoch [3/3], Batch [1338/2500], Loss: 0.052198752760887146\n",
      "Epoch [3/3], Batch [1339/2500], Loss: 0.36594149470329285\n",
      "Epoch [3/3], Batch [1340/2500], Loss: 0.11383306980133057\n",
      "Epoch [3/3], Batch [1341/2500], Loss: 0.0466659739613533\n",
      "Epoch [3/3], Batch [1342/2500], Loss: 0.11300577223300934\n",
      "Epoch [3/3], Batch [1343/2500], Loss: 0.06208697706460953\n",
      "Epoch [3/3], Batch [1344/2500], Loss: 0.3525485694408417\n",
      "Epoch [3/3], Batch [1345/2500], Loss: 0.30830585956573486\n",
      "Epoch [3/3], Batch [1346/2500], Loss: 0.24125899374485016\n",
      "Epoch [3/3], Batch [1347/2500], Loss: 0.07545273005962372\n",
      "Epoch [3/3], Batch [1348/2500], Loss: 0.31859534978866577\n",
      "Epoch [3/3], Batch [1349/2500], Loss: 0.07110822200775146\n",
      "Epoch [3/3], Batch [1350/2500], Loss: 0.039819106459617615\n",
      "Epoch [3/3], Batch [1351/2500], Loss: 0.04674944281578064\n",
      "Epoch [3/3], Batch [1352/2500], Loss: 0.037788182497024536\n",
      "Epoch [3/3], Batch [1353/2500], Loss: 0.2032320201396942\n",
      "Epoch [3/3], Batch [1354/2500], Loss: 0.05215625837445259\n",
      "Epoch [3/3], Batch [1355/2500], Loss: 0.6761269569396973\n",
      "Epoch [3/3], Batch [1356/2500], Loss: 0.13486894965171814\n",
      "Epoch [3/3], Batch [1357/2500], Loss: 0.08266138285398483\n",
      "Epoch [3/3], Batch [1358/2500], Loss: 0.15837518870830536\n",
      "Epoch [3/3], Batch [1359/2500], Loss: 0.03881584107875824\n",
      "Epoch [3/3], Batch [1360/2500], Loss: 0.04527172073721886\n",
      "Epoch [3/3], Batch [1361/2500], Loss: 0.28926992416381836\n",
      "Epoch [3/3], Batch [1362/2500], Loss: 0.10859846323728561\n",
      "Epoch [3/3], Batch [1363/2500], Loss: 0.09206610918045044\n",
      "Epoch [3/3], Batch [1364/2500], Loss: 0.25350210070610046\n",
      "Epoch [3/3], Batch [1365/2500], Loss: 0.05965203791856766\n",
      "Epoch [3/3], Batch [1366/2500], Loss: 0.028820408508181572\n",
      "Epoch [3/3], Batch [1367/2500], Loss: 0.212733194231987\n",
      "Epoch [3/3], Batch [1368/2500], Loss: 0.43291792273521423\n",
      "Epoch [3/3], Batch [1369/2500], Loss: 0.16822467744350433\n",
      "Epoch [3/3], Batch [1370/2500], Loss: 0.02099219709634781\n",
      "Epoch [3/3], Batch [1371/2500], Loss: 0.050945527851581573\n",
      "Epoch [3/3], Batch [1372/2500], Loss: 0.013083962723612785\n",
      "Epoch [3/3], Batch [1373/2500], Loss: 0.3129560947418213\n",
      "Epoch [3/3], Batch [1374/2500], Loss: 0.04387024790048599\n",
      "Epoch [3/3], Batch [1375/2500], Loss: 0.25143197178840637\n",
      "Epoch [3/3], Batch [1376/2500], Loss: 0.05434795841574669\n",
      "Epoch [3/3], Batch [1377/2500], Loss: 0.12497983872890472\n",
      "Epoch [3/3], Batch [1378/2500], Loss: 0.21167390048503876\n",
      "Epoch [3/3], Batch [1379/2500], Loss: 0.06678827106952667\n",
      "Epoch [3/3], Batch [1380/2500], Loss: 0.3239918053150177\n",
      "Epoch [3/3], Batch [1381/2500], Loss: 0.33499056100845337\n",
      "Epoch [3/3], Batch [1382/2500], Loss: 0.0940919816493988\n",
      "Epoch [3/3], Batch [1383/2500], Loss: 0.11249716579914093\n",
      "Epoch [3/3], Batch [1384/2500], Loss: 0.14671218395233154\n",
      "Epoch [3/3], Batch [1385/2500], Loss: 0.4274763762950897\n",
      "Epoch [3/3], Batch [1386/2500], Loss: 0.06975319236516953\n",
      "Epoch [3/3], Batch [1387/2500], Loss: 0.16567905247211456\n",
      "Epoch [3/3], Batch [1388/2500], Loss: 0.2620238661766052\n",
      "Epoch [3/3], Batch [1389/2500], Loss: 0.0603141151368618\n",
      "Epoch [3/3], Batch [1390/2500], Loss: 0.01603928580880165\n",
      "Epoch [3/3], Batch [1391/2500], Loss: 0.06145381182432175\n",
      "Epoch [3/3], Batch [1392/2500], Loss: 0.030275195837020874\n",
      "Epoch [3/3], Batch [1393/2500], Loss: 0.19082608819007874\n",
      "Epoch [3/3], Batch [1394/2500], Loss: 0.22184047102928162\n",
      "Epoch [3/3], Batch [1395/2500], Loss: 0.22159889340400696\n",
      "Epoch [3/3], Batch [1396/2500], Loss: 0.20204630494117737\n",
      "Epoch [3/3], Batch [1397/2500], Loss: 0.2994561493396759\n",
      "Epoch [3/3], Batch [1398/2500], Loss: 0.09126581251621246\n",
      "Epoch [3/3], Batch [1399/2500], Loss: 0.1625230461359024\n",
      "Epoch [3/3], Batch [1400/2500], Loss: 0.08619770407676697\n",
      "Epoch [3/3], Batch [1401/2500], Loss: 0.17320528626441956\n",
      "Epoch [3/3], Batch [1402/2500], Loss: 0.02206939458847046\n",
      "Epoch [3/3], Batch [1403/2500], Loss: 0.24343881011009216\n",
      "Epoch [3/3], Batch [1404/2500], Loss: 0.011646810919046402\n",
      "Epoch [3/3], Batch [1405/2500], Loss: 0.4070931375026703\n",
      "Epoch [3/3], Batch [1406/2500], Loss: 0.05752566456794739\n",
      "Epoch [3/3], Batch [1407/2500], Loss: 0.1946258842945099\n",
      "Epoch [3/3], Batch [1408/2500], Loss: 0.37041226029396057\n",
      "Epoch [3/3], Batch [1409/2500], Loss: 0.24973459541797638\n",
      "Epoch [3/3], Batch [1410/2500], Loss: 0.08800435811281204\n",
      "Epoch [3/3], Batch [1411/2500], Loss: 0.2826955020427704\n",
      "Epoch [3/3], Batch [1412/2500], Loss: 0.029555629938840866\n",
      "Epoch [3/3], Batch [1413/2500], Loss: 0.01387925073504448\n",
      "Epoch [3/3], Batch [1414/2500], Loss: 0.560860812664032\n",
      "Epoch [3/3], Batch [1415/2500], Loss: 0.20269827544689178\n",
      "Epoch [3/3], Batch [1416/2500], Loss: 0.10709799826145172\n",
      "Epoch [3/3], Batch [1417/2500], Loss: 0.07971727848052979\n",
      "Epoch [3/3], Batch [1418/2500], Loss: 0.2866080403327942\n",
      "Epoch [3/3], Batch [1419/2500], Loss: 0.1922864019870758\n",
      "Epoch [3/3], Batch [1420/2500], Loss: 0.46482256054878235\n",
      "Epoch [3/3], Batch [1421/2500], Loss: 0.09876859188079834\n",
      "Epoch [3/3], Batch [1422/2500], Loss: 0.17603342235088348\n",
      "Epoch [3/3], Batch [1423/2500], Loss: 0.03135407716035843\n",
      "Epoch [3/3], Batch [1424/2500], Loss: 0.7162508368492126\n",
      "Epoch [3/3], Batch [1425/2500], Loss: 0.12132398039102554\n",
      "Epoch [3/3], Batch [1426/2500], Loss: 0.06798936426639557\n",
      "Epoch [3/3], Batch [1427/2500], Loss: 0.021280784159898758\n",
      "Epoch [3/3], Batch [1428/2500], Loss: 0.04984715208411217\n",
      "Epoch [3/3], Batch [1429/2500], Loss: 0.2310567945241928\n",
      "Epoch [3/3], Batch [1430/2500], Loss: 0.16126365959644318\n",
      "Epoch [3/3], Batch [1431/2500], Loss: 0.042327530682086945\n",
      "Epoch [3/3], Batch [1432/2500], Loss: 0.047971054911613464\n",
      "Epoch [3/3], Batch [1433/2500], Loss: 0.012846462428569794\n",
      "Epoch [3/3], Batch [1434/2500], Loss: 0.030008060857653618\n",
      "Epoch [3/3], Batch [1435/2500], Loss: 0.13147670030593872\n",
      "Epoch [3/3], Batch [1436/2500], Loss: 0.1942645162343979\n",
      "Epoch [3/3], Batch [1437/2500], Loss: 0.04060492292046547\n",
      "Epoch [3/3], Batch [1438/2500], Loss: 0.24321481585502625\n",
      "Epoch [3/3], Batch [1439/2500], Loss: 0.10256846249103546\n",
      "Epoch [3/3], Batch [1440/2500], Loss: 0.026557408273220062\n",
      "Epoch [3/3], Batch [1441/2500], Loss: 0.10418257862329483\n",
      "Epoch [3/3], Batch [1442/2500], Loss: 0.08214932680130005\n",
      "Epoch [3/3], Batch [1443/2500], Loss: 0.1767619252204895\n",
      "Epoch [3/3], Batch [1444/2500], Loss: 0.08864718675613403\n",
      "Epoch [3/3], Batch [1445/2500], Loss: 0.11825623363256454\n",
      "Epoch [3/3], Batch [1446/2500], Loss: 0.25138527154922485\n",
      "Epoch [3/3], Batch [1447/2500], Loss: 0.1882012039422989\n",
      "Epoch [3/3], Batch [1448/2500], Loss: 0.14385689795017242\n",
      "Epoch [3/3], Batch [1449/2500], Loss: 0.13664010167121887\n",
      "Epoch [3/3], Batch [1450/2500], Loss: 0.2496073693037033\n",
      "Epoch [3/3], Batch [1451/2500], Loss: 0.2758961617946625\n",
      "Epoch [3/3], Batch [1452/2500], Loss: 0.23164232075214386\n",
      "Epoch [3/3], Batch [1453/2500], Loss: 0.3921967148780823\n",
      "Epoch [3/3], Batch [1454/2500], Loss: 0.07511068880558014\n",
      "Epoch [3/3], Batch [1455/2500], Loss: 0.20120246708393097\n",
      "Epoch [3/3], Batch [1456/2500], Loss: 0.13382506370544434\n",
      "Epoch [3/3], Batch [1457/2500], Loss: 0.3481708765029907\n",
      "Epoch [3/3], Batch [1458/2500], Loss: 0.04608168080449104\n",
      "Epoch [3/3], Batch [1459/2500], Loss: 0.09037716686725616\n",
      "Epoch [3/3], Batch [1460/2500], Loss: 0.2627617418766022\n",
      "Epoch [3/3], Batch [1461/2500], Loss: 0.0877843126654625\n",
      "Epoch [3/3], Batch [1462/2500], Loss: 0.060916077345609665\n",
      "Epoch [3/3], Batch [1463/2500], Loss: 0.18252508342266083\n",
      "Epoch [3/3], Batch [1464/2500], Loss: 0.10876335203647614\n",
      "Epoch [3/3], Batch [1465/2500], Loss: 0.05793633684515953\n",
      "Epoch [3/3], Batch [1466/2500], Loss: 0.21591071784496307\n",
      "Epoch [3/3], Batch [1467/2500], Loss: 0.21082206070423126\n",
      "Epoch [3/3], Batch [1468/2500], Loss: 0.1987076699733734\n",
      "Epoch [3/3], Batch [1469/2500], Loss: 0.14106857776641846\n",
      "Epoch [3/3], Batch [1470/2500], Loss: 0.19598349928855896\n",
      "Epoch [3/3], Batch [1471/2500], Loss: 0.07656852155923843\n",
      "Epoch [3/3], Batch [1472/2500], Loss: 0.06979953497648239\n",
      "Epoch [3/3], Batch [1473/2500], Loss: 0.19532008469104767\n",
      "Epoch [3/3], Batch [1474/2500], Loss: 0.011717336252331734\n",
      "Epoch [3/3], Batch [1475/2500], Loss: 0.01069402601569891\n",
      "Epoch [3/3], Batch [1476/2500], Loss: 0.1222524419426918\n",
      "Epoch [3/3], Batch [1477/2500], Loss: 0.17479676008224487\n",
      "Epoch [3/3], Batch [1478/2500], Loss: 0.09554572403430939\n",
      "Epoch [3/3], Batch [1479/2500], Loss: 0.18404503166675568\n",
      "Epoch [3/3], Batch [1480/2500], Loss: 0.31157007813453674\n",
      "Epoch [3/3], Batch [1481/2500], Loss: 0.050500039011240005\n",
      "Epoch [3/3], Batch [1482/2500], Loss: 0.1401817798614502\n",
      "Epoch [3/3], Batch [1483/2500], Loss: 0.2552959620952606\n",
      "Epoch [3/3], Batch [1484/2500], Loss: 0.030751194804906845\n",
      "Epoch [3/3], Batch [1485/2500], Loss: 0.08305816352367401\n",
      "Epoch [3/3], Batch [1486/2500], Loss: 0.007763140834867954\n",
      "Epoch [3/3], Batch [1487/2500], Loss: 0.01129240170121193\n",
      "Epoch [3/3], Batch [1488/2500], Loss: 0.04967247694730759\n",
      "Epoch [3/3], Batch [1489/2500], Loss: 0.04448768496513367\n",
      "Epoch [3/3], Batch [1490/2500], Loss: 0.008396412245929241\n",
      "Epoch [3/3], Batch [1491/2500], Loss: 0.19897735118865967\n",
      "Epoch [3/3], Batch [1492/2500], Loss: 0.02383660525083542\n",
      "Epoch [3/3], Batch [1493/2500], Loss: 0.1387333869934082\n",
      "Epoch [3/3], Batch [1494/2500], Loss: 0.09228319674730301\n",
      "Epoch [3/3], Batch [1495/2500], Loss: 0.05156039074063301\n",
      "Epoch [3/3], Batch [1496/2500], Loss: 0.06916158646345139\n",
      "Epoch [3/3], Batch [1497/2500], Loss: 0.10069872438907623\n",
      "Epoch [3/3], Batch [1498/2500], Loss: 0.11389993131160736\n",
      "Epoch [3/3], Batch [1499/2500], Loss: 0.0689510703086853\n",
      "Epoch [3/3], Batch [1500/2500], Loss: 0.09447583556175232\n",
      "Epoch [3/3], Batch [1501/2500], Loss: 0.05367790907621384\n",
      "Epoch [3/3], Batch [1502/2500], Loss: 0.10034675896167755\n",
      "Epoch [3/3], Batch [1503/2500], Loss: 0.23030619323253632\n",
      "Epoch [3/3], Batch [1504/2500], Loss: 0.058870118111371994\n",
      "Epoch [3/3], Batch [1505/2500], Loss: 0.014788122847676277\n",
      "Epoch [3/3], Batch [1506/2500], Loss: 0.05379314348101616\n",
      "Epoch [3/3], Batch [1507/2500], Loss: 0.07485383749008179\n",
      "Epoch [3/3], Batch [1508/2500], Loss: 0.10236099362373352\n",
      "Epoch [3/3], Batch [1509/2500], Loss: 0.053539831191301346\n",
      "Epoch [3/3], Batch [1510/2500], Loss: 0.073447085916996\n",
      "Epoch [3/3], Batch [1511/2500], Loss: 0.029173336923122406\n",
      "Epoch [3/3], Batch [1512/2500], Loss: 0.1531723141670227\n",
      "Epoch [3/3], Batch [1513/2500], Loss: 0.022721927613019943\n",
      "Epoch [3/3], Batch [1514/2500], Loss: 0.21369622647762299\n",
      "Epoch [3/3], Batch [1515/2500], Loss: 0.011570100672543049\n",
      "Epoch [3/3], Batch [1516/2500], Loss: 0.05128343403339386\n",
      "Epoch [3/3], Batch [1517/2500], Loss: 0.021542927250266075\n",
      "Epoch [3/3], Batch [1518/2500], Loss: 0.026351122185587883\n",
      "Epoch [3/3], Batch [1519/2500], Loss: 0.018585218116641045\n",
      "Epoch [3/3], Batch [1520/2500], Loss: 0.4284442365169525\n",
      "Epoch [3/3], Batch [1521/2500], Loss: 0.027843214571475983\n",
      "Epoch [3/3], Batch [1522/2500], Loss: 0.0850302055478096\n",
      "Epoch [3/3], Batch [1523/2500], Loss: 0.3155198097229004\n",
      "Epoch [3/3], Batch [1524/2500], Loss: 0.029902804642915726\n",
      "Epoch [3/3], Batch [1525/2500], Loss: 0.1928422749042511\n",
      "Epoch [3/3], Batch [1526/2500], Loss: 0.23625095188617706\n",
      "Epoch [3/3], Batch [1527/2500], Loss: 0.026343518868088722\n",
      "Epoch [3/3], Batch [1528/2500], Loss: 0.030701108276844025\n",
      "Epoch [3/3], Batch [1529/2500], Loss: 0.09476211667060852\n",
      "Epoch [3/3], Batch [1530/2500], Loss: 0.16251938045024872\n",
      "Epoch [3/3], Batch [1531/2500], Loss: 0.03495064005255699\n",
      "Epoch [3/3], Batch [1532/2500], Loss: 0.05081791430711746\n",
      "Epoch [3/3], Batch [1533/2500], Loss: 0.2899665832519531\n",
      "Epoch [3/3], Batch [1534/2500], Loss: 1.0481911897659302\n",
      "Epoch [3/3], Batch [1535/2500], Loss: 0.02284400723874569\n",
      "Epoch [3/3], Batch [1536/2500], Loss: 0.01463492214679718\n",
      "Epoch [3/3], Batch [1537/2500], Loss: 0.0813150629401207\n",
      "Epoch [3/3], Batch [1538/2500], Loss: 0.19925454258918762\n",
      "Epoch [3/3], Batch [1539/2500], Loss: 0.11383206397294998\n",
      "Epoch [3/3], Batch [1540/2500], Loss: 0.27492931485176086\n",
      "Epoch [3/3], Batch [1541/2500], Loss: 0.01657656580209732\n",
      "Epoch [3/3], Batch [1542/2500], Loss: 0.24190494418144226\n",
      "Epoch [3/3], Batch [1543/2500], Loss: 0.024645604193210602\n",
      "Epoch [3/3], Batch [1544/2500], Loss: 0.07002803683280945\n",
      "Epoch [3/3], Batch [1545/2500], Loss: 0.03193349391222\n",
      "Epoch [3/3], Batch [1546/2500], Loss: 0.09052896499633789\n",
      "Epoch [3/3], Batch [1547/2500], Loss: 0.04820399731397629\n",
      "Epoch [3/3], Batch [1548/2500], Loss: 0.023260094225406647\n",
      "Epoch [3/3], Batch [1549/2500], Loss: 0.07673061639070511\n",
      "Epoch [3/3], Batch [1550/2500], Loss: 0.09729838371276855\n",
      "Epoch [3/3], Batch [1551/2500], Loss: 0.4404468238353729\n",
      "Epoch [3/3], Batch [1552/2500], Loss: 0.02240109257400036\n",
      "Epoch [3/3], Batch [1553/2500], Loss: 0.013371102511882782\n",
      "Epoch [3/3], Batch [1554/2500], Loss: 0.22018341720104218\n",
      "Epoch [3/3], Batch [1555/2500], Loss: 0.047538984566926956\n",
      "Epoch [3/3], Batch [1556/2500], Loss: 0.05877570062875748\n",
      "Epoch [3/3], Batch [1557/2500], Loss: 0.06518615782260895\n",
      "Epoch [3/3], Batch [1558/2500], Loss: 0.23536917567253113\n",
      "Epoch [3/3], Batch [1559/2500], Loss: 0.028409438207745552\n",
      "Epoch [3/3], Batch [1560/2500], Loss: 0.042791567742824554\n",
      "Epoch [3/3], Batch [1561/2500], Loss: 0.2669362723827362\n",
      "Epoch [3/3], Batch [1562/2500], Loss: 0.08622853457927704\n",
      "Epoch [3/3], Batch [1563/2500], Loss: 0.14580826461315155\n",
      "Epoch [3/3], Batch [1564/2500], Loss: 0.012882747687399387\n",
      "Epoch [3/3], Batch [1565/2500], Loss: 0.2811126708984375\n",
      "Epoch [3/3], Batch [1566/2500], Loss: 0.2448803186416626\n",
      "Epoch [3/3], Batch [1567/2500], Loss: 0.29114842414855957\n",
      "Epoch [3/3], Batch [1568/2500], Loss: 0.20603084564208984\n",
      "Epoch [3/3], Batch [1569/2500], Loss: 0.045482974499464035\n",
      "Epoch [3/3], Batch [1570/2500], Loss: 0.4453344941139221\n",
      "Epoch [3/3], Batch [1571/2500], Loss: 0.019837625324726105\n",
      "Epoch [3/3], Batch [1572/2500], Loss: 0.041777774691581726\n",
      "Epoch [3/3], Batch [1573/2500], Loss: 0.16318120062351227\n",
      "Epoch [3/3], Batch [1574/2500], Loss: 0.07449924945831299\n",
      "Epoch [3/3], Batch [1575/2500], Loss: 0.3731006681919098\n",
      "Epoch [3/3], Batch [1576/2500], Loss: 0.07636295258998871\n",
      "Epoch [3/3], Batch [1577/2500], Loss: 0.027016684412956238\n",
      "Epoch [3/3], Batch [1578/2500], Loss: 0.19746458530426025\n",
      "Epoch [3/3], Batch [1579/2500], Loss: 0.03401360660791397\n",
      "Epoch [3/3], Batch [1580/2500], Loss: 0.07571722567081451\n",
      "Epoch [3/3], Batch [1581/2500], Loss: 0.21690039336681366\n",
      "Epoch [3/3], Batch [1582/2500], Loss: 0.054419469088315964\n",
      "Epoch [3/3], Batch [1583/2500], Loss: 0.017634738236665726\n",
      "Epoch [3/3], Batch [1584/2500], Loss: 0.02486911043524742\n",
      "Epoch [3/3], Batch [1585/2500], Loss: 0.0132498973980546\n",
      "Epoch [3/3], Batch [1586/2500], Loss: 0.12671425938606262\n",
      "Epoch [3/3], Batch [1587/2500], Loss: 0.06504543125629425\n",
      "Epoch [3/3], Batch [1588/2500], Loss: 0.2445046454668045\n",
      "Epoch [3/3], Batch [1589/2500], Loss: 0.01105434074997902\n",
      "Epoch [3/3], Batch [1590/2500], Loss: 0.4882871210575104\n",
      "Epoch [3/3], Batch [1591/2500], Loss: 0.30605122447013855\n",
      "Epoch [3/3], Batch [1592/2500], Loss: 0.06238937005400658\n",
      "Epoch [3/3], Batch [1593/2500], Loss: 0.03742300719022751\n",
      "Epoch [3/3], Batch [1594/2500], Loss: 0.10836507380008698\n",
      "Epoch [3/3], Batch [1595/2500], Loss: 0.014249121770262718\n",
      "Epoch [3/3], Batch [1596/2500], Loss: 0.37160468101501465\n",
      "Epoch [3/3], Batch [1597/2500], Loss: 0.10705159604549408\n",
      "Epoch [3/3], Batch [1598/2500], Loss: 0.021678350865840912\n",
      "Epoch [3/3], Batch [1599/2500], Loss: 0.03763360157608986\n",
      "Epoch [3/3], Batch [1600/2500], Loss: 0.11204829812049866\n",
      "Epoch [3/3], Batch [1601/2500], Loss: 0.10144435614347458\n",
      "Epoch [3/3], Batch [1602/2500], Loss: 0.19015346467494965\n",
      "Epoch [3/3], Batch [1603/2500], Loss: 0.01244442630559206\n",
      "Epoch [3/3], Batch [1604/2500], Loss: 0.24751125276088715\n",
      "Epoch [3/3], Batch [1605/2500], Loss: 0.006424500606954098\n",
      "Epoch [3/3], Batch [1606/2500], Loss: 0.031550515443086624\n",
      "Epoch [3/3], Batch [1607/2500], Loss: 0.594683825969696\n",
      "Epoch [3/3], Batch [1608/2500], Loss: 0.04016781225800514\n",
      "Epoch [3/3], Batch [1609/2500], Loss: 0.01409843098372221\n",
      "Epoch [3/3], Batch [1610/2500], Loss: 0.12612096965312958\n",
      "Epoch [3/3], Batch [1611/2500], Loss: 0.10576338320970535\n",
      "Epoch [3/3], Batch [1612/2500], Loss: 0.012446860782802105\n",
      "Epoch [3/3], Batch [1613/2500], Loss: 0.13861964643001556\n",
      "Epoch [3/3], Batch [1614/2500], Loss: 0.07854397594928741\n",
      "Epoch [3/3], Batch [1615/2500], Loss: 0.07126933336257935\n",
      "Epoch [3/3], Batch [1616/2500], Loss: 0.15261051058769226\n",
      "Epoch [3/3], Batch [1617/2500], Loss: 0.15705102682113647\n",
      "Epoch [3/3], Batch [1618/2500], Loss: 0.30288639664649963\n",
      "Epoch [3/3], Batch [1619/2500], Loss: 0.08603149652481079\n",
      "Epoch [3/3], Batch [1620/2500], Loss: 0.06418637931346893\n",
      "Epoch [3/3], Batch [1621/2500], Loss: 0.26287364959716797\n",
      "Epoch [3/3], Batch [1622/2500], Loss: 0.03712685778737068\n",
      "Epoch [3/3], Batch [1623/2500], Loss: 0.09804481267929077\n",
      "Epoch [3/3], Batch [1624/2500], Loss: 0.14229416847229004\n",
      "Epoch [3/3], Batch [1625/2500], Loss: 0.028564877808094025\n",
      "Epoch [3/3], Batch [1626/2500], Loss: 0.12653914093971252\n",
      "Epoch [3/3], Batch [1627/2500], Loss: 0.33956748247146606\n",
      "Epoch [3/3], Batch [1628/2500], Loss: 0.09305183589458466\n",
      "Epoch [3/3], Batch [1629/2500], Loss: 0.14462292194366455\n",
      "Epoch [3/3], Batch [1630/2500], Loss: 0.2296772003173828\n",
      "Epoch [3/3], Batch [1631/2500], Loss: 0.01195664145052433\n",
      "Epoch [3/3], Batch [1632/2500], Loss: 0.1336868852376938\n",
      "Epoch [3/3], Batch [1633/2500], Loss: 0.085771843791008\n",
      "Epoch [3/3], Batch [1634/2500], Loss: 0.10524976253509521\n",
      "Epoch [3/3], Batch [1635/2500], Loss: 0.019065607339143753\n",
      "Epoch [3/3], Batch [1636/2500], Loss: 0.12853290140628815\n",
      "Epoch [3/3], Batch [1637/2500], Loss: 0.06199811026453972\n",
      "Epoch [3/3], Batch [1638/2500], Loss: 0.21254879236221313\n",
      "Epoch [3/3], Batch [1639/2500], Loss: 0.2443208545446396\n",
      "Epoch [3/3], Batch [1640/2500], Loss: 0.4275500178337097\n",
      "Epoch [3/3], Batch [1641/2500], Loss: 0.08934152871370316\n",
      "Epoch [3/3], Batch [1642/2500], Loss: 0.19126075506210327\n",
      "Epoch [3/3], Batch [1643/2500], Loss: 0.13562701642513275\n",
      "Epoch [3/3], Batch [1644/2500], Loss: 0.05391516909003258\n",
      "Epoch [3/3], Batch [1645/2500], Loss: 0.08560891449451447\n",
      "Epoch [3/3], Batch [1646/2500], Loss: 0.21107353270053864\n",
      "Epoch [3/3], Batch [1647/2500], Loss: 0.20119310915470123\n",
      "Epoch [3/3], Batch [1648/2500], Loss: 0.2761059105396271\n",
      "Epoch [3/3], Batch [1649/2500], Loss: 0.11738155782222748\n",
      "Epoch [3/3], Batch [1650/2500], Loss: 0.044978853315114975\n",
      "Epoch [3/3], Batch [1651/2500], Loss: 0.02998635172843933\n",
      "Epoch [3/3], Batch [1652/2500], Loss: 0.015706388279795647\n",
      "Epoch [3/3], Batch [1653/2500], Loss: 0.1576429307460785\n",
      "Epoch [3/3], Batch [1654/2500], Loss: 0.010401773266494274\n",
      "Epoch [3/3], Batch [1655/2500], Loss: 0.31502845883369446\n",
      "Epoch [3/3], Batch [1656/2500], Loss: 0.016541797667741776\n",
      "Epoch [3/3], Batch [1657/2500], Loss: 0.0821090042591095\n",
      "Epoch [3/3], Batch [1658/2500], Loss: 0.029258348047733307\n",
      "Epoch [3/3], Batch [1659/2500], Loss: 0.05120472237467766\n",
      "Epoch [3/3], Batch [1660/2500], Loss: 0.3240431249141693\n",
      "Epoch [3/3], Batch [1661/2500], Loss: 0.14816999435424805\n",
      "Epoch [3/3], Batch [1662/2500], Loss: 0.032297223806381226\n",
      "Epoch [3/3], Batch [1663/2500], Loss: 0.05221480876207352\n",
      "Epoch [3/3], Batch [1664/2500], Loss: 0.40487295389175415\n",
      "Epoch [3/3], Batch [1665/2500], Loss: 0.23378239572048187\n",
      "Epoch [3/3], Batch [1666/2500], Loss: 0.4317282438278198\n",
      "Epoch [3/3], Batch [1667/2500], Loss: 0.7934752106666565\n",
      "Epoch [3/3], Batch [1668/2500], Loss: 0.04499812424182892\n",
      "Epoch [3/3], Batch [1669/2500], Loss: 0.023483846336603165\n",
      "Epoch [3/3], Batch [1670/2500], Loss: 0.5502451658248901\n",
      "Epoch [3/3], Batch [1671/2500], Loss: 0.355831503868103\n",
      "Epoch [3/3], Batch [1672/2500], Loss: 0.02448807656764984\n",
      "Epoch [3/3], Batch [1673/2500], Loss: 0.013082284480333328\n",
      "Epoch [3/3], Batch [1674/2500], Loss: 0.19832152128219604\n",
      "Epoch [3/3], Batch [1675/2500], Loss: 0.2865981459617615\n",
      "Epoch [3/3], Batch [1676/2500], Loss: 0.12142627686262131\n",
      "Epoch [3/3], Batch [1677/2500], Loss: 0.0565863773226738\n",
      "Epoch [3/3], Batch [1678/2500], Loss: 0.16965310275554657\n",
      "Epoch [3/3], Batch [1679/2500], Loss: 0.059919316321611404\n",
      "Epoch [3/3], Batch [1680/2500], Loss: 0.09114150702953339\n",
      "Epoch [3/3], Batch [1681/2500], Loss: 0.011258479207754135\n",
      "Epoch [3/3], Batch [1682/2500], Loss: 0.08888410776853561\n",
      "Epoch [3/3], Batch [1683/2500], Loss: 0.06506815552711487\n",
      "Epoch [3/3], Batch [1684/2500], Loss: 0.18061304092407227\n",
      "Epoch [3/3], Batch [1685/2500], Loss: 0.16116394102573395\n",
      "Epoch [3/3], Batch [1686/2500], Loss: 0.045193444937467575\n",
      "Epoch [3/3], Batch [1687/2500], Loss: 0.0650748461484909\n",
      "Epoch [3/3], Batch [1688/2500], Loss: 0.2511462867259979\n",
      "Epoch [3/3], Batch [1689/2500], Loss: 0.043219856917858124\n",
      "Epoch [3/3], Batch [1690/2500], Loss: 0.017942136153578758\n",
      "Epoch [3/3], Batch [1691/2500], Loss: 0.09517142176628113\n",
      "Epoch [3/3], Batch [1692/2500], Loss: 0.3969416320323944\n",
      "Epoch [3/3], Batch [1693/2500], Loss: 0.01262898650020361\n",
      "Epoch [3/3], Batch [1694/2500], Loss: 0.1381186991930008\n",
      "Epoch [3/3], Batch [1695/2500], Loss: 0.06307081133127213\n",
      "Epoch [3/3], Batch [1696/2500], Loss: 0.17075644433498383\n",
      "Epoch [3/3], Batch [1697/2500], Loss: 0.30410969257354736\n",
      "Epoch [3/3], Batch [1698/2500], Loss: 0.020390767604112625\n",
      "Epoch [3/3], Batch [1699/2500], Loss: 0.03553557023406029\n",
      "Epoch [3/3], Batch [1700/2500], Loss: 0.04928780719637871\n",
      "Epoch [3/3], Batch [1701/2500], Loss: 0.23055429756641388\n",
      "Epoch [3/3], Batch [1702/2500], Loss: 0.05162293091416359\n",
      "Epoch [3/3], Batch [1703/2500], Loss: 0.282894492149353\n",
      "Epoch [3/3], Batch [1704/2500], Loss: 0.04176950454711914\n",
      "Epoch [3/3], Batch [1705/2500], Loss: 0.6077568531036377\n",
      "Epoch [3/3], Batch [1706/2500], Loss: 0.4331299066543579\n",
      "Epoch [3/3], Batch [1707/2500], Loss: 0.20805136859416962\n",
      "Epoch [3/3], Batch [1708/2500], Loss: 0.04796179383993149\n",
      "Epoch [3/3], Batch [1709/2500], Loss: 0.09403708577156067\n",
      "Epoch [3/3], Batch [1710/2500], Loss: 0.056366510689258575\n",
      "Epoch [3/3], Batch [1711/2500], Loss: 0.10639429837465286\n",
      "Epoch [3/3], Batch [1712/2500], Loss: 0.4924614131450653\n",
      "Epoch [3/3], Batch [1713/2500], Loss: 0.05118361487984657\n",
      "Epoch [3/3], Batch [1714/2500], Loss: 0.14007869362831116\n",
      "Epoch [3/3], Batch [1715/2500], Loss: 0.3973468542098999\n",
      "Epoch [3/3], Batch [1716/2500], Loss: 0.08531787991523743\n",
      "Epoch [3/3], Batch [1717/2500], Loss: 0.02589567005634308\n",
      "Epoch [3/3], Batch [1718/2500], Loss: 0.05622297525405884\n",
      "Epoch [3/3], Batch [1719/2500], Loss: 0.12053137272596359\n",
      "Epoch [3/3], Batch [1720/2500], Loss: 0.1454634666442871\n",
      "Epoch [3/3], Batch [1721/2500], Loss: 0.14830052852630615\n",
      "Epoch [3/3], Batch [1722/2500], Loss: 0.14176777005195618\n",
      "Epoch [3/3], Batch [1723/2500], Loss: 0.23297293484210968\n",
      "Epoch [3/3], Batch [1724/2500], Loss: 0.24141283333301544\n",
      "Epoch [3/3], Batch [1725/2500], Loss: 0.25199398398399353\n",
      "Epoch [3/3], Batch [1726/2500], Loss: 0.14522628486156464\n",
      "Epoch [3/3], Batch [1727/2500], Loss: 0.17350858449935913\n",
      "Epoch [3/3], Batch [1728/2500], Loss: 0.09785011410713196\n",
      "Epoch [3/3], Batch [1729/2500], Loss: 0.5402076244354248\n",
      "Epoch [3/3], Batch [1730/2500], Loss: 0.12104860693216324\n",
      "Epoch [3/3], Batch [1731/2500], Loss: 0.3694126009941101\n",
      "Epoch [3/3], Batch [1732/2500], Loss: 0.037896402180194855\n",
      "Epoch [3/3], Batch [1733/2500], Loss: 0.25802284479141235\n",
      "Epoch [3/3], Batch [1734/2500], Loss: 0.11900500953197479\n",
      "Epoch [3/3], Batch [1735/2500], Loss: 0.3866562843322754\n",
      "Epoch [3/3], Batch [1736/2500], Loss: 0.37959396839141846\n",
      "Epoch [3/3], Batch [1737/2500], Loss: 0.17137867212295532\n",
      "Epoch [3/3], Batch [1738/2500], Loss: 0.03266057372093201\n",
      "Epoch [3/3], Batch [1739/2500], Loss: 0.08755145221948624\n",
      "Epoch [3/3], Batch [1740/2500], Loss: 0.05640353634953499\n",
      "Epoch [3/3], Batch [1741/2500], Loss: 0.08130217343568802\n",
      "Epoch [3/3], Batch [1742/2500], Loss: 0.3262655735015869\n",
      "Epoch [3/3], Batch [1743/2500], Loss: 0.07546700537204742\n",
      "Epoch [3/3], Batch [1744/2500], Loss: 0.20405972003936768\n",
      "Epoch [3/3], Batch [1745/2500], Loss: 0.06598012149333954\n",
      "Epoch [3/3], Batch [1746/2500], Loss: 0.09550945460796356\n",
      "Epoch [3/3], Batch [1747/2500], Loss: 0.026023341342806816\n",
      "Epoch [3/3], Batch [1748/2500], Loss: 0.017862632870674133\n",
      "Epoch [3/3], Batch [1749/2500], Loss: 0.2833687663078308\n",
      "Epoch [3/3], Batch [1750/2500], Loss: 0.32364943623542786\n",
      "Epoch [3/3], Batch [1751/2500], Loss: 0.2968253791332245\n",
      "Epoch [3/3], Batch [1752/2500], Loss: 0.04192331060767174\n",
      "Epoch [3/3], Batch [1753/2500], Loss: 0.1655128002166748\n",
      "Epoch [3/3], Batch [1754/2500], Loss: 0.12606966495513916\n",
      "Epoch [3/3], Batch [1755/2500], Loss: 0.07711008936166763\n",
      "Epoch [3/3], Batch [1756/2500], Loss: 0.06486386805772781\n",
      "Epoch [3/3], Batch [1757/2500], Loss: 0.008347602561116219\n",
      "Epoch [3/3], Batch [1758/2500], Loss: 0.20890650153160095\n",
      "Epoch [3/3], Batch [1759/2500], Loss: 0.10610044747591019\n",
      "Epoch [3/3], Batch [1760/2500], Loss: 0.056595634669065475\n",
      "Epoch [3/3], Batch [1761/2500], Loss: 0.1763545423746109\n",
      "Epoch [3/3], Batch [1762/2500], Loss: 0.015771280974149704\n",
      "Epoch [3/3], Batch [1763/2500], Loss: 0.1850183606147766\n",
      "Epoch [3/3], Batch [1764/2500], Loss: 0.39435872435569763\n",
      "Epoch [3/3], Batch [1765/2500], Loss: 0.1756734848022461\n",
      "Epoch [3/3], Batch [1766/2500], Loss: 0.23487727344036102\n",
      "Epoch [3/3], Batch [1767/2500], Loss: 0.22325384616851807\n",
      "Epoch [3/3], Batch [1768/2500], Loss: 0.03098996728658676\n",
      "Epoch [3/3], Batch [1769/2500], Loss: 0.3115023374557495\n",
      "Epoch [3/3], Batch [1770/2500], Loss: 0.05057187378406525\n",
      "Epoch [3/3], Batch [1771/2500], Loss: 0.05001132935285568\n",
      "Epoch [3/3], Batch [1772/2500], Loss: 0.02736668288707733\n",
      "Epoch [3/3], Batch [1773/2500], Loss: 0.14602291584014893\n",
      "Epoch [3/3], Batch [1774/2500], Loss: 0.26964783668518066\n",
      "Epoch [3/3], Batch [1775/2500], Loss: 0.08357292413711548\n",
      "Epoch [3/3], Batch [1776/2500], Loss: 0.03817587345838547\n",
      "Epoch [3/3], Batch [1777/2500], Loss: 0.1560249626636505\n",
      "Epoch [3/3], Batch [1778/2500], Loss: 0.23682385683059692\n",
      "Epoch [3/3], Batch [1779/2500], Loss: 0.10520754754543304\n",
      "Epoch [3/3], Batch [1780/2500], Loss: 0.12957319617271423\n",
      "Epoch [3/3], Batch [1781/2500], Loss: 0.23977217078208923\n",
      "Epoch [3/3], Batch [1782/2500], Loss: 0.09209839254617691\n",
      "Epoch [3/3], Batch [1783/2500], Loss: 0.07723712176084518\n",
      "Epoch [3/3], Batch [1784/2500], Loss: 0.15109628438949585\n",
      "Epoch [3/3], Batch [1785/2500], Loss: 0.018871933221817017\n",
      "Epoch [3/3], Batch [1786/2500], Loss: 0.21804648637771606\n",
      "Epoch [3/3], Batch [1787/2500], Loss: 0.08711770176887512\n",
      "Epoch [3/3], Batch [1788/2500], Loss: 0.3140852749347687\n",
      "Epoch [3/3], Batch [1789/2500], Loss: 0.01151962112635374\n",
      "Epoch [3/3], Batch [1790/2500], Loss: 0.05690637230873108\n",
      "Epoch [3/3], Batch [1791/2500], Loss: 0.0428621843457222\n",
      "Epoch [3/3], Batch [1792/2500], Loss: 0.2943381071090698\n",
      "Epoch [3/3], Batch [1793/2500], Loss: 0.19306260347366333\n",
      "Epoch [3/3], Batch [1794/2500], Loss: 0.08873039484024048\n",
      "Epoch [3/3], Batch [1795/2500], Loss: 0.05111437290906906\n",
      "Epoch [3/3], Batch [1796/2500], Loss: 0.19035644829273224\n",
      "Epoch [3/3], Batch [1797/2500], Loss: 0.2887565791606903\n",
      "Epoch [3/3], Batch [1798/2500], Loss: 0.1664673537015915\n",
      "Epoch [3/3], Batch [1799/2500], Loss: 0.027073027566075325\n",
      "Epoch [3/3], Batch [1800/2500], Loss: 0.11260778456926346\n",
      "Epoch [3/3], Batch [1801/2500], Loss: 0.01985754445195198\n",
      "Epoch [3/3], Batch [1802/2500], Loss: 0.20856665074825287\n",
      "Epoch [3/3], Batch [1803/2500], Loss: 0.15587137639522552\n",
      "Epoch [3/3], Batch [1804/2500], Loss: 0.03456493094563484\n",
      "Epoch [3/3], Batch [1805/2500], Loss: 0.3312133252620697\n",
      "Epoch [3/3], Batch [1806/2500], Loss: 0.018776126205921173\n",
      "Epoch [3/3], Batch [1807/2500], Loss: 0.13993996381759644\n",
      "Epoch [3/3], Batch [1808/2500], Loss: 0.03643561899662018\n",
      "Epoch [3/3], Batch [1809/2500], Loss: 0.05708533525466919\n",
      "Epoch [3/3], Batch [1810/2500], Loss: 0.03522985428571701\n",
      "Epoch [3/3], Batch [1811/2500], Loss: 0.10286612063646317\n",
      "Epoch [3/3], Batch [1812/2500], Loss: 0.6993399858474731\n",
      "Epoch [3/3], Batch [1813/2500], Loss: 0.16937421262264252\n",
      "Epoch [3/3], Batch [1814/2500], Loss: 0.028310872614383698\n",
      "Epoch [3/3], Batch [1815/2500], Loss: 0.3277893364429474\n",
      "Epoch [3/3], Batch [1816/2500], Loss: 0.05107584595680237\n",
      "Epoch [3/3], Batch [1817/2500], Loss: 0.2796032428741455\n",
      "Epoch [3/3], Batch [1818/2500], Loss: 0.04142501950263977\n",
      "Epoch [3/3], Batch [1819/2500], Loss: 0.5362114310264587\n",
      "Epoch [3/3], Batch [1820/2500], Loss: 0.13412490487098694\n",
      "Epoch [3/3], Batch [1821/2500], Loss: 0.6910387873649597\n",
      "Epoch [3/3], Batch [1822/2500], Loss: 0.13891242444515228\n",
      "Epoch [3/3], Batch [1823/2500], Loss: 0.045351043343544006\n",
      "Epoch [3/3], Batch [1824/2500], Loss: 0.11831483989953995\n",
      "Epoch [3/3], Batch [1825/2500], Loss: 0.052259039133787155\n",
      "Epoch [3/3], Batch [1826/2500], Loss: 0.1801384836435318\n",
      "Epoch [3/3], Batch [1827/2500], Loss: 0.3062843680381775\n",
      "Epoch [3/3], Batch [1828/2500], Loss: 0.15035046637058258\n",
      "Epoch [3/3], Batch [1829/2500], Loss: 0.1539190709590912\n",
      "Epoch [3/3], Batch [1830/2500], Loss: 0.14109638333320618\n",
      "Epoch [3/3], Batch [1831/2500], Loss: 0.2410171777009964\n",
      "Epoch [3/3], Batch [1832/2500], Loss: 0.26742565631866455\n",
      "Epoch [3/3], Batch [1833/2500], Loss: 0.09644132852554321\n",
      "Epoch [3/3], Batch [1834/2500], Loss: 0.12900057435035706\n",
      "Epoch [3/3], Batch [1835/2500], Loss: 0.11479705572128296\n",
      "Epoch [3/3], Batch [1836/2500], Loss: 0.3858136534690857\n",
      "Epoch [3/3], Batch [1837/2500], Loss: 0.059518963098526\n",
      "Epoch [3/3], Batch [1838/2500], Loss: 0.23092803359031677\n",
      "Epoch [3/3], Batch [1839/2500], Loss: 0.03897224739193916\n",
      "Epoch [3/3], Batch [1840/2500], Loss: 0.0837247297167778\n",
      "Epoch [3/3], Batch [1841/2500], Loss: 0.032165952026844025\n",
      "Epoch [3/3], Batch [1842/2500], Loss: 0.2124946415424347\n",
      "Epoch [3/3], Batch [1843/2500], Loss: 0.2081744521856308\n",
      "Epoch [3/3], Batch [1844/2500], Loss: 0.043810658156871796\n",
      "Epoch [3/3], Batch [1845/2500], Loss: 0.07656193524599075\n",
      "Epoch [3/3], Batch [1846/2500], Loss: 0.15878717601299286\n",
      "Epoch [3/3], Batch [1847/2500], Loss: 0.014041779562830925\n",
      "Epoch [3/3], Batch [1848/2500], Loss: 0.09406222403049469\n",
      "Epoch [3/3], Batch [1849/2500], Loss: 0.061889976263046265\n",
      "Epoch [3/3], Batch [1850/2500], Loss: 0.12841862440109253\n",
      "Epoch [3/3], Batch [1851/2500], Loss: 0.03353724628686905\n",
      "Epoch [3/3], Batch [1852/2500], Loss: 0.1986447423696518\n",
      "Epoch [3/3], Batch [1853/2500], Loss: 0.2701007127761841\n",
      "Epoch [3/3], Batch [1854/2500], Loss: 0.05265415459871292\n",
      "Epoch [3/3], Batch [1855/2500], Loss: 0.06798207759857178\n",
      "Epoch [3/3], Batch [1856/2500], Loss: 0.022256668657064438\n",
      "Epoch [3/3], Batch [1857/2500], Loss: 0.2104819118976593\n",
      "Epoch [3/3], Batch [1858/2500], Loss: 0.31220459938049316\n",
      "Epoch [3/3], Batch [1859/2500], Loss: 0.14387914538383484\n",
      "Epoch [3/3], Batch [1860/2500], Loss: 0.1368863582611084\n",
      "Epoch [3/3], Batch [1861/2500], Loss: 0.02828853391110897\n",
      "Epoch [3/3], Batch [1862/2500], Loss: 0.018481966108083725\n",
      "Epoch [3/3], Batch [1863/2500], Loss: 0.6399549841880798\n",
      "Epoch [3/3], Batch [1864/2500], Loss: 0.010633308440446854\n",
      "Epoch [3/3], Batch [1865/2500], Loss: 0.08704875409603119\n",
      "Epoch [3/3], Batch [1866/2500], Loss: 0.07248909771442413\n",
      "Epoch [3/3], Batch [1867/2500], Loss: 0.017865072935819626\n",
      "Epoch [3/3], Batch [1868/2500], Loss: 0.1734844595193863\n",
      "Epoch [3/3], Batch [1869/2500], Loss: 0.31151801347732544\n",
      "Epoch [3/3], Batch [1870/2500], Loss: 0.14078333973884583\n",
      "Epoch [3/3], Batch [1871/2500], Loss: 0.014660410583019257\n",
      "Epoch [3/3], Batch [1872/2500], Loss: 0.040091272443532944\n",
      "Epoch [3/3], Batch [1873/2500], Loss: 0.050266046077013016\n",
      "Epoch [3/3], Batch [1874/2500], Loss: 0.2608150243759155\n",
      "Epoch [3/3], Batch [1875/2500], Loss: 0.05933918431401253\n",
      "Epoch [3/3], Batch [1876/2500], Loss: 0.03785838186740875\n",
      "Epoch [3/3], Batch [1877/2500], Loss: 0.011692357249557972\n",
      "Epoch [3/3], Batch [1878/2500], Loss: 0.3586161434650421\n",
      "Epoch [3/3], Batch [1879/2500], Loss: 0.025832489132881165\n",
      "Epoch [3/3], Batch [1880/2500], Loss: 0.08422733843326569\n",
      "Epoch [3/3], Batch [1881/2500], Loss: 0.2118500918149948\n",
      "Epoch [3/3], Batch [1882/2500], Loss: 0.2440437376499176\n",
      "Epoch [3/3], Batch [1883/2500], Loss: 0.08113846927881241\n",
      "Epoch [3/3], Batch [1884/2500], Loss: 0.03235010802745819\n",
      "Epoch [3/3], Batch [1885/2500], Loss: 0.6328011155128479\n",
      "Epoch [3/3], Batch [1886/2500], Loss: 0.06732688844203949\n",
      "Epoch [3/3], Batch [1887/2500], Loss: 0.10922326147556305\n",
      "Epoch [3/3], Batch [1888/2500], Loss: 0.02445683255791664\n",
      "Epoch [3/3], Batch [1889/2500], Loss: 0.02605101838707924\n",
      "Epoch [3/3], Batch [1890/2500], Loss: 0.5549823045730591\n",
      "Epoch [3/3], Batch [1891/2500], Loss: 0.024795692414045334\n",
      "Epoch [3/3], Batch [1892/2500], Loss: 0.1682622879743576\n",
      "Epoch [3/3], Batch [1893/2500], Loss: 0.029429135844111443\n",
      "Epoch [3/3], Batch [1894/2500], Loss: 0.3116271197795868\n",
      "Epoch [3/3], Batch [1895/2500], Loss: 0.05462776869535446\n",
      "Epoch [3/3], Batch [1896/2500], Loss: 0.05017766356468201\n",
      "Epoch [3/3], Batch [1897/2500], Loss: 0.07964668422937393\n",
      "Epoch [3/3], Batch [1898/2500], Loss: 0.11611897498369217\n",
      "Epoch [3/3], Batch [1899/2500], Loss: 0.09205201268196106\n",
      "Epoch [3/3], Batch [1900/2500], Loss: 0.08251529932022095\n",
      "Epoch [3/3], Batch [1901/2500], Loss: 0.0332443006336689\n",
      "Epoch [3/3], Batch [1902/2500], Loss: 0.06241915002465248\n",
      "Epoch [3/3], Batch [1903/2500], Loss: 0.18474864959716797\n",
      "Epoch [3/3], Batch [1904/2500], Loss: 0.054945189505815506\n",
      "Epoch [3/3], Batch [1905/2500], Loss: 0.03984490782022476\n",
      "Epoch [3/3], Batch [1906/2500], Loss: 0.02282939851284027\n",
      "Epoch [3/3], Batch [1907/2500], Loss: 0.3238959312438965\n",
      "Epoch [3/3], Batch [1908/2500], Loss: 0.12935185432434082\n",
      "Epoch [3/3], Batch [1909/2500], Loss: 0.39729994535446167\n",
      "Epoch [3/3], Batch [1910/2500], Loss: 0.014708206057548523\n",
      "Epoch [3/3], Batch [1911/2500], Loss: 0.007485971786081791\n",
      "Epoch [3/3], Batch [1912/2500], Loss: 0.37101489305496216\n",
      "Epoch [3/3], Batch [1913/2500], Loss: 0.060186807066202164\n",
      "Epoch [3/3], Batch [1914/2500], Loss: 0.12186039239168167\n",
      "Epoch [3/3], Batch [1915/2500], Loss: 0.3299632668495178\n",
      "Epoch [3/3], Batch [1916/2500], Loss: 0.02395676076412201\n",
      "Epoch [3/3], Batch [1917/2500], Loss: 0.09630921483039856\n",
      "Epoch [3/3], Batch [1918/2500], Loss: 0.1140516847372055\n",
      "Epoch [3/3], Batch [1919/2500], Loss: 0.047865383327007294\n",
      "Epoch [3/3], Batch [1920/2500], Loss: 0.11880805343389511\n",
      "Epoch [3/3], Batch [1921/2500], Loss: 0.13862092792987823\n",
      "Epoch [3/3], Batch [1922/2500], Loss: 0.02955513820052147\n",
      "Epoch [3/3], Batch [1923/2500], Loss: 0.05438621714711189\n",
      "Epoch [3/3], Batch [1924/2500], Loss: 0.3276146948337555\n",
      "Epoch [3/3], Batch [1925/2500], Loss: 0.23446913063526154\n",
      "Epoch [3/3], Batch [1926/2500], Loss: 0.38338717818260193\n",
      "Epoch [3/3], Batch [1927/2500], Loss: 0.0298811886459589\n",
      "Epoch [3/3], Batch [1928/2500], Loss: 0.03249484300613403\n",
      "Epoch [3/3], Batch [1929/2500], Loss: 0.27946707606315613\n",
      "Epoch [3/3], Batch [1930/2500], Loss: 0.07572048902511597\n",
      "Epoch [3/3], Batch [1931/2500], Loss: 0.07818038761615753\n",
      "Epoch [3/3], Batch [1932/2500], Loss: 0.015487976372241974\n",
      "Epoch [3/3], Batch [1933/2500], Loss: 0.045121584087610245\n",
      "Epoch [3/3], Batch [1934/2500], Loss: 0.0528782457113266\n",
      "Epoch [3/3], Batch [1935/2500], Loss: 0.1828586757183075\n",
      "Epoch [3/3], Batch [1936/2500], Loss: 0.04743533954024315\n",
      "Epoch [3/3], Batch [1937/2500], Loss: 0.14092423021793365\n",
      "Epoch [3/3], Batch [1938/2500], Loss: 0.04618000239133835\n",
      "Epoch [3/3], Batch [1939/2500], Loss: 0.28278645873069763\n",
      "Epoch [3/3], Batch [1940/2500], Loss: 0.28637444972991943\n",
      "Epoch [3/3], Batch [1941/2500], Loss: 0.04100494831800461\n",
      "Epoch [3/3], Batch [1942/2500], Loss: 0.47507697343826294\n",
      "Epoch [3/3], Batch [1943/2500], Loss: 0.05962472781538963\n",
      "Epoch [3/3], Batch [1944/2500], Loss: 0.10299152880907059\n",
      "Epoch [3/3], Batch [1945/2500], Loss: 0.06532487273216248\n",
      "Epoch [3/3], Batch [1946/2500], Loss: 0.04381394386291504\n",
      "Epoch [3/3], Batch [1947/2500], Loss: 0.04970508813858032\n",
      "Epoch [3/3], Batch [1948/2500], Loss: 0.029501285403966904\n",
      "Epoch [3/3], Batch [1949/2500], Loss: 0.044552624225616455\n",
      "Epoch [3/3], Batch [1950/2500], Loss: 0.030980126932263374\n",
      "Epoch [3/3], Batch [1951/2500], Loss: 0.556655764579773\n",
      "Epoch [3/3], Batch [1952/2500], Loss: 0.2904500663280487\n",
      "Epoch [3/3], Batch [1953/2500], Loss: 0.011209091171622276\n",
      "Epoch [3/3], Batch [1954/2500], Loss: 0.1145905926823616\n",
      "Epoch [3/3], Batch [1955/2500], Loss: 0.02421250194311142\n",
      "Epoch [3/3], Batch [1956/2500], Loss: 0.03126352280378342\n",
      "Epoch [3/3], Batch [1957/2500], Loss: 0.018194012343883514\n",
      "Epoch [3/3], Batch [1958/2500], Loss: 0.06532029807567596\n",
      "Epoch [3/3], Batch [1959/2500], Loss: 0.28864991664886475\n",
      "Epoch [3/3], Batch [1960/2500], Loss: 0.014666145667433739\n",
      "Epoch [3/3], Batch [1961/2500], Loss: 0.1685871034860611\n",
      "Epoch [3/3], Batch [1962/2500], Loss: 0.4230550527572632\n",
      "Epoch [3/3], Batch [1963/2500], Loss: 0.033980727195739746\n",
      "Epoch [3/3], Batch [1964/2500], Loss: 0.022640801966190338\n",
      "Epoch [3/3], Batch [1965/2500], Loss: 0.22524483501911163\n",
      "Epoch [3/3], Batch [1966/2500], Loss: 0.2272144854068756\n",
      "Epoch [3/3], Batch [1967/2500], Loss: 0.041462648659944534\n",
      "Epoch [3/3], Batch [1968/2500], Loss: 0.12228589504957199\n",
      "Epoch [3/3], Batch [1969/2500], Loss: 0.2686595618724823\n",
      "Epoch [3/3], Batch [1970/2500], Loss: 0.2961530387401581\n",
      "Epoch [3/3], Batch [1971/2500], Loss: 0.07590392976999283\n",
      "Epoch [3/3], Batch [1972/2500], Loss: 0.2765510678291321\n",
      "Epoch [3/3], Batch [1973/2500], Loss: 0.044346023350954056\n",
      "Epoch [3/3], Batch [1974/2500], Loss: 0.1582040637731552\n",
      "Epoch [3/3], Batch [1975/2500], Loss: 0.15367059409618378\n",
      "Epoch [3/3], Batch [1976/2500], Loss: 0.05330919474363327\n",
      "Epoch [3/3], Batch [1977/2500], Loss: 0.36085245013237\n",
      "Epoch [3/3], Batch [1978/2500], Loss: 0.04640874266624451\n",
      "Epoch [3/3], Batch [1979/2500], Loss: 0.02246790938079357\n",
      "Epoch [3/3], Batch [1980/2500], Loss: 0.290805846452713\n",
      "Epoch [3/3], Batch [1981/2500], Loss: 0.11053315550088882\n",
      "Epoch [3/3], Batch [1982/2500], Loss: 0.08798345923423767\n",
      "Epoch [3/3], Batch [1983/2500], Loss: 0.18251174688339233\n",
      "Epoch [3/3], Batch [1984/2500], Loss: 0.03242914751172066\n",
      "Epoch [3/3], Batch [1985/2500], Loss: 0.09372717887163162\n",
      "Epoch [3/3], Batch [1986/2500], Loss: 0.12407667934894562\n",
      "Epoch [3/3], Batch [1987/2500], Loss: 0.3542119264602661\n",
      "Epoch [3/3], Batch [1988/2500], Loss: 0.08197902888059616\n",
      "Epoch [3/3], Batch [1989/2500], Loss: 0.10309380292892456\n",
      "Epoch [3/3], Batch [1990/2500], Loss: 0.06379641592502594\n",
      "Epoch [3/3], Batch [1991/2500], Loss: 0.37882912158966064\n",
      "Epoch [3/3], Batch [1992/2500], Loss: 0.05137114226818085\n",
      "Epoch [3/3], Batch [1993/2500], Loss: 0.20579952001571655\n",
      "Epoch [3/3], Batch [1994/2500], Loss: 0.10932236909866333\n",
      "Epoch [3/3], Batch [1995/2500], Loss: 0.06688158214092255\n",
      "Epoch [3/3], Batch [1996/2500], Loss: 0.12625907361507416\n",
      "Epoch [3/3], Batch [1997/2500], Loss: 0.046542439609766006\n",
      "Epoch [3/3], Batch [1998/2500], Loss: 0.21722452342510223\n",
      "Epoch [3/3], Batch [1999/2500], Loss: 0.30505090951919556\n",
      "Epoch [3/3], Batch [2000/2500], Loss: 0.10567669570446014\n",
      "Epoch [3/3], Batch [2001/2500], Loss: 0.31974712014198303\n",
      "Epoch [3/3], Batch [2002/2500], Loss: 0.05883744731545448\n",
      "Epoch [3/3], Batch [2003/2500], Loss: 0.14612816274166107\n",
      "Epoch [3/3], Batch [2004/2500], Loss: 0.016294406726956367\n",
      "Epoch [3/3], Batch [2005/2500], Loss: 0.13147161900997162\n",
      "Epoch [3/3], Batch [2006/2500], Loss: 0.264167845249176\n",
      "Epoch [3/3], Batch [2007/2500], Loss: 0.12239625304937363\n",
      "Epoch [3/3], Batch [2008/2500], Loss: 0.15278297662734985\n",
      "Epoch [3/3], Batch [2009/2500], Loss: 0.124924436211586\n",
      "Epoch [3/3], Batch [2010/2500], Loss: 0.2255159318447113\n",
      "Epoch [3/3], Batch [2011/2500], Loss: 0.7853888869285583\n",
      "Epoch [3/3], Batch [2012/2500], Loss: 0.051415640860795975\n",
      "Epoch [3/3], Batch [2013/2500], Loss: 0.04267824441194534\n",
      "Epoch [3/3], Batch [2014/2500], Loss: 0.3498312830924988\n",
      "Epoch [3/3], Batch [2015/2500], Loss: 0.012398535385727882\n",
      "Epoch [3/3], Batch [2016/2500], Loss: 0.17989186942577362\n",
      "Epoch [3/3], Batch [2017/2500], Loss: 0.07227689027786255\n",
      "Epoch [3/3], Batch [2018/2500], Loss: 0.11828026920557022\n",
      "Epoch [3/3], Batch [2019/2500], Loss: 0.07048159837722778\n",
      "Epoch [3/3], Batch [2020/2500], Loss: 0.06661014258861542\n",
      "Epoch [3/3], Batch [2021/2500], Loss: 0.10915160924196243\n",
      "Epoch [3/3], Batch [2022/2500], Loss: 0.07275962829589844\n",
      "Epoch [3/3], Batch [2023/2500], Loss: 0.027567949146032333\n",
      "Epoch [3/3], Batch [2024/2500], Loss: 0.2835330069065094\n",
      "Epoch [3/3], Batch [2025/2500], Loss: 0.06873009353876114\n",
      "Epoch [3/3], Batch [2026/2500], Loss: 0.024990936741232872\n",
      "Epoch [3/3], Batch [2027/2500], Loss: 0.08903427422046661\n",
      "Epoch [3/3], Batch [2028/2500], Loss: 0.05426250025629997\n",
      "Epoch [3/3], Batch [2029/2500], Loss: 0.06415552645921707\n",
      "Epoch [3/3], Batch [2030/2500], Loss: 0.158836230635643\n",
      "Epoch [3/3], Batch [2031/2500], Loss: 0.12285547703504562\n",
      "Epoch [3/3], Batch [2032/2500], Loss: 0.3556646406650543\n",
      "Epoch [3/3], Batch [2033/2500], Loss: 0.020042769610881805\n",
      "Epoch [3/3], Batch [2034/2500], Loss: 0.2029787302017212\n",
      "Epoch [3/3], Batch [2035/2500], Loss: 0.15253987908363342\n",
      "Epoch [3/3], Batch [2036/2500], Loss: 0.1480301171541214\n",
      "Epoch [3/3], Batch [2037/2500], Loss: 0.36519160866737366\n",
      "Epoch [3/3], Batch [2038/2500], Loss: 0.05164797976613045\n",
      "Epoch [3/3], Batch [2039/2500], Loss: 0.10478633642196655\n",
      "Epoch [3/3], Batch [2040/2500], Loss: 0.37621185183525085\n",
      "Epoch [3/3], Batch [2041/2500], Loss: 0.06590048223733902\n",
      "Epoch [3/3], Batch [2042/2500], Loss: 0.07996591180562973\n",
      "Epoch [3/3], Batch [2043/2500], Loss: 0.11998642981052399\n",
      "Epoch [3/3], Batch [2044/2500], Loss: 0.0791390985250473\n",
      "Epoch [3/3], Batch [2045/2500], Loss: 0.2718576192855835\n",
      "Epoch [3/3], Batch [2046/2500], Loss: 1.1900746822357178\n",
      "Epoch [3/3], Batch [2047/2500], Loss: 0.024071887135505676\n",
      "Epoch [3/3], Batch [2048/2500], Loss: 0.08372461795806885\n",
      "Epoch [3/3], Batch [2049/2500], Loss: 0.11464796960353851\n",
      "Epoch [3/3], Batch [2050/2500], Loss: 0.03379468992352486\n",
      "Epoch [3/3], Batch [2051/2500], Loss: 0.07375481724739075\n",
      "Epoch [3/3], Batch [2052/2500], Loss: 0.09112697839736938\n",
      "Epoch [3/3], Batch [2053/2500], Loss: 0.2764654755592346\n",
      "Epoch [3/3], Batch [2054/2500], Loss: 0.20207829773426056\n",
      "Epoch [3/3], Batch [2055/2500], Loss: 0.02917274832725525\n",
      "Epoch [3/3], Batch [2056/2500], Loss: 0.1626398265361786\n",
      "Epoch [3/3], Batch [2057/2500], Loss: 0.10520286858081818\n",
      "Epoch [3/3], Batch [2058/2500], Loss: 0.06256641447544098\n",
      "Epoch [3/3], Batch [2059/2500], Loss: 0.10817980021238327\n",
      "Epoch [3/3], Batch [2060/2500], Loss: 0.5127182006835938\n",
      "Epoch [3/3], Batch [2061/2500], Loss: 0.07184426486492157\n",
      "Epoch [3/3], Batch [2062/2500], Loss: 0.11690700799226761\n",
      "Epoch [3/3], Batch [2063/2500], Loss: 0.1213919147849083\n",
      "Epoch [3/3], Batch [2064/2500], Loss: 0.037375308573246\n",
      "Epoch [3/3], Batch [2065/2500], Loss: 0.2625054121017456\n",
      "Epoch [3/3], Batch [2066/2500], Loss: 0.1938118040561676\n",
      "Epoch [3/3], Batch [2067/2500], Loss: 0.03002696856856346\n",
      "Epoch [3/3], Batch [2068/2500], Loss: 0.04633108898997307\n",
      "Epoch [3/3], Batch [2069/2500], Loss: 0.08080984652042389\n",
      "Epoch [3/3], Batch [2070/2500], Loss: 0.22987207770347595\n",
      "Epoch [3/3], Batch [2071/2500], Loss: 0.5263724327087402\n",
      "Epoch [3/3], Batch [2072/2500], Loss: 0.04938911274075508\n",
      "Epoch [3/3], Batch [2073/2500], Loss: 0.8595698475837708\n",
      "Epoch [3/3], Batch [2074/2500], Loss: 0.13223816454410553\n",
      "Epoch [3/3], Batch [2075/2500], Loss: 0.035756226629018784\n",
      "Epoch [3/3], Batch [2076/2500], Loss: 0.04642374813556671\n",
      "Epoch [3/3], Batch [2077/2500], Loss: 0.027645617723464966\n",
      "Epoch [3/3], Batch [2078/2500], Loss: 0.4944252073764801\n",
      "Epoch [3/3], Batch [2079/2500], Loss: 0.10050886124372482\n",
      "Epoch [3/3], Batch [2080/2500], Loss: 0.15566787123680115\n",
      "Epoch [3/3], Batch [2081/2500], Loss: 0.030001845210790634\n",
      "Epoch [3/3], Batch [2082/2500], Loss: 0.07571321725845337\n",
      "Epoch [3/3], Batch [2083/2500], Loss: 0.14215576648712158\n",
      "Epoch [3/3], Batch [2084/2500], Loss: 0.023310745134949684\n",
      "Epoch [3/3], Batch [2085/2500], Loss: 0.10661227256059647\n",
      "Epoch [3/3], Batch [2086/2500], Loss: 0.2145192176103592\n",
      "Epoch [3/3], Batch [2087/2500], Loss: 0.5270043015480042\n",
      "Epoch [3/3], Batch [2088/2500], Loss: 0.2196895182132721\n",
      "Epoch [3/3], Batch [2089/2500], Loss: 0.08723773062229156\n",
      "Epoch [3/3], Batch [2090/2500], Loss: 0.15791864693164825\n",
      "Epoch [3/3], Batch [2091/2500], Loss: 0.04872920364141464\n",
      "Epoch [3/3], Batch [2092/2500], Loss: 0.6326943039894104\n",
      "Epoch [3/3], Batch [2093/2500], Loss: 0.037663280963897705\n",
      "Epoch [3/3], Batch [2094/2500], Loss: 0.04391561821103096\n",
      "Epoch [3/3], Batch [2095/2500], Loss: 0.2846094071865082\n",
      "Epoch [3/3], Batch [2096/2500], Loss: 0.37771084904670715\n",
      "Epoch [3/3], Batch [2097/2500], Loss: 0.05594629421830177\n",
      "Epoch [3/3], Batch [2098/2500], Loss: 0.08956815302371979\n",
      "Epoch [3/3], Batch [2099/2500], Loss: 0.6882458329200745\n",
      "Epoch [3/3], Batch [2100/2500], Loss: 0.1252841204404831\n",
      "Epoch [3/3], Batch [2101/2500], Loss: 0.026194829493761063\n",
      "Epoch [3/3], Batch [2102/2500], Loss: 0.07212402671575546\n",
      "Epoch [3/3], Batch [2103/2500], Loss: 0.06663204729557037\n",
      "Epoch [3/3], Batch [2104/2500], Loss: 0.12342575937509537\n",
      "Epoch [3/3], Batch [2105/2500], Loss: 0.7363067865371704\n",
      "Epoch [3/3], Batch [2106/2500], Loss: 0.13432222604751587\n",
      "Epoch [3/3], Batch [2107/2500], Loss: 0.5611080527305603\n",
      "Epoch [3/3], Batch [2108/2500], Loss: 0.03167116269469261\n",
      "Epoch [3/3], Batch [2109/2500], Loss: 0.2177295684814453\n",
      "Epoch [3/3], Batch [2110/2500], Loss: 0.032499320805072784\n",
      "Epoch [3/3], Batch [2111/2500], Loss: 0.3589824438095093\n",
      "Epoch [3/3], Batch [2112/2500], Loss: 0.04266437515616417\n",
      "Epoch [3/3], Batch [2113/2500], Loss: 0.06975635141134262\n",
      "Epoch [3/3], Batch [2114/2500], Loss: 0.053973741829395294\n",
      "Epoch [3/3], Batch [2115/2500], Loss: 0.16047081351280212\n",
      "Epoch [3/3], Batch [2116/2500], Loss: 0.06333217024803162\n",
      "Epoch [3/3], Batch [2117/2500], Loss: 0.0658608227968216\n",
      "Epoch [3/3], Batch [2118/2500], Loss: 0.08360700309276581\n",
      "Epoch [3/3], Batch [2119/2500], Loss: 0.043515294790267944\n",
      "Epoch [3/3], Batch [2120/2500], Loss: 0.16990911960601807\n",
      "Epoch [3/3], Batch [2121/2500], Loss: 0.06436118483543396\n",
      "Epoch [3/3], Batch [2122/2500], Loss: 0.07182366400957108\n",
      "Epoch [3/3], Batch [2123/2500], Loss: 0.10009241104125977\n",
      "Epoch [3/3], Batch [2124/2500], Loss: 0.3050864636898041\n",
      "Epoch [3/3], Batch [2125/2500], Loss: 0.06906330585479736\n",
      "Epoch [3/3], Batch [2126/2500], Loss: 0.1073049008846283\n",
      "Epoch [3/3], Batch [2127/2500], Loss: 0.05718623474240303\n",
      "Epoch [3/3], Batch [2128/2500], Loss: 0.04512757062911987\n",
      "Epoch [3/3], Batch [2129/2500], Loss: 0.10704930126667023\n",
      "Epoch [3/3], Batch [2130/2500], Loss: 0.12023979425430298\n",
      "Epoch [3/3], Batch [2131/2500], Loss: 0.35026150941848755\n",
      "Epoch [3/3], Batch [2132/2500], Loss: 0.09041016548871994\n",
      "Epoch [3/3], Batch [2133/2500], Loss: 0.25305184721946716\n",
      "Epoch [3/3], Batch [2134/2500], Loss: 0.037606775760650635\n",
      "Epoch [3/3], Batch [2135/2500], Loss: 0.0396663136780262\n",
      "Epoch [3/3], Batch [2136/2500], Loss: 0.1358591765165329\n",
      "Epoch [3/3], Batch [2137/2500], Loss: 0.2805751860141754\n",
      "Epoch [3/3], Batch [2138/2500], Loss: 0.09822012484073639\n",
      "Epoch [3/3], Batch [2139/2500], Loss: 0.10929329693317413\n",
      "Epoch [3/3], Batch [2140/2500], Loss: 0.07747405767440796\n",
      "Epoch [3/3], Batch [2141/2500], Loss: 0.014660869725048542\n",
      "Epoch [3/3], Batch [2142/2500], Loss: 0.021954422816634178\n",
      "Epoch [3/3], Batch [2143/2500], Loss: 0.15555956959724426\n",
      "Epoch [3/3], Batch [2144/2500], Loss: 0.12219592928886414\n",
      "Epoch [3/3], Batch [2145/2500], Loss: 0.12476033717393875\n",
      "Epoch [3/3], Batch [2146/2500], Loss: 0.016730021685361862\n",
      "Epoch [3/3], Batch [2147/2500], Loss: 0.22376662492752075\n",
      "Epoch [3/3], Batch [2148/2500], Loss: 0.41846963763237\n",
      "Epoch [3/3], Batch [2149/2500], Loss: 0.14716963469982147\n",
      "Epoch [3/3], Batch [2150/2500], Loss: 0.10538723319768906\n",
      "Epoch [3/3], Batch [2151/2500], Loss: 0.05837389826774597\n",
      "Epoch [3/3], Batch [2152/2500], Loss: 0.1705167442560196\n",
      "Epoch [3/3], Batch [2153/2500], Loss: 0.053869567811489105\n",
      "Epoch [3/3], Batch [2154/2500], Loss: 0.21015240252017975\n",
      "Epoch [3/3], Batch [2155/2500], Loss: 0.055663008242845535\n",
      "Epoch [3/3], Batch [2156/2500], Loss: 0.21036753058433533\n",
      "Epoch [3/3], Batch [2157/2500], Loss: 0.042848531156778336\n",
      "Epoch [3/3], Batch [2158/2500], Loss: 0.30511215329170227\n",
      "Epoch [3/3], Batch [2159/2500], Loss: 0.1681886911392212\n",
      "Epoch [3/3], Batch [2160/2500], Loss: 0.2067251354455948\n",
      "Epoch [3/3], Batch [2161/2500], Loss: 0.01601051352918148\n",
      "Epoch [3/3], Batch [2162/2500], Loss: 0.03863851726055145\n",
      "Epoch [3/3], Batch [2163/2500], Loss: 0.13197030127048492\n",
      "Epoch [3/3], Batch [2164/2500], Loss: 0.04399920627474785\n",
      "Epoch [3/3], Batch [2165/2500], Loss: 0.026617463678121567\n",
      "Epoch [3/3], Batch [2166/2500], Loss: 0.03968490660190582\n",
      "Epoch [3/3], Batch [2167/2500], Loss: 0.01896742172539234\n",
      "Epoch [3/3], Batch [2168/2500], Loss: 0.082114078104496\n",
      "Epoch [3/3], Batch [2169/2500], Loss: 0.16850271821022034\n",
      "Epoch [3/3], Batch [2170/2500], Loss: 0.3523877263069153\n",
      "Epoch [3/3], Batch [2171/2500], Loss: 0.01970195770263672\n",
      "Epoch [3/3], Batch [2172/2500], Loss: 0.03981970623135567\n",
      "Epoch [3/3], Batch [2173/2500], Loss: 0.06053423509001732\n",
      "Epoch [3/3], Batch [2174/2500], Loss: 0.020806502550840378\n",
      "Epoch [3/3], Batch [2175/2500], Loss: 0.17301315069198608\n",
      "Epoch [3/3], Batch [2176/2500], Loss: 0.03331134840846062\n",
      "Epoch [3/3], Batch [2177/2500], Loss: 0.10202085226774216\n",
      "Epoch [3/3], Batch [2178/2500], Loss: 0.014827623032033443\n",
      "Epoch [3/3], Batch [2179/2500], Loss: 0.13425937294960022\n",
      "Epoch [3/3], Batch [2180/2500], Loss: 0.2027292251586914\n",
      "Epoch [3/3], Batch [2181/2500], Loss: 0.03224115073680878\n",
      "Epoch [3/3], Batch [2182/2500], Loss: 0.03610982745885849\n",
      "Epoch [3/3], Batch [2183/2500], Loss: 0.029950924217700958\n",
      "Epoch [3/3], Batch [2184/2500], Loss: 0.01971817947924137\n",
      "Epoch [3/3], Batch [2185/2500], Loss: 0.3051438629627228\n",
      "Epoch [3/3], Batch [2186/2500], Loss: 0.11902031302452087\n",
      "Epoch [3/3], Batch [2187/2500], Loss: 0.14498190581798553\n",
      "Epoch [3/3], Batch [2188/2500], Loss: 0.014262830838561058\n",
      "Epoch [3/3], Batch [2189/2500], Loss: 0.022075127810239792\n",
      "Epoch [3/3], Batch [2190/2500], Loss: 0.03358021378517151\n",
      "Epoch [3/3], Batch [2191/2500], Loss: 0.050929080694913864\n",
      "Epoch [3/3], Batch [2192/2500], Loss: 0.1296890527009964\n",
      "Epoch [3/3], Batch [2193/2500], Loss: 0.024686582386493683\n",
      "Epoch [3/3], Batch [2194/2500], Loss: 0.0722687616944313\n",
      "Epoch [3/3], Batch [2195/2500], Loss: 0.20919902622699738\n",
      "Epoch [3/3], Batch [2196/2500], Loss: 0.33002787828445435\n",
      "Epoch [3/3], Batch [2197/2500], Loss: 0.35235559940338135\n",
      "Epoch [3/3], Batch [2198/2500], Loss: 0.024409465491771698\n",
      "Epoch [3/3], Batch [2199/2500], Loss: 0.027534684166312218\n",
      "Epoch [3/3], Batch [2200/2500], Loss: 0.03764718770980835\n",
      "Epoch [3/3], Batch [2201/2500], Loss: 0.033524490892887115\n",
      "Epoch [3/3], Batch [2202/2500], Loss: 0.04361095279455185\n",
      "Epoch [3/3], Batch [2203/2500], Loss: 0.017468474805355072\n",
      "Epoch [3/3], Batch [2204/2500], Loss: 0.02504884824156761\n",
      "Epoch [3/3], Batch [2205/2500], Loss: 0.30775588750839233\n",
      "Epoch [3/3], Batch [2206/2500], Loss: 0.16097138822078705\n",
      "Epoch [3/3], Batch [2207/2500], Loss: 0.029420219361782074\n",
      "Epoch [3/3], Batch [2208/2500], Loss: 0.023753464221954346\n",
      "Epoch [3/3], Batch [2209/2500], Loss: 0.29852810502052307\n",
      "Epoch [3/3], Batch [2210/2500], Loss: 0.24291978776454926\n",
      "Epoch [3/3], Batch [2211/2500], Loss: 0.20114973187446594\n",
      "Epoch [3/3], Batch [2212/2500], Loss: 0.03565436974167824\n",
      "Epoch [3/3], Batch [2213/2500], Loss: 0.19265016913414001\n",
      "Epoch [3/3], Batch [2214/2500], Loss: 0.03043941780924797\n",
      "Epoch [3/3], Batch [2215/2500], Loss: 0.12821421027183533\n",
      "Epoch [3/3], Batch [2216/2500], Loss: 0.07493530213832855\n",
      "Epoch [3/3], Batch [2217/2500], Loss: 0.03581715375185013\n",
      "Epoch [3/3], Batch [2218/2500], Loss: 0.018313560634851456\n",
      "Epoch [3/3], Batch [2219/2500], Loss: 0.1380009949207306\n",
      "Epoch [3/3], Batch [2220/2500], Loss: 0.5215862393379211\n",
      "Epoch [3/3], Batch [2221/2500], Loss: 0.1351221650838852\n",
      "Epoch [3/3], Batch [2222/2500], Loss: 0.040287457406520844\n",
      "Epoch [3/3], Batch [2223/2500], Loss: 0.10908897966146469\n",
      "Epoch [3/3], Batch [2224/2500], Loss: 0.043754711747169495\n",
      "Epoch [3/3], Batch [2225/2500], Loss: 0.026308666914701462\n",
      "Epoch [3/3], Batch [2226/2500], Loss: 0.06090031564235687\n",
      "Epoch [3/3], Batch [2227/2500], Loss: 0.03230556845664978\n",
      "Epoch [3/3], Batch [2228/2500], Loss: 0.04580245167016983\n",
      "Epoch [3/3], Batch [2229/2500], Loss: 0.07801919430494308\n",
      "Epoch [3/3], Batch [2230/2500], Loss: 0.20069995522499084\n",
      "Epoch [3/3], Batch [2231/2500], Loss: 0.027412135154008865\n",
      "Epoch [3/3], Batch [2232/2500], Loss: 0.20505988597869873\n",
      "Epoch [3/3], Batch [2233/2500], Loss: 0.22851073741912842\n",
      "Epoch [3/3], Batch [2234/2500], Loss: 0.1410546600818634\n",
      "Epoch [3/3], Batch [2235/2500], Loss: 0.10973678529262543\n",
      "Epoch [3/3], Batch [2236/2500], Loss: 0.09207776933908463\n",
      "Epoch [3/3], Batch [2237/2500], Loss: 0.07416040450334549\n",
      "Epoch [3/3], Batch [2238/2500], Loss: 0.05909522622823715\n",
      "Epoch [3/3], Batch [2239/2500], Loss: 0.025720704346895218\n",
      "Epoch [3/3], Batch [2240/2500], Loss: 0.04013931006193161\n",
      "Epoch [3/3], Batch [2241/2500], Loss: 0.02660776674747467\n",
      "Epoch [3/3], Batch [2242/2500], Loss: 0.3313736617565155\n",
      "Epoch [3/3], Batch [2243/2500], Loss: 0.01021333783864975\n",
      "Epoch [3/3], Batch [2244/2500], Loss: 0.06371597945690155\n",
      "Epoch [3/3], Batch [2245/2500], Loss: 0.017814939841628075\n",
      "Epoch [3/3], Batch [2246/2500], Loss: 0.18403944373130798\n",
      "Epoch [3/3], Batch [2247/2500], Loss: 0.09262414276599884\n",
      "Epoch [3/3], Batch [2248/2500], Loss: 0.04022424295544624\n",
      "Epoch [3/3], Batch [2249/2500], Loss: 0.02730030193924904\n",
      "Epoch [3/3], Batch [2250/2500], Loss: 0.026207631453871727\n",
      "Epoch [3/3], Batch [2251/2500], Loss: 0.08198551088571548\n",
      "Epoch [3/3], Batch [2252/2500], Loss: 0.0729864165186882\n",
      "Epoch [3/3], Batch [2253/2500], Loss: 0.1069590151309967\n",
      "Epoch [3/3], Batch [2254/2500], Loss: 0.18442684412002563\n",
      "Epoch [3/3], Batch [2255/2500], Loss: 0.28938373923301697\n",
      "Epoch [3/3], Batch [2256/2500], Loss: 0.00625616917386651\n",
      "Epoch [3/3], Batch [2257/2500], Loss: 0.00818847119808197\n",
      "Epoch [3/3], Batch [2258/2500], Loss: 0.42913752794265747\n",
      "Epoch [3/3], Batch [2259/2500], Loss: 0.05690537393093109\n",
      "Epoch [3/3], Batch [2260/2500], Loss: 0.0814749151468277\n",
      "Epoch [3/3], Batch [2261/2500], Loss: 0.15818151831626892\n",
      "Epoch [3/3], Batch [2262/2500], Loss: 0.0319109745323658\n",
      "Epoch [3/3], Batch [2263/2500], Loss: 0.5678269267082214\n",
      "Epoch [3/3], Batch [2264/2500], Loss: 0.06415972858667374\n",
      "Epoch [3/3], Batch [2265/2500], Loss: 0.06217057257890701\n",
      "Epoch [3/3], Batch [2266/2500], Loss: 0.1695510745048523\n",
      "Epoch [3/3], Batch [2267/2500], Loss: 0.021839138120412827\n",
      "Epoch [3/3], Batch [2268/2500], Loss: 0.3598177433013916\n",
      "Epoch [3/3], Batch [2269/2500], Loss: 0.016878481954336166\n",
      "Epoch [3/3], Batch [2270/2500], Loss: 0.39416423439979553\n",
      "Epoch [3/3], Batch [2271/2500], Loss: 0.7053244709968567\n",
      "Epoch [3/3], Batch [2272/2500], Loss: 0.06320443749427795\n",
      "Epoch [3/3], Batch [2273/2500], Loss: 0.29824748635292053\n",
      "Epoch [3/3], Batch [2274/2500], Loss: 0.04509008675813675\n",
      "Epoch [3/3], Batch [2275/2500], Loss: 0.015325060114264488\n",
      "Epoch [3/3], Batch [2276/2500], Loss: 0.23511788249015808\n",
      "Epoch [3/3], Batch [2277/2500], Loss: 0.6161413192749023\n",
      "Epoch [3/3], Batch [2278/2500], Loss: 0.4535372853279114\n",
      "Epoch [3/3], Batch [2279/2500], Loss: 0.22285959124565125\n",
      "Epoch [3/3], Batch [2280/2500], Loss: 0.0535840280354023\n",
      "Epoch [3/3], Batch [2281/2500], Loss: 0.1532789170742035\n",
      "Epoch [3/3], Batch [2282/2500], Loss: 0.011687614023685455\n",
      "Epoch [3/3], Batch [2283/2500], Loss: 0.38213372230529785\n",
      "Epoch [3/3], Batch [2284/2500], Loss: 0.11875773221254349\n",
      "Epoch [3/3], Batch [2285/2500], Loss: 0.30142056941986084\n",
      "Epoch [3/3], Batch [2286/2500], Loss: 0.025056444108486176\n",
      "Epoch [3/3], Batch [2287/2500], Loss: 0.44424304366111755\n",
      "Epoch [3/3], Batch [2288/2500], Loss: 0.07719708979129791\n",
      "Epoch [3/3], Batch [2289/2500], Loss: 0.06927850842475891\n",
      "Epoch [3/3], Batch [2290/2500], Loss: 0.45956820249557495\n",
      "Epoch [3/3], Batch [2291/2500], Loss: 0.16890296339988708\n",
      "Epoch [3/3], Batch [2292/2500], Loss: 0.013790931552648544\n",
      "Epoch [3/3], Batch [2293/2500], Loss: 0.027345085516572\n",
      "Epoch [3/3], Batch [2294/2500], Loss: 0.18163469433784485\n",
      "Epoch [3/3], Batch [2295/2500], Loss: 0.41598576307296753\n",
      "Epoch [3/3], Batch [2296/2500], Loss: 0.4279504716396332\n",
      "Epoch [3/3], Batch [2297/2500], Loss: 0.5113450288772583\n",
      "Epoch [3/3], Batch [2298/2500], Loss: 0.05810827389359474\n",
      "Epoch [3/3], Batch [2299/2500], Loss: 0.16430138051509857\n",
      "Epoch [3/3], Batch [2300/2500], Loss: 0.2883498966693878\n",
      "Epoch [3/3], Batch [2301/2500], Loss: 0.039822280406951904\n",
      "Epoch [3/3], Batch [2302/2500], Loss: 0.1566731482744217\n",
      "Epoch [3/3], Batch [2303/2500], Loss: 0.014310344122350216\n",
      "Epoch [3/3], Batch [2304/2500], Loss: 0.01112999115139246\n",
      "Epoch [3/3], Batch [2305/2500], Loss: 0.1332080215215683\n",
      "Epoch [3/3], Batch [2306/2500], Loss: 0.27178263664245605\n",
      "Epoch [3/3], Batch [2307/2500], Loss: 0.011721991933882236\n",
      "Epoch [3/3], Batch [2308/2500], Loss: 0.14908833801746368\n",
      "Epoch [3/3], Batch [2309/2500], Loss: 0.08849148452281952\n",
      "Epoch [3/3], Batch [2310/2500], Loss: 0.18078412115573883\n",
      "Epoch [3/3], Batch [2311/2500], Loss: 0.11550421267747879\n",
      "Epoch [3/3], Batch [2312/2500], Loss: 0.04658767580986023\n",
      "Epoch [3/3], Batch [2313/2500], Loss: 0.09375858306884766\n",
      "Epoch [3/3], Batch [2314/2500], Loss: 0.08262623101472855\n",
      "Epoch [3/3], Batch [2315/2500], Loss: 0.04263370484113693\n",
      "Epoch [3/3], Batch [2316/2500], Loss: 0.17958012223243713\n",
      "Epoch [3/3], Batch [2317/2500], Loss: 0.027809979394078255\n",
      "Epoch [3/3], Batch [2318/2500], Loss: 0.23913784325122833\n",
      "Epoch [3/3], Batch [2319/2500], Loss: 0.023849572986364365\n",
      "Epoch [3/3], Batch [2320/2500], Loss: 0.09291046857833862\n",
      "Epoch [3/3], Batch [2321/2500], Loss: 0.14107653498649597\n",
      "Epoch [3/3], Batch [2322/2500], Loss: 0.21933870017528534\n",
      "Epoch [3/3], Batch [2323/2500], Loss: 0.14155039191246033\n",
      "Epoch [3/3], Batch [2324/2500], Loss: 0.3280048370361328\n",
      "Epoch [3/3], Batch [2325/2500], Loss: 0.27820298075675964\n",
      "Epoch [3/3], Batch [2326/2500], Loss: 0.25736570358276367\n",
      "Epoch [3/3], Batch [2327/2500], Loss: 0.14988023042678833\n",
      "Epoch [3/3], Batch [2328/2500], Loss: 0.01951828971505165\n",
      "Epoch [3/3], Batch [2329/2500], Loss: 0.10758926719427109\n",
      "Epoch [3/3], Batch [2330/2500], Loss: 0.2964392602443695\n",
      "Epoch [3/3], Batch [2331/2500], Loss: 0.012656140141189098\n",
      "Epoch [3/3], Batch [2332/2500], Loss: 0.3185498118400574\n",
      "Epoch [3/3], Batch [2333/2500], Loss: 0.05020998418331146\n",
      "Epoch [3/3], Batch [2334/2500], Loss: 0.27131402492523193\n",
      "Epoch [3/3], Batch [2335/2500], Loss: 0.25550204515457153\n",
      "Epoch [3/3], Batch [2336/2500], Loss: 0.05153251439332962\n",
      "Epoch [3/3], Batch [2337/2500], Loss: 0.10596863925457001\n",
      "Epoch [3/3], Batch [2338/2500], Loss: 0.3294731080532074\n",
      "Epoch [3/3], Batch [2339/2500], Loss: 0.10097785294055939\n",
      "Epoch [3/3], Batch [2340/2500], Loss: 0.22212587296962738\n",
      "Epoch [3/3], Batch [2341/2500], Loss: 0.30692392587661743\n",
      "Epoch [3/3], Batch [2342/2500], Loss: 0.061345912516117096\n",
      "Epoch [3/3], Batch [2343/2500], Loss: 0.046539612114429474\n",
      "Epoch [3/3], Batch [2344/2500], Loss: 0.06596978008747101\n",
      "Epoch [3/3], Batch [2345/2500], Loss: 0.10108088701963425\n",
      "Epoch [3/3], Batch [2346/2500], Loss: 0.10058678686618805\n",
      "Epoch [3/3], Batch [2347/2500], Loss: 0.3023534119129181\n",
      "Epoch [3/3], Batch [2348/2500], Loss: 0.03718969225883484\n",
      "Epoch [3/3], Batch [2349/2500], Loss: 0.09914656728506088\n",
      "Epoch [3/3], Batch [2350/2500], Loss: 0.05794410780072212\n",
      "Epoch [3/3], Batch [2351/2500], Loss: 0.15934333205223083\n",
      "Epoch [3/3], Batch [2352/2500], Loss: 0.09185237437486649\n",
      "Epoch [3/3], Batch [2353/2500], Loss: 0.09733375906944275\n",
      "Epoch [3/3], Batch [2354/2500], Loss: 0.011695977300405502\n",
      "Epoch [3/3], Batch [2355/2500], Loss: 0.3775542974472046\n",
      "Epoch [3/3], Batch [2356/2500], Loss: 0.07389514148235321\n",
      "Epoch [3/3], Batch [2357/2500], Loss: 0.4156407117843628\n",
      "Epoch [3/3], Batch [2358/2500], Loss: 0.6437122821807861\n",
      "Epoch [3/3], Batch [2359/2500], Loss: 0.19428573548793793\n",
      "Epoch [3/3], Batch [2360/2500], Loss: 0.0297219380736351\n",
      "Epoch [3/3], Batch [2361/2500], Loss: 0.06672067195177078\n",
      "Epoch [3/3], Batch [2362/2500], Loss: 0.2723180055618286\n",
      "Epoch [3/3], Batch [2363/2500], Loss: 0.013323505409061909\n",
      "Epoch [3/3], Batch [2364/2500], Loss: 0.061397284269332886\n",
      "Epoch [3/3], Batch [2365/2500], Loss: 0.02304384857416153\n",
      "Epoch [3/3], Batch [2366/2500], Loss: 0.219477578997612\n",
      "Epoch [3/3], Batch [2367/2500], Loss: 0.29648569226264954\n",
      "Epoch [3/3], Batch [2368/2500], Loss: 0.0665229931473732\n",
      "Epoch [3/3], Batch [2369/2500], Loss: 0.31342801451683044\n",
      "Epoch [3/3], Batch [2370/2500], Loss: 0.16353288292884827\n",
      "Epoch [3/3], Batch [2371/2500], Loss: 0.07571826130151749\n",
      "Epoch [3/3], Batch [2372/2500], Loss: 0.0382067933678627\n",
      "Epoch [3/3], Batch [2373/2500], Loss: 0.016804387792944908\n",
      "Epoch [3/3], Batch [2374/2500], Loss: 0.03592360019683838\n",
      "Epoch [3/3], Batch [2375/2500], Loss: 0.12803219258785248\n",
      "Epoch [3/3], Batch [2376/2500], Loss: 0.016519596800208092\n",
      "Epoch [3/3], Batch [2377/2500], Loss: 0.039455100893974304\n",
      "Epoch [3/3], Batch [2378/2500], Loss: 0.04784851893782616\n",
      "Epoch [3/3], Batch [2379/2500], Loss: 0.06188870966434479\n",
      "Epoch [3/3], Batch [2380/2500], Loss: 0.0283501073718071\n",
      "Epoch [3/3], Batch [2381/2500], Loss: 1.0586276054382324\n",
      "Epoch [3/3], Batch [2382/2500], Loss: 0.027482695877552032\n",
      "Epoch [3/3], Batch [2383/2500], Loss: 0.14739441871643066\n",
      "Epoch [3/3], Batch [2384/2500], Loss: 0.028593897819519043\n",
      "Epoch [3/3], Batch [2385/2500], Loss: 0.037938833236694336\n",
      "Epoch [3/3], Batch [2386/2500], Loss: 0.47801393270492554\n",
      "Epoch [3/3], Batch [2387/2500], Loss: 0.21385939419269562\n",
      "Epoch [3/3], Batch [2388/2500], Loss: 0.27943527698516846\n",
      "Epoch [3/3], Batch [2389/2500], Loss: 0.3861662447452545\n",
      "Epoch [3/3], Batch [2390/2500], Loss: 0.08170202374458313\n",
      "Epoch [3/3], Batch [2391/2500], Loss: 0.048511020839214325\n",
      "Epoch [3/3], Batch [2392/2500], Loss: 0.033422455191612244\n",
      "Epoch [3/3], Batch [2393/2500], Loss: 0.7201741933822632\n",
      "Epoch [3/3], Batch [2394/2500], Loss: 0.013520069420337677\n",
      "Epoch [3/3], Batch [2395/2500], Loss: 0.012591509148478508\n",
      "Epoch [3/3], Batch [2396/2500], Loss: 0.20992179214954376\n",
      "Epoch [3/3], Batch [2397/2500], Loss: 0.17333370447158813\n",
      "Epoch [3/3], Batch [2398/2500], Loss: 0.11347460746765137\n",
      "Epoch [3/3], Batch [2399/2500], Loss: 0.19869743287563324\n",
      "Epoch [3/3], Batch [2400/2500], Loss: 0.07696913927793503\n",
      "Epoch [3/3], Batch [2401/2500], Loss: 0.07201892882585526\n",
      "Epoch [3/3], Batch [2402/2500], Loss: 0.012565585784614086\n",
      "Epoch [3/3], Batch [2403/2500], Loss: 0.18856275081634521\n",
      "Epoch [3/3], Batch [2404/2500], Loss: 0.09448729455471039\n",
      "Epoch [3/3], Batch [2405/2500], Loss: 0.5325626134872437\n",
      "Epoch [3/3], Batch [2406/2500], Loss: 0.08431898802518845\n",
      "Epoch [3/3], Batch [2407/2500], Loss: 0.038485199213027954\n",
      "Epoch [3/3], Batch [2408/2500], Loss: 0.26405835151672363\n",
      "Epoch [3/3], Batch [2409/2500], Loss: 0.24208156764507294\n",
      "Epoch [3/3], Batch [2410/2500], Loss: 0.04511628299951553\n",
      "Epoch [3/3], Batch [2411/2500], Loss: 0.2297978401184082\n",
      "Epoch [3/3], Batch [2412/2500], Loss: 0.1642952710390091\n",
      "Epoch [3/3], Batch [2413/2500], Loss: 0.0875171422958374\n",
      "Epoch [3/3], Batch [2414/2500], Loss: 0.07886364310979843\n",
      "Epoch [3/3], Batch [2415/2500], Loss: 0.01736409030854702\n",
      "Epoch [3/3], Batch [2416/2500], Loss: 0.2575526535511017\n",
      "Epoch [3/3], Batch [2417/2500], Loss: 0.036337003111839294\n",
      "Epoch [3/3], Batch [2418/2500], Loss: 0.017784804105758667\n",
      "Epoch [3/3], Batch [2419/2500], Loss: 0.3046827018260956\n",
      "Epoch [3/3], Batch [2420/2500], Loss: 0.10009488463401794\n",
      "Epoch [3/3], Batch [2421/2500], Loss: 0.04855882748961449\n",
      "Epoch [3/3], Batch [2422/2500], Loss: 0.9188346862792969\n",
      "Epoch [3/3], Batch [2423/2500], Loss: 0.6133301854133606\n",
      "Epoch [3/3], Batch [2424/2500], Loss: 0.4252919852733612\n",
      "Epoch [3/3], Batch [2425/2500], Loss: 0.4447074830532074\n",
      "Epoch [3/3], Batch [2426/2500], Loss: 0.24781250953674316\n",
      "Epoch [3/3], Batch [2427/2500], Loss: 0.12523649632930756\n",
      "Epoch [3/3], Batch [2428/2500], Loss: 0.24932247400283813\n",
      "Epoch [3/3], Batch [2429/2500], Loss: 0.0316515751183033\n",
      "Epoch [3/3], Batch [2430/2500], Loss: 0.1296626478433609\n",
      "Epoch [3/3], Batch [2431/2500], Loss: 0.012730073183774948\n",
      "Epoch [3/3], Batch [2432/2500], Loss: 0.054667942225933075\n",
      "Epoch [3/3], Batch [2433/2500], Loss: 0.07481610029935837\n",
      "Epoch [3/3], Batch [2434/2500], Loss: 0.03970027342438698\n",
      "Epoch [3/3], Batch [2435/2500], Loss: 0.17460961639881134\n",
      "Epoch [3/3], Batch [2436/2500], Loss: 0.04770928621292114\n",
      "Epoch [3/3], Batch [2437/2500], Loss: 0.19213628768920898\n",
      "Epoch [3/3], Batch [2438/2500], Loss: 0.16614678502082825\n",
      "Epoch [3/3], Batch [2439/2500], Loss: 0.49898669123649597\n",
      "Epoch [3/3], Batch [2440/2500], Loss: 0.1660223752260208\n",
      "Epoch [3/3], Batch [2441/2500], Loss: 0.028855521231889725\n",
      "Epoch [3/3], Batch [2442/2500], Loss: 0.1794067621231079\n",
      "Epoch [3/3], Batch [2443/2500], Loss: 0.17965424060821533\n",
      "Epoch [3/3], Batch [2444/2500], Loss: 0.016082189977169037\n",
      "Epoch [3/3], Batch [2445/2500], Loss: 0.010735960677266121\n",
      "Epoch [3/3], Batch [2446/2500], Loss: 0.06343134492635727\n",
      "Epoch [3/3], Batch [2447/2500], Loss: 0.25661706924438477\n",
      "Epoch [3/3], Batch [2448/2500], Loss: 0.09636380523443222\n",
      "Epoch [3/3], Batch [2449/2500], Loss: 0.018101537600159645\n",
      "Epoch [3/3], Batch [2450/2500], Loss: 0.2879481017589569\n",
      "Epoch [3/3], Batch [2451/2500], Loss: 0.027126841247081757\n",
      "Epoch [3/3], Batch [2452/2500], Loss: 0.06600429862737656\n",
      "Epoch [3/3], Batch [2453/2500], Loss: 0.3783586025238037\n",
      "Epoch [3/3], Batch [2454/2500], Loss: 0.4883808493614197\n",
      "Epoch [3/3], Batch [2455/2500], Loss: 0.10624337196350098\n",
      "Epoch [3/3], Batch [2456/2500], Loss: 0.37687620520591736\n",
      "Epoch [3/3], Batch [2457/2500], Loss: 0.04220285266637802\n",
      "Epoch [3/3], Batch [2458/2500], Loss: 0.08986259996891022\n",
      "Epoch [3/3], Batch [2459/2500], Loss: 0.25527316331863403\n",
      "Epoch [3/3], Batch [2460/2500], Loss: 0.1269455999135971\n",
      "Epoch [3/3], Batch [2461/2500], Loss: 0.06605316698551178\n",
      "Epoch [3/3], Batch [2462/2500], Loss: 0.2209296077489853\n",
      "Epoch [3/3], Batch [2463/2500], Loss: 0.0885370597243309\n",
      "Epoch [3/3], Batch [2464/2500], Loss: 0.07621262967586517\n",
      "Epoch [3/3], Batch [2465/2500], Loss: 0.26161882281303406\n",
      "Epoch [3/3], Batch [2466/2500], Loss: 0.1396484375\n",
      "Epoch [3/3], Batch [2467/2500], Loss: 0.2536795139312744\n",
      "Epoch [3/3], Batch [2468/2500], Loss: 0.017767053097486496\n",
      "Epoch [3/3], Batch [2469/2500], Loss: 0.03967424854636192\n",
      "Epoch [3/3], Batch [2470/2500], Loss: 0.04096977040171623\n",
      "Epoch [3/3], Batch [2471/2500], Loss: 0.12855949997901917\n",
      "Epoch [3/3], Batch [2472/2500], Loss: 0.06865029782056808\n",
      "Epoch [3/3], Batch [2473/2500], Loss: 0.2922247350215912\n",
      "Epoch [3/3], Batch [2474/2500], Loss: 0.07393273711204529\n",
      "Epoch [3/3], Batch [2475/2500], Loss: 0.22369472682476044\n",
      "Epoch [3/3], Batch [2476/2500], Loss: 0.1190769299864769\n",
      "Epoch [3/3], Batch [2477/2500], Loss: 0.10708881914615631\n",
      "Epoch [3/3], Batch [2478/2500], Loss: 0.35634270310401917\n",
      "Epoch [3/3], Batch [2479/2500], Loss: 0.15177036821842194\n",
      "Epoch [3/3], Batch [2480/2500], Loss: 0.1892232745885849\n",
      "Epoch [3/3], Batch [2481/2500], Loss: 0.3644384741783142\n",
      "Epoch [3/3], Batch [2482/2500], Loss: 0.08125074952840805\n",
      "Epoch [3/3], Batch [2483/2500], Loss: 0.17986179888248444\n",
      "Epoch [3/3], Batch [2484/2500], Loss: 0.0602375790476799\n",
      "Epoch [3/3], Batch [2485/2500], Loss: 0.36936458945274353\n",
      "Epoch [3/3], Batch [2486/2500], Loss: 0.05586874857544899\n",
      "Epoch [3/3], Batch [2487/2500], Loss: 0.3167152404785156\n",
      "Epoch [3/3], Batch [2488/2500], Loss: 0.28562673926353455\n",
      "Epoch [3/3], Batch [2489/2500], Loss: 0.0618707537651062\n",
      "Epoch [3/3], Batch [2490/2500], Loss: 0.10173024982213974\n",
      "Epoch [3/3], Batch [2491/2500], Loss: 0.13795864582061768\n",
      "Epoch [3/3], Batch [2492/2500], Loss: 0.4483284652233124\n",
      "Epoch [3/3], Batch [2493/2500], Loss: 0.16453328728675842\n",
      "Epoch [3/3], Batch [2494/2500], Loss: 0.11291345208883286\n",
      "Epoch [3/3], Batch [2495/2500], Loss: 0.0978359505534172\n",
      "Epoch [3/3], Batch [2496/2500], Loss: 0.27772271633148193\n",
      "Epoch [3/3], Batch [2497/2500], Loss: 0.3103162348270416\n",
      "Epoch [3/3], Batch [2498/2500], Loss: 0.14458942413330078\n",
      "Epoch [3/3], Batch [2499/2500], Loss: 0.03031260520219803\n",
      "Epoch [3/3], Batch [2500/2500], Loss: 0.28729313611984253\n",
      "Epoch [3/3] Average Loss: 0.14999720402713865\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    DebertaV2Tokenizer,\n",
    "    DebertaV2ForQuestionAnswering,\n",
    "    BertModel\n",
    ")\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize both tokenizers\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "deberta_tokenizer = DebertaV2Tokenizer.from_pretrained('microsoft/deberta-v3-base')\n",
    "\n",
    "# Preprocess data for both BERT and DeBERTa\n",
    "def preprocess_data(df):\n",
    "    questions = df['question'].tolist()\n",
    "    contexts = [\" \".join([\" \".join(context[1]) for context in item]) for item in df['context']]\n",
    "    answers = df['answer'].tolist()\n",
    "    \n",
    "    # BERT Tokenization\n",
    "    bert_query_encodings = bert_tokenizer(questions, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "    bert_context_encodings = bert_tokenizer(contexts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    \n",
    "    # DeBERTa Tokenization\n",
    "    deberta_input_encodings = deberta_tokenizer(questions, contexts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    \n",
    "    # Supporting Facts for Retrieval Labels using BERT Encodings\n",
    "    supporting_facts = df['supporting_facts'].tolist()\n",
    "    labels = []\n",
    "    for i, facts in enumerate(supporting_facts):\n",
    "        label = [0] * bert_context_encodings['input_ids'].size(1)\n",
    "        for fact in facts:\n",
    "            title, sent_idx = fact\n",
    "            context = df['context'].iloc[i]\n",
    "            for j, para in enumerate(context):\n",
    "                if para[0] == title:\n",
    "                    try:\n",
    "                        sentence_tokens = bert_tokenizer.tokenize(para[1][sent_idx])\n",
    "                        if len(sentence_tokens) == 0:\n",
    "                            continue\n",
    "                        start_idx = bert_tokenizer.convert_tokens_to_ids(sentence_tokens)[0]\n",
    "                        input_ids_list = bert_context_encodings['input_ids'][i].tolist()\n",
    "                        if start_idx in input_ids_list:\n",
    "                            label[input_ids_list.index(start_idx)] = 1\n",
    "                    except IndexError:\n",
    "                        continue\n",
    "        labels.append(label)\n",
    "    \n",
    "    # Return both BERT and DeBERTa processed data\n",
    "    return {\n",
    "        # BERT Encodings\n",
    "        'bert_query_input_ids': bert_query_encodings['input_ids'],\n",
    "        'bert_query_attention_mask': bert_query_encodings['attention_mask'],\n",
    "        'bert_context_input_ids': bert_context_encodings['input_ids'],\n",
    "        'bert_context_attention_mask': bert_context_encodings['attention_mask'],\n",
    "        \n",
    "        # DeBERTa Encodings\n",
    "        'deberta_input_ids': deberta_input_encodings['input_ids'],\n",
    "        'deberta_attention_mask': deberta_input_encodings['attention_mask'],\n",
    "        \n",
    "        # Labels\n",
    "        'labels': torch.tensor(labels),\n",
    "    }\n",
    "\n",
    "# # Define GANModel with both BERT and DeBERTa components\n",
    "# class RetrievalNetwork(nn.Module):\n",
    "#     def __init__(self, bert_model='bert-base-uncased'):\n",
    "#         super(RetrievalNetwork, self).__init__()\n",
    "#         self.bert = BertModel.from_pretrained(bert_model)\n",
    "#         self.classifier = nn.Linear(self.bert.config.hidden_size, 1)  # Binary classifier for relevance\n",
    "# \n",
    "#     def forward(self, input_ids, attention_mask):\n",
    "#         outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#         pooled_output = outputs[1]  # [CLS] token representation\n",
    "#         logits = self.classifier(pooled_output)\n",
    "#         return logits\n",
    "\n",
    "class AnswerGenerationNetwork(nn.Module):\n",
    "    def __init__(self, deberta_model='microsoft/deberta-v3-base'):\n",
    "        super(AnswerGenerationNetwork, self).__init__()\n",
    "        self.deberta = DebertaV2ForQuestionAnswering.from_pretrained(deberta_model)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.deberta(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            start_positions=labels[:, 0],\n",
    "            end_positions=labels[:, 1]\n",
    "        )\n",
    "        return outputs.start_logits, outputs.end_logits, outputs.loss\n",
    "\n",
    "class RetrievalNetwork(nn.Module):\n",
    "    def __init__(self, bert_model='bert-base-uncased'):\n",
    "        super(RetrievalNetwork, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, 1)  # Binary classifier for each token\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = outputs.last_hidden_state  # Use token-wise hidden states\n",
    "        logits = self.classifier(sequence_output).squeeze(-1)  # Shape: [batch_size, sequence_length]\n",
    "        return logits\n",
    "\n",
    "class GANModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GANModel, self).__init__()\n",
    "        self.retrieval_network = RetrievalNetwork()\n",
    "        self.answer_generation_network = AnswerGenerationNetwork()\n",
    "\n",
    "    def forward(self, preprocessed_data):\n",
    "        # For BERT (Retrieval Network)\n",
    "        retrieval_logits = self.retrieval_network(\n",
    "            input_ids=preprocessed_data['bert_context_input_ids'],\n",
    "            attention_mask=preprocessed_data['bert_context_attention_mask']\n",
    "        )\n",
    "        \n",
    "        # Calculate retrieval loss\n",
    "        retrieval_loss_fn = nn.BCEWithLogitsLoss()\n",
    "        retrieval_loss = retrieval_loss_fn(retrieval_logits, preprocessed_data['labels'].float())\n",
    "        \n",
    "        # For DeBERTa (Answer Generation Network)\n",
    "        start_logits, end_logits, generation_loss = self.answer_generation_network(\n",
    "            input_ids=preprocessed_data['deberta_input_ids'],\n",
    "            attention_mask=preprocessed_data['deberta_attention_mask'],\n",
    "            labels=preprocessed_data['labels']\n",
    "        )\n",
    "        \n",
    "        # Combine losses\n",
    "        total_loss = retrieval_loss + generation_loss\n",
    "        return total_loss, retrieval_logits, (start_logits, end_logits)\n",
    "\n",
    "\n",
    "# Training loop with batch processing for GANModel\n",
    "def train(model, optimizer, preprocessed_data, batch_size=4, epochs=3):\n",
    "    print(\"Starting training...\")\n",
    "    model.train()\n",
    "\n",
    "    # Split the data into batches for both BERT and DeBERTa tokenized inputs\n",
    "    bert_context_batches = torch.split(preprocessed_data['bert_context_input_ids'], batch_size)\n",
    "    bert_context_mask_batches = torch.split(preprocessed_data['bert_context_attention_mask'], batch_size)\n",
    "    \n",
    "    deberta_input_batches = torch.split(preprocessed_data['deberta_input_ids'], batch_size)\n",
    "    deberta_attention_batches = torch.split(preprocessed_data['deberta_attention_mask'], batch_size)\n",
    "    labels_batches = torch.split(preprocessed_data['labels'], batch_size)\n",
    "\n",
    "    # Determine the number of batches\n",
    "    num_batches = len(bert_context_batches)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for batch_idx in range(num_batches):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Retrieve batch data for both BERT and DeBERTa\n",
    "            bert_context_input_ids = bert_context_batches[batch_idx]\n",
    "            bert_context_attention_mask = bert_context_mask_batches[batch_idx]\n",
    "            deberta_input_ids = deberta_input_batches[batch_idx]\n",
    "            deberta_attention_mask = deberta_attention_batches[batch_idx]\n",
    "            labels = labels_batches[batch_idx]\n",
    "\n",
    "            # Prepare preprocessed data dictionary for model forward pass\n",
    "            batch_data = {\n",
    "                'bert_context_input_ids': bert_context_input_ids,\n",
    "                'bert_context_attention_mask': bert_context_attention_mask,\n",
    "                'labels': labels,\n",
    "                'deberta_input_ids': deberta_input_ids,\n",
    "                'deberta_attention_mask': deberta_attention_mask\n",
    "            }\n",
    "\n",
    "            # Forward pass\n",
    "            total_loss, retrieval_logits, generated_logits = model(batch_data)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate the batch loss for the epoch\n",
    "            epoch_loss += total_loss.item()\n",
    "            print(f\"Epoch [{epoch + 1}/{epochs}], Batch [{batch_idx + 1}/{num_batches}], Loss: {total_loss.item()}\")\n",
    "\n",
    "        # Average loss for the epoch\n",
    "        avg_loss = epoch_loss / num_batches\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}] Average Loss: {avg_loss}\")\n",
    "\n",
    "    print(\"Training completed.\")\n",
    "\n",
    "# Load a small sample dataset and preprocess it\n",
    "df = pd.read_json(\"hotpot_train_v1.1.json\").sample(n=10000)\n",
    "preprocessed_df = preprocess_data(df)\n",
    "\n",
    "# Instantiate the model\n",
    "model = GANModel()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Training loop\n",
    "train(model, optimizer, preprocessed_df, epochs=3)\n",
    "\n",
    "# save_directory = \"./deberta_v3_base_model\"\n",
    "# \n",
    "# # Save tokenizer and model\n",
    "# deberta_tokenizer.save_pretrained(save_directory)\n",
    "# model.answer_generation_network.deberta.save_pretrained(save_directory)\n",
    "\n",
    "# Load the tokenizer and model from the saved directory\n",
    "# tokenizer = AutoTokenizer.from_pretrained(save_directory)\n",
    "# model = AutoModelForQuestionAnswering.from_pretrained(save_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to ./deberta_v3_base_model\n"
     ]
    }
   ],
   "source": [
    "# Define the directory where you want to save the model and tokenizer\n",
    "save_directory = \"./deberta_v3_base_model\"\n",
    "\n",
    "# Save the DeBERTa tokenizer and model\n",
    "deberta_tokenizer.save_pretrained(save_directory)\n",
    "model.answer_generation_network.deberta.save_pretrained(save_directory)\n",
    "\n",
    "print(f\"Model and tokenizer saved to {save_directory}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-01T23:58:08.472717600Z",
     "start_time": "2024-11-01T23:58:07.767753300Z"
    }
   },
   "id": "1cab41bd87a12501",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to ./deberta_v3_base_model2\n"
     ]
    }
   ],
   "source": [
    "# Define the directory where you want to save the model and tokenizer\n",
    "save_directory = \"./deberta_v3_base_model1\"\n",
    "\n",
    "# Save the DeBERTa tokenizer and model\n",
    "deberta_tokenizer.save_pretrained(save_directory)\n",
    "model.answer_generation_network.deberta.save_pretrained(save_directory)\n",
    "\n",
    "print(f\"Model and tokenizer saved to {save_directory}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-01T23:58:21.521695200Z",
     "start_time": "2024-11-01T23:58:21.015867100Z"
    }
   },
   "id": "ce0483356d0b0269",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to ./bert_model1\n"
     ]
    }
   ],
   "source": [
    "# Define the directory where you want to save the model and tokenizer\n",
    "save_directory = \"./bert_model1\"\n",
    "\n",
    "# Save the DeBERTa tokenizer and model\n",
    "bert_tokenizer.save_pretrained(save_directory)\n",
    "model.retrieval_network.bert.save_pretrained(save_directory)\n",
    "\n",
    "print(f\"Model and tokenizer saved to {save_directory}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T11:59:52.555483200Z",
     "start_time": "2024-11-02T11:59:52.055823900Z"
    }
   },
   "id": "8a4d756ce0421027",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x500 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Read the log file\n",
    "with open('loss.txt', 'r') as file:\n",
    "    log = file.readlines()\n",
    "\n",
    "# Extract batch losses\n",
    "batch_losses = []\n",
    "for line in log:\n",
    "    match = re.search(r'Loss: ([\\d\\.]+)', line)\n",
    "    if match:\n",
    "        loss = float(match.group(1))\n",
    "        batch_losses.append(loss)\n",
    "\n",
    "# Apply a moving average for smoothing\n",
    "window_size = 10  # Adjust window size for more or less smoothing\n",
    "smoothed_losses = np.convolve(batch_losses, np.ones(window_size)/window_size, mode='valid')\n",
    "avg_e1=0.35747247423231604\n",
    "avg_e2=0.19631572096273303\n",
    "avg_e3=0.14999720402713865\n",
    "# Plotting the smoothed losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(smoothed_losses, label='Combined Loss', color='lightblue')\n",
    "plt.xlabel('Batch Number')\n",
    "plt.ylabel('Loss')\n",
    "plt.hlines(avg_e1,0,2500, color=\"blue\", label=\"Epoch Average\")\n",
    "plt.hlines(avg_e2,2500, 5000, color=\"blue\")\n",
    "plt.hlines(avg_e3,5000,7500, color=\"blue\")\n",
    "# plt.vlines(x=2500, ymin=0, ymax=7)\n",
    "# plt.vlines(x=5000, ymin=0, ymax=7)\n",
    "plt.ylim(0,1.5)\n",
    "plt.title('Combined training Loss per Batch per epoch')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-04T09:52:59.723966400Z",
     "start_time": "2024-11-04T09:52:59.625640900Z"
    }
   },
   "id": "15c9c99adfa22ec0",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f1843bd93bc5abc1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
